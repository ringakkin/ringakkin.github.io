{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/umami-view.js","path":"js/umami-view.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"acad91ace80b80295b11a9b7ad4c29a2dcfdd8fb","modified":1724577194748},{"_id":"source/_posts/needsHierarchy.md","hash":"5c0ad9edffb52dc1a71307c8f8b841752bfdd328","modified":1724577195503},{"_id":"source/_posts/kafka.md","hash":"83f83c9f44c8ac8a50bd00f5a58d8159ec1c84c4","modified":1724577196279},{"_id":"source/_posts/obsidian-zola.md","hash":"613fd2b7c7cc1a27e73040a46c4acb58555abcde","modified":1724577196279},{"_id":"source/_posts/sleep.md","hash":"154645e2f5f0c0726fe277aafabf87c4defea368","modified":1724577195504},{"_id":"source/_posts/presentation.md","hash":"1ee13e40a9a40600eb593c1662c9489ae8b0971d","modified":1724577196280},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1724577189670},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"f5c17282f53b08a024ef8e04ddf988b46f1d02b6","modified":1724577189550},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"511e49f0bd8282a0d002c527474da8e1e5add393","modified":1724577189548},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"8cb27280346eae05984de91f79562a38a7549398","modified":1724577189549},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"fd6756866314aaf4b15d734a83b85aa09aa0b5ed","modified":1724577189603},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"c49974dcbda02fe720498398e9778826335459c0","modified":1724577189559},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"838a68e210bddfca6d4ba070e1e2f1ca53cb7d06","modified":1724577189596},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"2f3ea36713f0fa91d8d61d39fcf9e584372de818","modified":1724577189594},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"dde1f6a27c8d09c38850a691089937f181b6c035","modified":1724577189597},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"c524ce76747042ec2f9ed8d5025f80e01b462b3b","modified":1724577189595},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"264f68cbf826787e683a30e1377c56c0895c7386","modified":1724577189597},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"d4ffeb7eff398dea154340794bd277f75ddeedef","modified":1724577189598},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"fbed4b3d1e475b3de9d8ce05362abcc658a53408","modified":1724577189599},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"e87fc58829ea214ac16e8e4f13cd5c389133697b","modified":1724577189602},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"c8da695dc1b01b715909ae6f1052ccaebdf9db4c","modified":1724577189601},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"8ba210724c023d45a4564415762f3da299bd1d0e","modified":1724577189600},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"b7c1a6d8fc1097fc16d2300260297013cb692153","modified":1724577189602},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"f814263ded504cb4c50a8b66157bdd71f553be1b","modified":1724577189551},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"314b97a7e68093328675acfd308d839b1d772ac9","modified":1724577189553},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"415e3403182e1282386f28b9d61343f147519163","modified":1724577189552},{"_id":"node_modules/hexo-theme-fluid/languages/zh-HK.yml","hash":"05418d0bca261de386872be65027bf4498758788","modified":1724577189557},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"65a90f294f6c73245e8250e87d124630ad10b389","modified":1724577189554},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"497b3dea5058f718da225a7a443e916da895ea10","modified":1724577189556},{"_id":"node_modules/hexo-theme-fluid/languages/ru.yml","hash":"998112b384b574e0e29c6ea16e4c1ebce1c15a4c","modified":1724577189555},{"_id":"node_modules/hexo-theme-fluid/languages/es.yml","hash":"0ad94ddf1ca868a67b5b84aed257a30572962210","modified":1724577189553},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"ded0621e63b1f8b241be21f6e9b52d4f36edbcd0","modified":1724577189558},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"508254a648d8597e62e4012c8beab44bfa82e904","modified":1724577189561},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"78c34e32746041f23678669bbadfbede15e4c6d2","modified":1724577189560},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"0c14869e15f7dc615c8353765569644238f38f2d","modified":1724577189562},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"1ce9094faec6204949cdaf604aaf9200787e4218","modified":1724577189562},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/css.ejs","hash":"901280e6fb3194c30542751d04f27e78b42d3c6f","modified":1724577189571},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"6bb3335b5486d4bee2ed42f8bef57903066bc234","modified":1724577189572},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"b5cd435b27f090939b6051bef41a38a3376044ac","modified":1724577189578},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/head.ejs","hash":"a0bcbbfc34efaef3b23c6b531e7f3201f2eab2dd","modified":1724577189575},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header.ejs","hash":"3668304d08c48b68d532532921a12069a2736150","modified":1724577189575},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"89fc9f663a1091911b79ab9697c09446d16184f9","modified":1724577189593},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/search.ejs","hash":"57a0f61242d9ce2bd2c51b2f84193f6dc1377ef9","modified":1724577189593},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"6c3b24207e4ea3ae4edeb715af40ef23711b92b9","modified":1724577189604},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0d443f23c459787338917900f50fec1c8b3b3bdd","modified":1724577189579},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"3d30c722b9e24c33577d6fab822628841fadf992","modified":1724577189616},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"2340a576635b16fd2456b3494f5afe89cd7764db","modified":1724577189617},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"67637461e3f94f9e9675369eb7ff015355d9ec54","modified":1724577189618},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/engine.js","hash":"96af7e55fdbe0819bacc554ecbfe42375a088df6","modified":1724577189623},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"14a207a7d4e329382ab5d4e1da1ef85ff043daba","modified":1724577189623},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bc9ba08d1d871394ee1c3a1cc2f21dc343f515a","modified":1724577189622},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/import.js","hash":"f9821f7789ea6f069977a8c642aa5ccb6d19077c","modified":1724577189625},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/injects.js","hash":"9219d59c51930c7a82fcde918d6efbc5aa572ea2","modified":1724577189625},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"49b2c6449d7be35739c6cfea3cab4e790580983a","modified":1724577189626},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"f57be245e6e7228673e1dec3a3477e731492c5c1","modified":1724577189628},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"f713ddb6c8018ec7b96d3567057f1f932609beea","modified":1724577189628},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"0bb33314aa5cfe326ab9bb14b545e343e4db4193","modified":1724577189629},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"e1d0caed12e7cd9a35cf64272c41854b2901a58f","modified":1724577189630},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/scope.js","hash":"3b67d50050158423c8fa47f1de6aedcfe916637b","modified":1724577189627},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"1ff4ea054f2c735dfaccb0be90f1708a2a750bc8","modified":1724577189631},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/fold.js","hash":"a93e2603021ad38714e870399767bea24e7cbe3e","modified":1724577189631},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"cc176cc1d7e7cc28cedf8397ae748c691d140be2","modified":1724577189632},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"e300ec4ee6c63464859ab000e987bf8dd7db4025","modified":1724577189633},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"dbfe59fde77d87b1d7d0c46480a2a729010988eb","modified":1724577189633},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"37f90bd4e35ce49457dc2a348b9f66e0b242c014","modified":1724577189635},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"6c5916d86c63795c7e910bf614b0e7ece5073702","modified":1724577189632},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/crypto.js","hash":"474b00a57f43dbe7bc2876d637ece4214d016c06","modified":1724577189635},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"3e03b534e2e92a6e17567b006d7e3eaad4b37598","modified":1724577189636},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/index-generator.js","hash":"3550976efc94500284795f13485f5a1765fc120b","modified":1724577189618},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/url-join.js","hash":"dbdb10b23fcd3928e86a4cb46fa3455e060b4aa0","modified":1724577189637},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"33427308ca29f1d76336c83e704571c9de75df02","modified":1724577189620},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/resolve.js","hash":"a5d70005913ab03cea0a0dc601097628b4dbd5a8","modified":1724577189636},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"3fb72d3c2224c32d861a6e8a85e78a8b67e6a244","modified":1724577189621},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"c74d7aed425d20f2fa096f386a9521b67b9ab269","modified":1724577189674},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"1fe60b2ab1d704f5a4f55e700dca5b8785fb390e","modified":1724577189674},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1724577189676},{"_id":"node_modules/hexo-theme-fluid/source/css/highlight.styl","hash":"57ce8b8f95ab1f40612a9dce1793de5ab9b4bbfc","modified":1724577189674},{"_id":"node_modules/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1724577189680},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"9e9171325bb7148c11ceee283d00c137c8a1c5c5","modified":1724577189675},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1724577189681},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"33bb7c8255d2e3c93a1bea8c9221399b3a868a63","modified":1724577189682},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1724577189680},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"3efd602cdb694902d6e74c4eb1e5bd70120ac5b1","modified":1724577189683},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"491021125d2579e841c83f36d3ab790d1eab9d1e","modified":1724577189685},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"67f6250f98b36a6599ea982d11cbb060c5ffb92a","modified":1724577189684},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"e9ad1b5659f0af867174687daa0ecf4375e40b75","modified":1724577189685},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"753c2cf95f2659fef80277b895f4da10c8888c72","modified":1724577189686},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"e7addcc88eb73dec4a9a8641a4bb68966a38a65d","modified":1724577189683},{"_id":"node_modules/hexo-theme-fluid/source/js/umami-view.js","hash":"370ab30ab88c596d85327dbd7db3bafd49489fdd","modified":1724577189687},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"9d0423db40a787f3b19968205b9ed92a848c9153","modified":1724577189688},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"0c410ef79785897c8de3da333b057a2936fd569b","modified":1724577189563},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1724577189689},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"1e93ca89777e4beb0f0e5cb70e03aab48e958542","modified":1724577189564},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/discuss.ejs","hash":"d400e5721af28cefecaf50b46c82dcdde4cda4a8","modified":1724577189565},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"7f04e5c22821bb94da791973d9c6692b03bac81d","modified":1724577189567},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"79ec17eec6e15076c685688e740230e92c66efa9","modified":1724577189565},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"66995ec9dab10ed35c2a775010c447113c6848d4","modified":1724577189566},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"938eb60413ae8af83ffeaba4d85df88387cdd5be","modified":1724577189569},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"45c879768b40ba56af62e18ad54bffbf73a6f3a1","modified":1724577189568},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"bcceafab01fe695c59951d939f7cef502f3d7b48","modified":1724577189568},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"df6bae1a93827991049f7a33f6a69681c60eab0e","modified":1724577189571},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"ef04d4fc3f26588ae9d8712938d648304fc05455","modified":1724577189570},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"d7bcc183fc31af643e7835b13da10fe2ab8614ce","modified":1724577189569},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"a84d8dcb44f5f6289ef09db4d02ab14de72c2c87","modified":1724577189576},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"551ffae43844925beb099c85a9e6d8d9fcbf8086","modified":1724577189588},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"047bece1db5cdf96cb78a44c6420ce3e92e6a9ca","modified":1724577189574},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"f0cb813cd03642c9b68cff8b6669f73a61dd10f8","modified":1724577189589},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"26905d5862b1531ebcc175af15178dabeecc81c8","modified":1724577189589},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"e5219b14410066bf8ab491379aca797304b4a914","modified":1724577189577},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"73827074db4e0fc3d52c51a76285df87aa5e5a7f","modified":1724577189590},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"db4ecdcc762bb1b1bae5060f0baa6115174779ff","modified":1724577189590},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"77d0c9df31a22ed8a3e341637bde4165a11a7ce9","modified":1724577189573},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"1b1eb4c8e163a5d909e86da76ef778948e0e0b77","modified":1724577189592},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"2507cdad08f61cf8c1d9b0ca7f4f1dc8c4e5841b","modified":1724577189591},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"31208a0db986ba864f756a8ec806b7d254440f9b","modified":1724577189606},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"9b1934c61dc78622a07da554413f6ad31854576d","modified":1724577189608},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"da987411ae4a4e6896a9b8af1fce6209192af28e","modified":1724577189609},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"d103e4bf612b2445bb136712d57b81e784a313e2","modified":1724577189610},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"f8fe8e58b83f627db82c0dbeb663389efc33c1c6","modified":1724577189580},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"92123b7280695b4ac6650f5e1d7fa0d772c71f5b","modified":1724577189612},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"ec6bf395ccad3dd41f29dc0080aeabf413e30fd9","modified":1724577189614},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"8a4ea62c46f9a75c94096a27b2d3f5c10a2f82e5","modified":1724577189581},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"c9696633f77dd8055e900497469f9e64eca4d97f","modified":1724577189613},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"03c7c69fbb1754fdccfa18671aac23b8637b869e","modified":1724577189582},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"018cab52ff696a6c78ebc01e10237a90a0c33603","modified":1724577189582},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"3900e54ade140e0e49c571a1955f0b1f3a59b281","modified":1724577189583},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"502b99e19e496825df7032ca2b0b1a95ebb2b357","modified":1724577189583},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"d0f06fb482e3a8f9a53dfd94c4e4a65a43f1ff34","modified":1724577189584},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"110e45e2d3433178f00f482adc863110f90c46d6","modified":1724577189585},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/moment.ejs","hash":"acc72c3284fe906a4505132c3d9a4720d80e6fcb","modified":1724577189586},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"47c1df255aa552ad71ef3e57deca46530a8f2802","modified":1724577189587},{"_id":"node_modules/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"42850952e8f5858497fe774c2aff87b6563ab01e","modified":1724577189587},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"046979dbd8cdabd21d89f9c1d8f1bb3f2fd06d6f","modified":1724577189639},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"171697018fd384fce0834875ca94b91f16564cac","modified":1724577189638},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"9ea66cf79f1e4356b6b402bc3dc5fb55c9862f1f","modified":1724577189673},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"8ba5fb6a8ced1de6f7893184bf12f4021fe22595","modified":1724577189641},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"92c062cf55457b6549497244d09ec34e9c0c95c2","modified":1724577189671},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"e3846fb429f6732bd15fde40f7c28b3492d786c8","modified":1724577189642},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"cd255079553985722ee80fb1833f6507dde52194","modified":1724577189655},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"d3aeb7bf22d52d7dde59b292090ef8b46943718a","modified":1724577189662},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"f35415bd86b5c26fbc71728048d9e1481263554f","modified":1724577189660},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"4263f7b930e6b57e13295d17fd3745a9e5c52494","modified":1724577189661},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"66d5b045c0e54001d3c98c5901d72590fe08acc4","modified":1724577189656},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"bac20c8fb20276b08972df5ecc7a5850a72393f4","modified":1724577189663},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"58a7f8f2baea2d58cf5f7edfc91314ee5d7156ca","modified":1724577189658},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"96c3bb95dea4b3d3ecd20b810a674bfcef04870c","modified":1724577189657},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/print.styl","hash":"571bd018e914bd0f7c5f89df874b5937937e5fa6","modified":1724577189659},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"29e9b72cfda2f2baf9cf2597fcd7f9e66303a9bd","modified":1724577189671},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"d3ef491fd449d89a1b95801dee788a5d9bec4320","modified":1724577189665},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"1fc96d09d52d9502e84e4e2a8d482ea45e8b81ea","modified":1724577189666},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"d73cccb65eaa804910884df17442e34736b3f4fb","modified":1724577189667},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"2d12f23b46d0ce07ae810bc4f5635c490a098fa4","modified":1724577189668},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"6a35a450bd0a12f68fd92aac3f88b23475a98d46","modified":1724577189669},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"26d65475b1c52a61115044db8883df6739c3a473","modified":1724577189643},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"31c64c3fae4a0fc4747d8afeb72f7a9667c5326c","modified":1724577189669},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"80301db38e448e40e88bb34d0128628b0809b243","modified":1724577189644},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"1068d71721baeed76bf0176f9b964d36b5764c9f","modified":1724577189645},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"3ac1eb36e124adef607775aa505386d5680960e2","modified":1724577189647},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"417a7388b39c0203178b0032e151febd66a0e9f3","modified":1724577189646},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"41935973a66c14ab2bea0539d4b1f15c62534fa4","modified":1724577189648},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"e6f5921ff9009c1853e7db30c482bc1682433ed9","modified":1724577189648},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"88c3c2d99a097142a87eeec0c7c65a3789f25117","modified":1724577189649},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"0ca6171ce262339e0e36cfea0978b554d87ae7fc","modified":1724577189650},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"f4ae7cbf2f10f459de7864f8e642553b587df889","modified":1724577189652},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"48799d3148ef6493be0e05897c635124e9b05d03","modified":1724577189651},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"8fad325e411bc83c8ebdc4115015477eed5f60da","modified":1724577189651},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"04447d3b673be84a1af1dc57933a3c41dd7c0cfe","modified":1724577189653},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"e4dbbbb1a2508a72bc04680552d7ebbea0eed0fe","modified":1724577189653},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"1f4e678d7219815ab62de1b92ec75e021247f90b","modified":1724577189654},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"5defef321e3e933fe84f3f2ca481c88f55381fb0","modified":1724577189655},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1724577189678},{"_id":"public/local-search.xml","hash":"aa694d440bdc132984a8cf874971bed715f8f50c","modified":1724639153365},{"_id":"public/archives/index.html","hash":"434575991dd553d01c56d8b11ec90252aafdc236","modified":1724639153365},{"_id":"public/archives/2024/index.html","hash":"feeb340a2509d849cc12cb87fec34aec7082fe2c","modified":1724639153365},{"_id":"public/archives/2024/08/index.html","hash":"f5bb65d67d1ff5c781eb01306435a696ab509361","modified":1724639153365},{"_id":"public/404.html","hash":"db40f7df9ed1393d72508db0298b0b7ef0dabc1c","modified":1724639153365},{"_id":"public/tags/index.html","hash":"d31f3bd2ac4c8c05460b885f7e73f51d5b87e7fb","modified":1724639153365},{"_id":"public/categories/index.html","hash":"2d443813e7607623222b40263bb0f006f54b7cc9","modified":1724639153365},{"_id":"public/links/index.html","hash":"e289cacfc942a1dd958893712d8c2f78ead3875a","modified":1724639153365},{"_id":"public/2024/08/25/presentation/index.html","hash":"e156229570d8f29d690a5c9061819a18e07cefe9","modified":1724639153365},{"_id":"public/2024/08/25/obsidian-zola/index.html","hash":"09e2092745279226c250d951181b9c0552d4102d","modified":1724639153365},{"_id":"public/2024/08/25/kafka/index.html","hash":"9d460296c121af5415f866ed920a2b3e6035635b","modified":1724639153365},{"_id":"public/2024/08/25/needsHierarchy/index.html","hash":"fc12326722a7335290f72b77e148586ba00d83c2","modified":1724639153365},{"_id":"public/2024/08/25/sleep/index.html","hash":"ffc38bca823d24427f03eaba9468168f00d0292a","modified":1724639153365},{"_id":"public/2024/08/25/hello-world/index.html","hash":"4a8d9edeaa2da77f66344f8e5916e1d3bfcdbc1b","modified":1724639153365},{"_id":"public/index.html","hash":"decfea0f2cd0ff91e79ecfa1afbe593f21b9ddda","modified":1724639153365},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1724639153365},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1724639153365},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1724639153365},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1724639153365},{"_id":"public/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1724639153365},{"_id":"public/css/highlight.css","hash":"04d4ddbb5e1d1007447c2fe293ee05aae9b9563e","modified":1724639153365},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1724639153365},{"_id":"public/css/highlight-dark.css","hash":"902294bada4323c0f51502d67cba8c3a0298952f","modified":1724639153365},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1724639153365},{"_id":"public/js/color-schema.js","hash":"1ef88c881b9f942deadde3d890387b94c617342a","modified":1724639153365},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1724639153365},{"_id":"public/js/events.js","hash":"6869811f67e4c3de3edfa4b08464bb242b97a402","modified":1724639153365},{"_id":"public/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1724639153365},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1724639153365},{"_id":"public/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1724639153365},{"_id":"public/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1724639153365},{"_id":"public/js/umami-view.js","hash":"33c4b3883fa747604074ad3921606eeeaeb50716","modified":1724639153365},{"_id":"public/css/main.css","hash":"14ebd9b515085666cee29bbcbe362ad3604ab62a","modified":1724639153365},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1724639153365}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2024-08-25T09:13:14.748Z","updated":"2024-08-25T09:13:14.748Z","comments":1,"layout":"post","photos":[],"_id":"cm0admg6q000054uig0yieyn1","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo new <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo new <span class=\"hljs-string\">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo server<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo generate<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">$ hexo deploy<br></code></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"马斯洛“需要层次理论”","_content":"\n![马斯洛“需要层次理论”](https://pic1.zhimg.com/70/v2-0d3a66ebd920914936c396c4ce1a0d4b_1440w.image?source=172ae18b&biz_tag=Post)\n\n# 马斯洛“需要层次理论”\n\n\n人类要思考如何慢下来\n\n\n需要层次理论是由**美国心理学家马斯洛在1943年所著的《人的行为动机》一书中提出**来的，在世界上广为流传，成为应用最普遍、最主要的激励理论之一。\n\n### 1. 需要层次理论的基本内容\n\n马斯洛的需要层次理论主要有以下三个观点。\n\n---\n\n1. 人的多种需要分为5个层级\n\n马斯洛认为，需要是人类行为的积极的动因或源泉。需要引起动机，动机驱动行为。  \n因此弄清了人类的基本需求结构或层次，就能很好地说明、解释、预测和控制人类的行为。  \n他按照**由低级到高级的顺序将人的需要分为五个层次：生理需要、安全需要、社交需要、尊重需要、自我实现需要。**\n\n- **生理需要是人类维持其生命和生存最基本的需要，也是需要层次的基础，包括对食物、水、性以及避免寒冷或炎热的需要等。**  \n  对于缺乏这类东西的人来说，其主要的行为动机受生理需要支配。  \n  例如，一个极端饥饿的人，将会把全部的精力用在觅食活动上，对他来说有食物的地方是最理想的去处。  \n  马斯洛曾说“一个人如果同时缺少食物、安全、爱情和被尊重等，则食物的渴求可能最为强烈。”  \n  生理需要是人类最低层次的需要。一旦这种需要被满足，人们开始最求最高层次的需要。\n\n- **安全需要是指对避免危险、威胁和剥夺的需要。**  \n  **最常见的安全需要之一，就是保护个人免受肉体上的危险**，如火灾或事故等。  \n  在工业部门，常见到这类标牌“此区禁止吸烟”“超过此处必须佩戴护目镜”等，也是管理者为满足安全需要所做的一种努力。  \n  **第二种安全需要是经济保障。**  \n  员工的各种福利待遇，如事故保险、健康保险以及人寿保险等，均有助于满足这类需要。  \n  **第三种安全需要是对有秩序的、可预知环境的需要。**  \n  安全需要的含义很广泛，从世界和平、社会安定直至个人的安全等都属于安全需要的范畴。安全需要是人类安居乐业的基本保证。\n\n- **社交需要是指个人对爱、情感和归属的需要，**主要包括两方面内容。  \n  **一是爱的需要**，即人都希望伙伴之间、同事之间关系融洽，保持友谊和忠诚，希望得到甜美而忠贞的爱情，希望爱别人，也渴望得到别人的爱。  \n  **二是归属的需要**，即个体都有一种要求归属于一个集团或群体的感情，希望成为其中的一员并得到相互关心和照顾。  \n  组织管理者应该认识到，当社交需要成为主要的激励来源时，员工会把工作视为寻求建立温馨、友善、和谐人际关系的机会。\n\n- **尊重需要是指个体希望获得成就感以及得到他人对自身价值的承认与尊重。**  \n  尊重需要分为两类：**一类是希望有实力、有成就、能胜任、有信息以及要求独立和自由；另一类是要求能使对自己充满信心，对社会满腔热情，体会到自己生活在世界上的用处和价值，**但尊重需要一旦受到挫折，就会使人产生自卑感、软弱感、无能感，从而使人失去生活的基本信心。  \n  关注员工尊重需要的管理者一般会通过公开奖励以承认其工作业绩等方式激励员工。这类管理者会采用在公司报刊上撰写文章或在公报栏里发布消息等方式对员工的良好表现进行表扬。当然，也有部分员工不喜欢公开表扬而宁愿私下被肯定成绩。\n\n- **自我实现需要是人的最高层次的精神需要。**它是指发挥自我内在潜力，实现自己理想和抱负的需要。  \n  产生这种需要的人决心发挥自己最大的能力完成难度较大的工作任务，成就一番事业，努力使自己成为理想的人。  \n  这种需要往往是通过胜任感和成就感来获得满足，如音乐家创作出天籁之音，作家写出万古流芳的作品，诗人吟唱出脍炙人口的诗篇，这些都是借以达到自我实现的途径。  \n  注重自我实现需要的管理者会激励员工们进行工作设计，发挥一技之长，或者给予班组以自由安排工作任务的权力。\n\n\n马斯洛需要层次理论\n\n---\n\n2. 人的需要分等分层，像阶梯一样逐渐上升\n\n马斯洛认为，人的五个层次的需要是由低向高排列的。  \n一般来说，只有在低层次的需要满足之后，人才会进一步追求较高层次的需要，而且低层次需要满足的程度越高，对高层次需要的追求就越强烈。  \n马斯洛将五种需要划分为高、低两级。  \n生理需要和安全需要属于低级需要，这些需要通过外部条件使人满足，如借助于工资收入满足生理需要，借助于法律制度满足安全需要等。  \n社交需要、尊重需要和自我实现需要是高级需要，它是从内部使人得到满足的，而且一个人对这些高级需要是永远不会感到完全满足的。  \n因此通过满足员工的高级需要来调动工作积极性，具有更稳定、更持久的力量。  \n人在不同的发展阶段，其需求结构也不同。一般来说，在同一时期内，人们可以同时存在几种需要，但总有一种需要占支配地位，它决定着人们行为的方向。\n\n---\n\n3. 未被满足的需求才有激励作用\n\n需要是促使人产生某种动机的内在基础。  \n当一个人一无所求时，也就没有什么动力与活力；反之，若一个人有所需求，就必然存在着激励因素。  \n五个层次的需要是人生来就有的，但每一个人的需求强度、暴露程度可能不同，它由生物的、文化的、环境的因素共同决定。  \n另外，当某种需要得到满足之后，这种需求也就失去了对行为的唤起作用，下一层次的尚未满足的需求就会成为人们行为的动力。  \n高层次的需要，不仅内容比低层次需要更广泛，实现难度也更大。  \n**马斯洛1943年曾经指出，85%的生理需要和70%的安全需要一般会得到满足，但只有50%的社交需要、40%尊重需要和10%的自我实现需要能得到满足。**\n\n---\n\n### 2. 需要层次理论在企业管理中的应用\n\n马斯洛的需要层次理论第一次系统地阐述了人的需要与行为之间的关系，在现代企业管理中具有广泛的应用价值。  \n下表列出了不同层次需要对应的追求目标及相应的管理措施。\n\n\n需要层次理论与管理措施相关表\n\n从【需要层次理论与管理措施相关表】可以看出，管理者可以根据五种需要层次对员工的多种需要加以归类和确认，然后了解员工未满足的或正在追求的需要是什么，采取相应的管理制度与措施进行激励，既不能落后，又不能超前于员工的需求状况。\n\n**这就是说，当员工的低层次需要未得到满足时，不要奢望他们有更高的献身精神，应把解决他们的衣食住行问题放在首位；而当员工的低层次需要被满足了时，又不能一味地停留于物质奖励的办法来刺激他们，应该创设更好的工作和人际环境，来满足他们更高层次的需要。**\n\n在某种程度上说，一个企业或组织员工需求层次的高低，应作为企业或组织管理成败的重要标志之一。员工需求层次愈高，说明这个企业的管理愈成功，反之亦然。\n\n---\n\n### 3. 对需要层次理论的评价\n\n西方管理心理学对马斯洛的需要层次理论的评价各不相同。总的来说，既重视这一理论，又指出了这一理论的不足之处。\n\n一方面，马斯洛的需要层次论有其科学性的一面。  \n第一，马斯洛对人类的需要进行系统研究，把千差万别的人类需要归纳为五个层次，并就五个层次需要的内容和层次间的关系作了详细阐述，这与以往心理学所进行的零散、不系统的研究相比无疑是前进了一步。因此需要层次论对心理学的需要动机理论发展是一个重要的贡献。  \n第二，马斯洛提出的需要层次性和需要由低级向高级发展的趋向，在某种程度上是符合人类需要发展的一般规律的。一个人从出生到成年，其需要的发展基本上是按照马斯洛提出的需要层次进行的。  \n第三，马斯洛的需要理论为企业管理指出了调动积极性的工作方向和内容。例如，任何企业都应该从物质和精神两方面去满足员工的合理需要，同时要根据不同员工不同的需要层次，针对性地采取不同的管理措施。\n\n另一方面，马斯洛的需要层次论也有局限性和不足之处。  \n第一，马斯洛的需要理论绝大部分谈的是人的自然需要，忽视了社会存在对人的成长所具有的影响。马斯洛认为人的需要都是本能的活动，都是生而具有的。人有生理需要是为了维持自己的生存；人有安全需要是出于“趋利避害”的本能；人有社交需要是为了自己享受生活的乐趣；人有尊重和自我实现的需要是为了自己能出人头地，高高在上。这样就完全否定了社会存在对人的成长的决定性影响，宣扬个人主义的实质非常明显。  \n二是，马斯洛的需要层次论带有一定的机械主义色彩。把人的需要层次看成固定的程序，认为只有满足了低一级的需要层次之后，才能进入下一层次的需要，这显然是机械的。它忽视了人的主观能动性，忽视了高层次需要有对低层次需要影响的一面，忽视了为了崇高理想，人可以忍受物质生活困难带来痛苦，甚至牺牲宝贵生命的事实。\n\n\n\n[马斯洛需求层次理论](https://www.zhihu.com/topic/19904710)\n\n[管理心理学](https://www.zhihu.com/topic/20010089)\n\n[企业管理](https://www.zhihu.com/topic/19559804)\n\n","source":"_posts/needsHierarchy.md","raw":"---\ntitle: 马斯洛“需要层次理论”\n---\n\n![马斯洛“需要层次理论”](https://pic1.zhimg.com/70/v2-0d3a66ebd920914936c396c4ce1a0d4b_1440w.image?source=172ae18b&biz_tag=Post)\n\n# 马斯洛“需要层次理论”\n\n\n人类要思考如何慢下来\n\n\n需要层次理论是由**美国心理学家马斯洛在1943年所著的《人的行为动机》一书中提出**来的，在世界上广为流传，成为应用最普遍、最主要的激励理论之一。\n\n### 1. 需要层次理论的基本内容\n\n马斯洛的需要层次理论主要有以下三个观点。\n\n---\n\n1. 人的多种需要分为5个层级\n\n马斯洛认为，需要是人类行为的积极的动因或源泉。需要引起动机，动机驱动行为。  \n因此弄清了人类的基本需求结构或层次，就能很好地说明、解释、预测和控制人类的行为。  \n他按照**由低级到高级的顺序将人的需要分为五个层次：生理需要、安全需要、社交需要、尊重需要、自我实现需要。**\n\n- **生理需要是人类维持其生命和生存最基本的需要，也是需要层次的基础，包括对食物、水、性以及避免寒冷或炎热的需要等。**  \n  对于缺乏这类东西的人来说，其主要的行为动机受生理需要支配。  \n  例如，一个极端饥饿的人，将会把全部的精力用在觅食活动上，对他来说有食物的地方是最理想的去处。  \n  马斯洛曾说“一个人如果同时缺少食物、安全、爱情和被尊重等，则食物的渴求可能最为强烈。”  \n  生理需要是人类最低层次的需要。一旦这种需要被满足，人们开始最求最高层次的需要。\n\n- **安全需要是指对避免危险、威胁和剥夺的需要。**  \n  **最常见的安全需要之一，就是保护个人免受肉体上的危险**，如火灾或事故等。  \n  在工业部门，常见到这类标牌“此区禁止吸烟”“超过此处必须佩戴护目镜”等，也是管理者为满足安全需要所做的一种努力。  \n  **第二种安全需要是经济保障。**  \n  员工的各种福利待遇，如事故保险、健康保险以及人寿保险等，均有助于满足这类需要。  \n  **第三种安全需要是对有秩序的、可预知环境的需要。**  \n  安全需要的含义很广泛，从世界和平、社会安定直至个人的安全等都属于安全需要的范畴。安全需要是人类安居乐业的基本保证。\n\n- **社交需要是指个人对爱、情感和归属的需要，**主要包括两方面内容。  \n  **一是爱的需要**，即人都希望伙伴之间、同事之间关系融洽，保持友谊和忠诚，希望得到甜美而忠贞的爱情，希望爱别人，也渴望得到别人的爱。  \n  **二是归属的需要**，即个体都有一种要求归属于一个集团或群体的感情，希望成为其中的一员并得到相互关心和照顾。  \n  组织管理者应该认识到，当社交需要成为主要的激励来源时，员工会把工作视为寻求建立温馨、友善、和谐人际关系的机会。\n\n- **尊重需要是指个体希望获得成就感以及得到他人对自身价值的承认与尊重。**  \n  尊重需要分为两类：**一类是希望有实力、有成就、能胜任、有信息以及要求独立和自由；另一类是要求能使对自己充满信心，对社会满腔热情，体会到自己生活在世界上的用处和价值，**但尊重需要一旦受到挫折，就会使人产生自卑感、软弱感、无能感，从而使人失去生活的基本信心。  \n  关注员工尊重需要的管理者一般会通过公开奖励以承认其工作业绩等方式激励员工。这类管理者会采用在公司报刊上撰写文章或在公报栏里发布消息等方式对员工的良好表现进行表扬。当然，也有部分员工不喜欢公开表扬而宁愿私下被肯定成绩。\n\n- **自我实现需要是人的最高层次的精神需要。**它是指发挥自我内在潜力，实现自己理想和抱负的需要。  \n  产生这种需要的人决心发挥自己最大的能力完成难度较大的工作任务，成就一番事业，努力使自己成为理想的人。  \n  这种需要往往是通过胜任感和成就感来获得满足，如音乐家创作出天籁之音，作家写出万古流芳的作品，诗人吟唱出脍炙人口的诗篇，这些都是借以达到自我实现的途径。  \n  注重自我实现需要的管理者会激励员工们进行工作设计，发挥一技之长，或者给予班组以自由安排工作任务的权力。\n\n\n马斯洛需要层次理论\n\n---\n\n2. 人的需要分等分层，像阶梯一样逐渐上升\n\n马斯洛认为，人的五个层次的需要是由低向高排列的。  \n一般来说，只有在低层次的需要满足之后，人才会进一步追求较高层次的需要，而且低层次需要满足的程度越高，对高层次需要的追求就越强烈。  \n马斯洛将五种需要划分为高、低两级。  \n生理需要和安全需要属于低级需要，这些需要通过外部条件使人满足，如借助于工资收入满足生理需要，借助于法律制度满足安全需要等。  \n社交需要、尊重需要和自我实现需要是高级需要，它是从内部使人得到满足的，而且一个人对这些高级需要是永远不会感到完全满足的。  \n因此通过满足员工的高级需要来调动工作积极性，具有更稳定、更持久的力量。  \n人在不同的发展阶段，其需求结构也不同。一般来说，在同一时期内，人们可以同时存在几种需要，但总有一种需要占支配地位，它决定着人们行为的方向。\n\n---\n\n3. 未被满足的需求才有激励作用\n\n需要是促使人产生某种动机的内在基础。  \n当一个人一无所求时，也就没有什么动力与活力；反之，若一个人有所需求，就必然存在着激励因素。  \n五个层次的需要是人生来就有的，但每一个人的需求强度、暴露程度可能不同，它由生物的、文化的、环境的因素共同决定。  \n另外，当某种需要得到满足之后，这种需求也就失去了对行为的唤起作用，下一层次的尚未满足的需求就会成为人们行为的动力。  \n高层次的需要，不仅内容比低层次需要更广泛，实现难度也更大。  \n**马斯洛1943年曾经指出，85%的生理需要和70%的安全需要一般会得到满足，但只有50%的社交需要、40%尊重需要和10%的自我实现需要能得到满足。**\n\n---\n\n### 2. 需要层次理论在企业管理中的应用\n\n马斯洛的需要层次理论第一次系统地阐述了人的需要与行为之间的关系，在现代企业管理中具有广泛的应用价值。  \n下表列出了不同层次需要对应的追求目标及相应的管理措施。\n\n\n需要层次理论与管理措施相关表\n\n从【需要层次理论与管理措施相关表】可以看出，管理者可以根据五种需要层次对员工的多种需要加以归类和确认，然后了解员工未满足的或正在追求的需要是什么，采取相应的管理制度与措施进行激励，既不能落后，又不能超前于员工的需求状况。\n\n**这就是说，当员工的低层次需要未得到满足时，不要奢望他们有更高的献身精神，应把解决他们的衣食住行问题放在首位；而当员工的低层次需要被满足了时，又不能一味地停留于物质奖励的办法来刺激他们，应该创设更好的工作和人际环境，来满足他们更高层次的需要。**\n\n在某种程度上说，一个企业或组织员工需求层次的高低，应作为企业或组织管理成败的重要标志之一。员工需求层次愈高，说明这个企业的管理愈成功，反之亦然。\n\n---\n\n### 3. 对需要层次理论的评价\n\n西方管理心理学对马斯洛的需要层次理论的评价各不相同。总的来说，既重视这一理论，又指出了这一理论的不足之处。\n\n一方面，马斯洛的需要层次论有其科学性的一面。  \n第一，马斯洛对人类的需要进行系统研究，把千差万别的人类需要归纳为五个层次，并就五个层次需要的内容和层次间的关系作了详细阐述，这与以往心理学所进行的零散、不系统的研究相比无疑是前进了一步。因此需要层次论对心理学的需要动机理论发展是一个重要的贡献。  \n第二，马斯洛提出的需要层次性和需要由低级向高级发展的趋向，在某种程度上是符合人类需要发展的一般规律的。一个人从出生到成年，其需要的发展基本上是按照马斯洛提出的需要层次进行的。  \n第三，马斯洛的需要理论为企业管理指出了调动积极性的工作方向和内容。例如，任何企业都应该从物质和精神两方面去满足员工的合理需要，同时要根据不同员工不同的需要层次，针对性地采取不同的管理措施。\n\n另一方面，马斯洛的需要层次论也有局限性和不足之处。  \n第一，马斯洛的需要理论绝大部分谈的是人的自然需要，忽视了社会存在对人的成长所具有的影响。马斯洛认为人的需要都是本能的活动，都是生而具有的。人有生理需要是为了维持自己的生存；人有安全需要是出于“趋利避害”的本能；人有社交需要是为了自己享受生活的乐趣；人有尊重和自我实现的需要是为了自己能出人头地，高高在上。这样就完全否定了社会存在对人的成长的决定性影响，宣扬个人主义的实质非常明显。  \n二是，马斯洛的需要层次论带有一定的机械主义色彩。把人的需要层次看成固定的程序，认为只有满足了低一级的需要层次之后，才能进入下一层次的需要，这显然是机械的。它忽视了人的主观能动性，忽视了高层次需要有对低层次需要影响的一面，忽视了为了崇高理想，人可以忍受物质生活困难带来痛苦，甚至牺牲宝贵生命的事实。\n\n\n\n[马斯洛需求层次理论](https://www.zhihu.com/topic/19904710)\n\n[管理心理学](https://www.zhihu.com/topic/20010089)\n\n[企业管理](https://www.zhihu.com/topic/19559804)\n\n","slug":"needsHierarchy","published":1,"date":"2024-08-25T09:13:15.503Z","updated":"2024-08-25T09:13:15.503Z","comments":1,"layout":"post","photos":[],"_id":"cm0admg6w000154uia42326wb","content":"<p><img src=\"https://pic1.zhimg.com/70/v2-0d3a66ebd920914936c396c4ce1a0d4b_1440w.image?source=172ae18b&biz_tag=Post\" alt=\"马斯洛“需要层次理论”\"></p>\n<h1 id=\"马斯洛“需要层次理论”\"><a href=\"#马斯洛“需要层次理论”\" class=\"headerlink\" title=\"马斯洛“需要层次理论”\"></a>马斯洛“需要层次理论”</h1><p>人类要思考如何慢下来</p>\n<p>需要层次理论是由<strong>美国心理学家马斯洛在1943年所著的《人的行为动机》一书中提出</strong>来的，在世界上广为流传，成为应用最普遍、最主要的激励理论之一。</p>\n<h3 id=\"1-需要层次理论的基本内容\"><a href=\"#1-需要层次理论的基本内容\" class=\"headerlink\" title=\"1. 需要层次理论的基本内容\"></a>1. 需要层次理论的基本内容</h3><p>马斯洛的需要层次理论主要有以下三个观点。</p>\n<hr>\n<ol>\n<li>人的多种需要分为5个层级</li>\n</ol>\n<p>马斯洛认为，需要是人类行为的积极的动因或源泉。需要引起动机，动机驱动行为。<br>因此弄清了人类的基本需求结构或层次，就能很好地说明、解释、预测和控制人类的行为。<br>他按照<strong>由低级到高级的顺序将人的需要分为五个层次：生理需要、安全需要、社交需要、尊重需要、自我实现需要。</strong></p>\n<ul>\n<li><p><strong>生理需要是人类维持其生命和生存最基本的需要，也是需要层次的基础，包括对食物、水、性以及避免寒冷或炎热的需要等。</strong><br>对于缺乏这类东西的人来说，其主要的行为动机受生理需要支配。<br>例如，一个极端饥饿的人，将会把全部的精力用在觅食活动上，对他来说有食物的地方是最理想的去处。<br>马斯洛曾说“一个人如果同时缺少食物、安全、爱情和被尊重等，则食物的渴求可能最为强烈。”<br>生理需要是人类最低层次的需要。一旦这种需要被满足，人们开始最求最高层次的需要。</p>\n</li>\n<li><p><strong>安全需要是指对避免危险、威胁和剥夺的需要。</strong><br><strong>最常见的安全需要之一，就是保护个人免受肉体上的危险</strong>，如火灾或事故等。<br>在工业部门，常见到这类标牌“此区禁止吸烟”“超过此处必须佩戴护目镜”等，也是管理者为满足安全需要所做的一种努力。<br><strong>第二种安全需要是经济保障。</strong><br>员工的各种福利待遇，如事故保险、健康保险以及人寿保险等，均有助于满足这类需要。<br><strong>第三种安全需要是对有秩序的、可预知环境的需要。</strong><br>安全需要的含义很广泛，从世界和平、社会安定直至个人的安全等都属于安全需要的范畴。安全需要是人类安居乐业的基本保证。</p>\n</li>\n<li><p><strong>社交需要是指个人对爱、情感和归属的需要，</strong>主要包括两方面内容。<br><strong>一是爱的需要</strong>，即人都希望伙伴之间、同事之间关系融洽，保持友谊和忠诚，希望得到甜美而忠贞的爱情，希望爱别人，也渴望得到别人的爱。<br><strong>二是归属的需要</strong>，即个体都有一种要求归属于一个集团或群体的感情，希望成为其中的一员并得到相互关心和照顾。<br>组织管理者应该认识到，当社交需要成为主要的激励来源时，员工会把工作视为寻求建立温馨、友善、和谐人际关系的机会。</p>\n</li>\n<li><p><strong>尊重需要是指个体希望获得成就感以及得到他人对自身价值的承认与尊重。</strong><br>尊重需要分为两类：<strong>一类是希望有实力、有成就、能胜任、有信息以及要求独立和自由；另一类是要求能使对自己充满信心，对社会满腔热情，体会到自己生活在世界上的用处和价值，</strong>但尊重需要一旦受到挫折，就会使人产生自卑感、软弱感、无能感，从而使人失去生活的基本信心。<br>关注员工尊重需要的管理者一般会通过公开奖励以承认其工作业绩等方式激励员工。这类管理者会采用在公司报刊上撰写文章或在公报栏里发布消息等方式对员工的良好表现进行表扬。当然，也有部分员工不喜欢公开表扬而宁愿私下被肯定成绩。</p>\n</li>\n<li><p><strong>自我实现需要是人的最高层次的精神需要。</strong>它是指发挥自我内在潜力，实现自己理想和抱负的需要。<br>产生这种需要的人决心发挥自己最大的能力完成难度较大的工作任务，成就一番事业，努力使自己成为理想的人。<br>这种需要往往是通过胜任感和成就感来获得满足，如音乐家创作出天籁之音，作家写出万古流芳的作品，诗人吟唱出脍炙人口的诗篇，这些都是借以达到自我实现的途径。<br>注重自我实现需要的管理者会激励员工们进行工作设计，发挥一技之长，或者给予班组以自由安排工作任务的权力。</p>\n</li>\n</ul>\n<p>马斯洛需要层次理论</p>\n<hr>\n<ol start=\"2\">\n<li>人的需要分等分层，像阶梯一样逐渐上升</li>\n</ol>\n<p>马斯洛认为，人的五个层次的需要是由低向高排列的。<br>一般来说，只有在低层次的需要满足之后，人才会进一步追求较高层次的需要，而且低层次需要满足的程度越高，对高层次需要的追求就越强烈。<br>马斯洛将五种需要划分为高、低两级。<br>生理需要和安全需要属于低级需要，这些需要通过外部条件使人满足，如借助于工资收入满足生理需要，借助于法律制度满足安全需要等。<br>社交需要、尊重需要和自我实现需要是高级需要，它是从内部使人得到满足的，而且一个人对这些高级需要是永远不会感到完全满足的。<br>因此通过满足员工的高级需要来调动工作积极性，具有更稳定、更持久的力量。<br>人在不同的发展阶段，其需求结构也不同。一般来说，在同一时期内，人们可以同时存在几种需要，但总有一种需要占支配地位，它决定着人们行为的方向。</p>\n<hr>\n<ol start=\"3\">\n<li>未被满足的需求才有激励作用</li>\n</ol>\n<p>需要是促使人产生某种动机的内在基础。<br>当一个人一无所求时，也就没有什么动力与活力；反之，若一个人有所需求，就必然存在着激励因素。<br>五个层次的需要是人生来就有的，但每一个人的需求强度、暴露程度可能不同，它由生物的、文化的、环境的因素共同决定。<br>另外，当某种需要得到满足之后，这种需求也就失去了对行为的唤起作用，下一层次的尚未满足的需求就会成为人们行为的动力。<br>高层次的需要，不仅内容比低层次需要更广泛，实现难度也更大。<br><strong>马斯洛1943年曾经指出，85%的生理需要和70%的安全需要一般会得到满足，但只有50%的社交需要、40%尊重需要和10%的自我实现需要能得到满足。</strong></p>\n<hr>\n<h3 id=\"2-需要层次理论在企业管理中的应用\"><a href=\"#2-需要层次理论在企业管理中的应用\" class=\"headerlink\" title=\"2. 需要层次理论在企业管理中的应用\"></a>2. 需要层次理论在企业管理中的应用</h3><p>马斯洛的需要层次理论第一次系统地阐述了人的需要与行为之间的关系，在现代企业管理中具有广泛的应用价值。<br>下表列出了不同层次需要对应的追求目标及相应的管理措施。</p>\n<p>需要层次理论与管理措施相关表</p>\n<p>从【需要层次理论与管理措施相关表】可以看出，管理者可以根据五种需要层次对员工的多种需要加以归类和确认，然后了解员工未满足的或正在追求的需要是什么，采取相应的管理制度与措施进行激励，既不能落后，又不能超前于员工的需求状况。</p>\n<p><strong>这就是说，当员工的低层次需要未得到满足时，不要奢望他们有更高的献身精神，应把解决他们的衣食住行问题放在首位；而当员工的低层次需要被满足了时，又不能一味地停留于物质奖励的办法来刺激他们，应该创设更好的工作和人际环境，来满足他们更高层次的需要。</strong></p>\n<p>在某种程度上说，一个企业或组织员工需求层次的高低，应作为企业或组织管理成败的重要标志之一。员工需求层次愈高，说明这个企业的管理愈成功，反之亦然。</p>\n<hr>\n<h3 id=\"3-对需要层次理论的评价\"><a href=\"#3-对需要层次理论的评价\" class=\"headerlink\" title=\"3. 对需要层次理论的评价\"></a>3. 对需要层次理论的评价</h3><p>西方管理心理学对马斯洛的需要层次理论的评价各不相同。总的来说，既重视这一理论，又指出了这一理论的不足之处。</p>\n<p>一方面，马斯洛的需要层次论有其科学性的一面。<br>第一，马斯洛对人类的需要进行系统研究，把千差万别的人类需要归纳为五个层次，并就五个层次需要的内容和层次间的关系作了详细阐述，这与以往心理学所进行的零散、不系统的研究相比无疑是前进了一步。因此需要层次论对心理学的需要动机理论发展是一个重要的贡献。<br>第二，马斯洛提出的需要层次性和需要由低级向高级发展的趋向，在某种程度上是符合人类需要发展的一般规律的。一个人从出生到成年，其需要的发展基本上是按照马斯洛提出的需要层次进行的。<br>第三，马斯洛的需要理论为企业管理指出了调动积极性的工作方向和内容。例如，任何企业都应该从物质和精神两方面去满足员工的合理需要，同时要根据不同员工不同的需要层次，针对性地采取不同的管理措施。</p>\n<p>另一方面，马斯洛的需要层次论也有局限性和不足之处。<br>第一，马斯洛的需要理论绝大部分谈的是人的自然需要，忽视了社会存在对人的成长所具有的影响。马斯洛认为人的需要都是本能的活动，都是生而具有的。人有生理需要是为了维持自己的生存；人有安全需要是出于“趋利避害”的本能；人有社交需要是为了自己享受生活的乐趣；人有尊重和自我实现的需要是为了自己能出人头地，高高在上。这样就完全否定了社会存在对人的成长的决定性影响，宣扬个人主义的实质非常明显。<br>二是，马斯洛的需要层次论带有一定的机械主义色彩。把人的需要层次看成固定的程序，认为只有满足了低一级的需要层次之后，才能进入下一层次的需要，这显然是机械的。它忽视了人的主观能动性，忽视了高层次需要有对低层次需要影响的一面，忽视了为了崇高理想，人可以忍受物质生活困难带来痛苦，甚至牺牲宝贵生命的事实。</p>\n<p><a href=\"https://www.zhihu.com/topic/19904710\">马斯洛需求层次理论</a></p>\n<p><a href=\"https://www.zhihu.com/topic/20010089\">管理心理学</a></p>\n<p><a href=\"https://www.zhihu.com/topic/19559804\">企业管理</a></p>\n","excerpt":"","more":"<p><img src=\"https://pic1.zhimg.com/70/v2-0d3a66ebd920914936c396c4ce1a0d4b_1440w.image?source=172ae18b&biz_tag=Post\" alt=\"马斯洛“需要层次理论”\"></p>\n<h1 id=\"马斯洛“需要层次理论”\"><a href=\"#马斯洛“需要层次理论”\" class=\"headerlink\" title=\"马斯洛“需要层次理论”\"></a>马斯洛“需要层次理论”</h1><p>人类要思考如何慢下来</p>\n<p>需要层次理论是由<strong>美国心理学家马斯洛在1943年所著的《人的行为动机》一书中提出</strong>来的，在世界上广为流传，成为应用最普遍、最主要的激励理论之一。</p>\n<h3 id=\"1-需要层次理论的基本内容\"><a href=\"#1-需要层次理论的基本内容\" class=\"headerlink\" title=\"1. 需要层次理论的基本内容\"></a>1. 需要层次理论的基本内容</h3><p>马斯洛的需要层次理论主要有以下三个观点。</p>\n<hr>\n<ol>\n<li>人的多种需要分为5个层级</li>\n</ol>\n<p>马斯洛认为，需要是人类行为的积极的动因或源泉。需要引起动机，动机驱动行为。<br>因此弄清了人类的基本需求结构或层次，就能很好地说明、解释、预测和控制人类的行为。<br>他按照<strong>由低级到高级的顺序将人的需要分为五个层次：生理需要、安全需要、社交需要、尊重需要、自我实现需要。</strong></p>\n<ul>\n<li><p><strong>生理需要是人类维持其生命和生存最基本的需要，也是需要层次的基础，包括对食物、水、性以及避免寒冷或炎热的需要等。</strong><br>对于缺乏这类东西的人来说，其主要的行为动机受生理需要支配。<br>例如，一个极端饥饿的人，将会把全部的精力用在觅食活动上，对他来说有食物的地方是最理想的去处。<br>马斯洛曾说“一个人如果同时缺少食物、安全、爱情和被尊重等，则食物的渴求可能最为强烈。”<br>生理需要是人类最低层次的需要。一旦这种需要被满足，人们开始最求最高层次的需要。</p>\n</li>\n<li><p><strong>安全需要是指对避免危险、威胁和剥夺的需要。</strong><br><strong>最常见的安全需要之一，就是保护个人免受肉体上的危险</strong>，如火灾或事故等。<br>在工业部门，常见到这类标牌“此区禁止吸烟”“超过此处必须佩戴护目镜”等，也是管理者为满足安全需要所做的一种努力。<br><strong>第二种安全需要是经济保障。</strong><br>员工的各种福利待遇，如事故保险、健康保险以及人寿保险等，均有助于满足这类需要。<br><strong>第三种安全需要是对有秩序的、可预知环境的需要。</strong><br>安全需要的含义很广泛，从世界和平、社会安定直至个人的安全等都属于安全需要的范畴。安全需要是人类安居乐业的基本保证。</p>\n</li>\n<li><p><strong>社交需要是指个人对爱、情感和归属的需要，</strong>主要包括两方面内容。<br><strong>一是爱的需要</strong>，即人都希望伙伴之间、同事之间关系融洽，保持友谊和忠诚，希望得到甜美而忠贞的爱情，希望爱别人，也渴望得到别人的爱。<br><strong>二是归属的需要</strong>，即个体都有一种要求归属于一个集团或群体的感情，希望成为其中的一员并得到相互关心和照顾。<br>组织管理者应该认识到，当社交需要成为主要的激励来源时，员工会把工作视为寻求建立温馨、友善、和谐人际关系的机会。</p>\n</li>\n<li><p><strong>尊重需要是指个体希望获得成就感以及得到他人对自身价值的承认与尊重。</strong><br>尊重需要分为两类：<strong>一类是希望有实力、有成就、能胜任、有信息以及要求独立和自由；另一类是要求能使对自己充满信心，对社会满腔热情，体会到自己生活在世界上的用处和价值，</strong>但尊重需要一旦受到挫折，就会使人产生自卑感、软弱感、无能感，从而使人失去生活的基本信心。<br>关注员工尊重需要的管理者一般会通过公开奖励以承认其工作业绩等方式激励员工。这类管理者会采用在公司报刊上撰写文章或在公报栏里发布消息等方式对员工的良好表现进行表扬。当然，也有部分员工不喜欢公开表扬而宁愿私下被肯定成绩。</p>\n</li>\n<li><p><strong>自我实现需要是人的最高层次的精神需要。</strong>它是指发挥自我内在潜力，实现自己理想和抱负的需要。<br>产生这种需要的人决心发挥自己最大的能力完成难度较大的工作任务，成就一番事业，努力使自己成为理想的人。<br>这种需要往往是通过胜任感和成就感来获得满足，如音乐家创作出天籁之音，作家写出万古流芳的作品，诗人吟唱出脍炙人口的诗篇，这些都是借以达到自我实现的途径。<br>注重自我实现需要的管理者会激励员工们进行工作设计，发挥一技之长，或者给予班组以自由安排工作任务的权力。</p>\n</li>\n</ul>\n<p>马斯洛需要层次理论</p>\n<hr>\n<ol start=\"2\">\n<li>人的需要分等分层，像阶梯一样逐渐上升</li>\n</ol>\n<p>马斯洛认为，人的五个层次的需要是由低向高排列的。<br>一般来说，只有在低层次的需要满足之后，人才会进一步追求较高层次的需要，而且低层次需要满足的程度越高，对高层次需要的追求就越强烈。<br>马斯洛将五种需要划分为高、低两级。<br>生理需要和安全需要属于低级需要，这些需要通过外部条件使人满足，如借助于工资收入满足生理需要，借助于法律制度满足安全需要等。<br>社交需要、尊重需要和自我实现需要是高级需要，它是从内部使人得到满足的，而且一个人对这些高级需要是永远不会感到完全满足的。<br>因此通过满足员工的高级需要来调动工作积极性，具有更稳定、更持久的力量。<br>人在不同的发展阶段，其需求结构也不同。一般来说，在同一时期内，人们可以同时存在几种需要，但总有一种需要占支配地位，它决定着人们行为的方向。</p>\n<hr>\n<ol start=\"3\">\n<li>未被满足的需求才有激励作用</li>\n</ol>\n<p>需要是促使人产生某种动机的内在基础。<br>当一个人一无所求时，也就没有什么动力与活力；反之，若一个人有所需求，就必然存在着激励因素。<br>五个层次的需要是人生来就有的，但每一个人的需求强度、暴露程度可能不同，它由生物的、文化的、环境的因素共同决定。<br>另外，当某种需要得到满足之后，这种需求也就失去了对行为的唤起作用，下一层次的尚未满足的需求就会成为人们行为的动力。<br>高层次的需要，不仅内容比低层次需要更广泛，实现难度也更大。<br><strong>马斯洛1943年曾经指出，85%的生理需要和70%的安全需要一般会得到满足，但只有50%的社交需要、40%尊重需要和10%的自我实现需要能得到满足。</strong></p>\n<hr>\n<h3 id=\"2-需要层次理论在企业管理中的应用\"><a href=\"#2-需要层次理论在企业管理中的应用\" class=\"headerlink\" title=\"2. 需要层次理论在企业管理中的应用\"></a>2. 需要层次理论在企业管理中的应用</h3><p>马斯洛的需要层次理论第一次系统地阐述了人的需要与行为之间的关系，在现代企业管理中具有广泛的应用价值。<br>下表列出了不同层次需要对应的追求目标及相应的管理措施。</p>\n<p>需要层次理论与管理措施相关表</p>\n<p>从【需要层次理论与管理措施相关表】可以看出，管理者可以根据五种需要层次对员工的多种需要加以归类和确认，然后了解员工未满足的或正在追求的需要是什么，采取相应的管理制度与措施进行激励，既不能落后，又不能超前于员工的需求状况。</p>\n<p><strong>这就是说，当员工的低层次需要未得到满足时，不要奢望他们有更高的献身精神，应把解决他们的衣食住行问题放在首位；而当员工的低层次需要被满足了时，又不能一味地停留于物质奖励的办法来刺激他们，应该创设更好的工作和人际环境，来满足他们更高层次的需要。</strong></p>\n<p>在某种程度上说，一个企业或组织员工需求层次的高低，应作为企业或组织管理成败的重要标志之一。员工需求层次愈高，说明这个企业的管理愈成功，反之亦然。</p>\n<hr>\n<h3 id=\"3-对需要层次理论的评价\"><a href=\"#3-对需要层次理论的评价\" class=\"headerlink\" title=\"3. 对需要层次理论的评价\"></a>3. 对需要层次理论的评价</h3><p>西方管理心理学对马斯洛的需要层次理论的评价各不相同。总的来说，既重视这一理论，又指出了这一理论的不足之处。</p>\n<p>一方面，马斯洛的需要层次论有其科学性的一面。<br>第一，马斯洛对人类的需要进行系统研究，把千差万别的人类需要归纳为五个层次，并就五个层次需要的内容和层次间的关系作了详细阐述，这与以往心理学所进行的零散、不系统的研究相比无疑是前进了一步。因此需要层次论对心理学的需要动机理论发展是一个重要的贡献。<br>第二，马斯洛提出的需要层次性和需要由低级向高级发展的趋向，在某种程度上是符合人类需要发展的一般规律的。一个人从出生到成年，其需要的发展基本上是按照马斯洛提出的需要层次进行的。<br>第三，马斯洛的需要理论为企业管理指出了调动积极性的工作方向和内容。例如，任何企业都应该从物质和精神两方面去满足员工的合理需要，同时要根据不同员工不同的需要层次，针对性地采取不同的管理措施。</p>\n<p>另一方面，马斯洛的需要层次论也有局限性和不足之处。<br>第一，马斯洛的需要理论绝大部分谈的是人的自然需要，忽视了社会存在对人的成长所具有的影响。马斯洛认为人的需要都是本能的活动，都是生而具有的。人有生理需要是为了维持自己的生存；人有安全需要是出于“趋利避害”的本能；人有社交需要是为了自己享受生活的乐趣；人有尊重和自我实现的需要是为了自己能出人头地，高高在上。这样就完全否定了社会存在对人的成长的决定性影响，宣扬个人主义的实质非常明显。<br>二是，马斯洛的需要层次论带有一定的机械主义色彩。把人的需要层次看成固定的程序，认为只有满足了低一级的需要层次之后，才能进入下一层次的需要，这显然是机械的。它忽视了人的主观能动性，忽视了高层次需要有对低层次需要影响的一面，忽视了为了崇高理想，人可以忍受物质生活困难带来痛苦，甚至牺牲宝贵生命的事实。</p>\n<p><a href=\"https://www.zhihu.com/topic/19904710\">马斯洛需求层次理论</a></p>\n<p><a href=\"https://www.zhihu.com/topic/20010089\">管理心理学</a></p>\n<p><a href=\"https://www.zhihu.com/topic/19559804\">企业管理</a></p>\n"},{"title":"使用docker和streamlit阿里云服务器部署简单的演示网页","_content":"\n# 使用docker和streamlit阿里云服务器部署简单的演示网页\n\n这是一篇尽可能新手向的文章，适合首次购买阿里云服务器，想要建一个简单的，用于演示网站的用户，比如深度学习/数据的交互式页面。不需要你有什么web开发经验，一步一步跟着搭建就好。我自己前后折腾了两天，写下这篇文章以免其他人绕弯路。\n\n> 不用学前端编程，你就能用 Python 简单高效写出漂亮的交互式 Web 应用，将你的数据分析成果立即展示给团队和客户。\n\n## 最终效果[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C \"Permanent link\")\n\n一个网站（ip地址）： [http://47.115.79.16:8501](http://47.115.79.16:8501/)\n\n![picture 12](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-46-47.png)\n\n> 如果你购买了域名并且备案成功-国内需要，你就可以用域名来访问这个ip网址了，域名以及解析不在本文讨论范围内，可以上网自查，也不难\n\n## 为了实现这个效果，你需要？[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%BA%E4%BA%86%E5%AE%9E%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%95%88%E6%9E%9C%E4%BD%A0%E9%9C%80%E8%A6%81 \"Permanent link\")\n\n- **一点钱**：购买一台最低配置的阿里云服务器，参考价格：16￥/周；50￥/月；500￥/年。本文为了演示，买了一台最最便宜的，只花了16元。\n- **一点docker知识**：不过不用担心，照着本文依样画葫芦也可以。如果你想学习docker，推荐：[docker从入门到实践](https://yeasy.gitbook.io/)\n- **一点时间**：半小时到5小时不等，取决于你想学到什么程度\n- ssh客户端（xshell/vscode之类），连接服务器的时候用。（不会也没问题，可以用阿里云的网页连接服务器终端）\n\n> 为什么使用docker？\n>\n> 方便部署，不需要在每一台新的服务器上都折腾很久。搞定这个你也可以用相同的方法弄flask、django的部署\n>\n> 为什么使用streamlit？\n>\n> flask和django无疑更好，但加上前端的知识，学习成本较高，但我的目标只是搭建一个简单的交互页面，streamlit足够了而且非常简单\n\n## 开始干吧！[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%BC%80%E5%A7%8B%E5%B9%B2%E5%90%A7 \"Permanent link\")\n\n### 一、购买阿里云服务器[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%80%E8%B4%AD%E4%B9%B0%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8 \"Permanent link\")\n\n1. 访问[阿里云官网](https://www.aliyun.com/)，选择`云服务器ECS`，在跳转后的页面中选择`立即购买`  \n   ![picture 1](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_02-14-17.png)\n\n   > 你会看到很多其他类型的服务器，适用场景不同。\n   > 1. ECS(Elastic Compute Service)服务器可以简单理解为“弹性”服务器，也就是随时可以根据你的需求提高/降低电脑的配置，比如CPU更强，内存更大，更多服务器。\n   > 2. 轻量应用服务器：适合建立轻量的网站，配置也很简单。不过我个人希望自由度高一些，就没有用这个了。\n\n2. 本文为了方便起见，**选择**`一键购买`，然后基本上按默认配置购买即可。注意点：服务器选最低配的（够用了），镜像那里选`ubuntu 18.04`，本文仅供演示，购买时长只选了一周（16元），付款搞定\n\n   > 如果你对服务器比较熟悉或者能折腾想学习，可以选择`自定义购买`，稍微费点时间\n\n\n> 镜像的说明：ubuntu其他版本也可以，ubuntu用的人比较多，centos 和 aliyun linux（基于centos）也可以，后两者商用多一些。\n\n![picture 2](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-03-37.png)\n\n![picture 3](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-14-20.png)\n\n### 二、配置服务器[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%8C%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8 \"Permanent link\")\n\n由于我们刚才选的是`一键购买`，省略了一点配置，现在需要补上。做好心理准备，阿里云控制台有些复杂，我第一次用也很懵逼。如果你之前用`自定义购买`，下面可以跳过（记得开启80端口），不过你终究还是要熟悉控制台页面的，也可以看一下。\n\n1. 回到[阿里云官网](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/aliyun.com)，登录后在页面右上角有`控制台`按钮\n2. 进入控制台后，选择左上角的符号，展开选择`云服务器ECS`  \n   ![picture 4](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-21-31.png)\n3. 仿照图片，选择`实例`，在实例`更多`那里选择`重置密码`，之后我们要用这个密码，通过ssh连接服务器  \n   ![picture 6](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-27-08.png)\n\n   > 有更加安全的连接服务器的方式，你可以在阿里云的帮助文档中看到\n\n4. 仿照下面几张图片，我们要修改安全组配置，加入80端口（http端口），以便之后能够访问网页  \n   ![picture 7](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-30-11.png)  \n   ![picture 8](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-10.png)  \n   选择快速添加（手动添加也差不多），这里我顺带把443https端口也开了  \n   ![picture 9](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-52.png)\n\n### 三、ssh连接服务器[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%89ssh%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8 \"Permanent link\")\n\n实例列表那里有公网ip，复制一下，我的是：`101.37.146.225`  \n![picture 10](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-37-04.png)  \n然后找一个ssh客户端（xshell/vscode），通过`ssh root@101.37.146.225`连接阿里云服务器，你也可以使用阿里云提供的其他连接方式（在实例页面选择`远程连接`）\n\n### 四、安装docker[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%9B%9B%E5%AE%89%E8%A3%85docker \"Permanent link\")\n\n> 你也完全可以不使用docker，在服务器上安装python环境和streamlint就可以了，不过docker可以简化这个流程\n\n在阿里云服务器的终端中输入以下指令\n\n`apt update # 必须先update，才能安装软件 curl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun # mirror是镜像，为了加速`\n\n> 正常来讲为了权限控制，还需要创建一个docker用户，不过这里为了方便省略掉了\n\n### 五、使用docker创建streamlit镜像并部署[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%94%E4%BD%BF%E7%94%A8docker%E5%88%9B%E5%BB%BAstreamlit%E9%95%9C%E5%83%8F%E5%B9%B6%E9%83%A8%E7%BD%B2 \"Permanent link\")\n\n> 这是一个简单的演示，并非是使用docker的最佳实践\n\n创建一个文件夹，创建Dockerfile，内容为（注释可以删掉）\n\n`# 从python3.6镜像基础上创建 FROM python:3.6 # 设置镜像源，提高pip install 速度 RUN pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ \\         && pip install streamlit # streamlit hello创建一个演示页面，映射80端口以便网页访问 CMD [\"streamlit\",\"hello\", \"--server.port\",\"80\"]`\n\n\n然后执行`docker build -t streamlit .` （注意结尾有一个`.`符号），耐心等待一段时间\n\n> 这个指令用于创建一个streamlit的镜像（docker术语），`-t streamlit`指定了这个镜像的名字，最后一个`.`表示构建的上下文路径\n\n然后使用streamlit镜像创建容器，运行streamlit\n\n`docker run -p 80:80 streamlit`\n\n\n然后它会提示你`External URL: http://101.37.146.225:80`，由于80是http的默认端口，所以你在浏览器中直接输入`101.37.146.225`就可以了（换成你的阿里云公网ip地址）\n\n> 本文最后将streamlit部署在另一个服务器的8501端口了，所以应当访问这个：[http://47.115.79.16:8501](http://47.115.79.16:8501/)  \n> Done!! 搞定！你可以在网址中愉快地玩耍了  \n> ![picture 11](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-33-45.png)\n\n### 六、下一步[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%85%AD%E4%B8%8B%E4%B8%80%E6%AD%A5 \"Permanent link\")\n\n1. 学习docker和streamlit创建更好玩的网站！学习资料在此\n    - [docker从入门到实践](https://yeasy.gitbook.io/)\n    - streamlit：[王树义老师的教程](https://sspai.com/post/58474)或者[streamlit官网](https://www.streamlit.io/)\n    - [使用nginx优化部署](https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561)\n2. 购买域名并将域名指向这个服务器，方便你的同学、老师、客户查看\n\n## 参考资料[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99 \"Permanent link\")\n\n1. [docker部署一个超简单的flask应用](https://zhuanlan.zhihu.com/p/78432719)\n2. [docker+streamlit展示spacy命名实体识别功能](https://maelfabien.github.io/project/Streamlit/)\n3. [在AWS上用docker+nginx部署streamlit](https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561)","source":"_posts/presentation.md","raw":"---\ntitle: 使用docker和streamlit阿里云服务器部署简单的演示网页\n---\n\n# 使用docker和streamlit阿里云服务器部署简单的演示网页\n\n这是一篇尽可能新手向的文章，适合首次购买阿里云服务器，想要建一个简单的，用于演示网站的用户，比如深度学习/数据的交互式页面。不需要你有什么web开发经验，一步一步跟着搭建就好。我自己前后折腾了两天，写下这篇文章以免其他人绕弯路。\n\n> 不用学前端编程，你就能用 Python 简单高效写出漂亮的交互式 Web 应用，将你的数据分析成果立即展示给团队和客户。\n\n## 最终效果[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C \"Permanent link\")\n\n一个网站（ip地址）： [http://47.115.79.16:8501](http://47.115.79.16:8501/)\n\n![picture 12](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-46-47.png)\n\n> 如果你购买了域名并且备案成功-国内需要，你就可以用域名来访问这个ip网址了，域名以及解析不在本文讨论范围内，可以上网自查，也不难\n\n## 为了实现这个效果，你需要？[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%BA%E4%BA%86%E5%AE%9E%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%95%88%E6%9E%9C%E4%BD%A0%E9%9C%80%E8%A6%81 \"Permanent link\")\n\n- **一点钱**：购买一台最低配置的阿里云服务器，参考价格：16￥/周；50￥/月；500￥/年。本文为了演示，买了一台最最便宜的，只花了16元。\n- **一点docker知识**：不过不用担心，照着本文依样画葫芦也可以。如果你想学习docker，推荐：[docker从入门到实践](https://yeasy.gitbook.io/)\n- **一点时间**：半小时到5小时不等，取决于你想学到什么程度\n- ssh客户端（xshell/vscode之类），连接服务器的时候用。（不会也没问题，可以用阿里云的网页连接服务器终端）\n\n> 为什么使用docker？\n>\n> 方便部署，不需要在每一台新的服务器上都折腾很久。搞定这个你也可以用相同的方法弄flask、django的部署\n>\n> 为什么使用streamlit？\n>\n> flask和django无疑更好，但加上前端的知识，学习成本较高，但我的目标只是搭建一个简单的交互页面，streamlit足够了而且非常简单\n\n## 开始干吧！[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%BC%80%E5%A7%8B%E5%B9%B2%E5%90%A7 \"Permanent link\")\n\n### 一、购买阿里云服务器[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%80%E8%B4%AD%E4%B9%B0%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8 \"Permanent link\")\n\n1. 访问[阿里云官网](https://www.aliyun.com/)，选择`云服务器ECS`，在跳转后的页面中选择`立即购买`  \n   ![picture 1](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_02-14-17.png)\n\n   > 你会看到很多其他类型的服务器，适用场景不同。\n   > 1. ECS(Elastic Compute Service)服务器可以简单理解为“弹性”服务器，也就是随时可以根据你的需求提高/降低电脑的配置，比如CPU更强，内存更大，更多服务器。\n   > 2. 轻量应用服务器：适合建立轻量的网站，配置也很简单。不过我个人希望自由度高一些，就没有用这个了。\n\n2. 本文为了方便起见，**选择**`一键购买`，然后基本上按默认配置购买即可。注意点：服务器选最低配的（够用了），镜像那里选`ubuntu 18.04`，本文仅供演示，购买时长只选了一周（16元），付款搞定\n\n   > 如果你对服务器比较熟悉或者能折腾想学习，可以选择`自定义购买`，稍微费点时间\n\n\n> 镜像的说明：ubuntu其他版本也可以，ubuntu用的人比较多，centos 和 aliyun linux（基于centos）也可以，后两者商用多一些。\n\n![picture 2](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-03-37.png)\n\n![picture 3](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-14-20.png)\n\n### 二、配置服务器[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%8C%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8 \"Permanent link\")\n\n由于我们刚才选的是`一键购买`，省略了一点配置，现在需要补上。做好心理准备，阿里云控制台有些复杂，我第一次用也很懵逼。如果你之前用`自定义购买`，下面可以跳过（记得开启80端口），不过你终究还是要熟悉控制台页面的，也可以看一下。\n\n1. 回到[阿里云官网](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/aliyun.com)，登录后在页面右上角有`控制台`按钮\n2. 进入控制台后，选择左上角的符号，展开选择`云服务器ECS`  \n   ![picture 4](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-21-31.png)\n3. 仿照图片，选择`实例`，在实例`更多`那里选择`重置密码`，之后我们要用这个密码，通过ssh连接服务器  \n   ![picture 6](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-27-08.png)\n\n   > 有更加安全的连接服务器的方式，你可以在阿里云的帮助文档中看到\n\n4. 仿照下面几张图片，我们要修改安全组配置，加入80端口（http端口），以便之后能够访问网页  \n   ![picture 7](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-30-11.png)  \n   ![picture 8](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-10.png)  \n   选择快速添加（手动添加也差不多），这里我顺带把443https端口也开了  \n   ![picture 9](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-52.png)\n\n### 三、ssh连接服务器[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%89ssh%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8 \"Permanent link\")\n\n实例列表那里有公网ip，复制一下，我的是：`101.37.146.225`  \n![picture 10](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-37-04.png)  \n然后找一个ssh客户端（xshell/vscode），通过`ssh root@101.37.146.225`连接阿里云服务器，你也可以使用阿里云提供的其他连接方式（在实例页面选择`远程连接`）\n\n### 四、安装docker[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%9B%9B%E5%AE%89%E8%A3%85docker \"Permanent link\")\n\n> 你也完全可以不使用docker，在服务器上安装python环境和streamlint就可以了，不过docker可以简化这个流程\n\n在阿里云服务器的终端中输入以下指令\n\n`apt update # 必须先update，才能安装软件 curl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun # mirror是镜像，为了加速`\n\n> 正常来讲为了权限控制，还需要创建一个docker用户，不过这里为了方便省略掉了\n\n### 五、使用docker创建streamlit镜像并部署[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%94%E4%BD%BF%E7%94%A8docker%E5%88%9B%E5%BB%BAstreamlit%E9%95%9C%E5%83%8F%E5%B9%B6%E9%83%A8%E7%BD%B2 \"Permanent link\")\n\n> 这是一个简单的演示，并非是使用docker的最佳实践\n\n创建一个文件夹，创建Dockerfile，内容为（注释可以删掉）\n\n`# 从python3.6镜像基础上创建 FROM python:3.6 # 设置镜像源，提高pip install 速度 RUN pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ \\         && pip install streamlit # streamlit hello创建一个演示页面，映射80端口以便网页访问 CMD [\"streamlit\",\"hello\", \"--server.port\",\"80\"]`\n\n\n然后执行`docker build -t streamlit .` （注意结尾有一个`.`符号），耐心等待一段时间\n\n> 这个指令用于创建一个streamlit的镜像（docker术语），`-t streamlit`指定了这个镜像的名字，最后一个`.`表示构建的上下文路径\n\n然后使用streamlit镜像创建容器，运行streamlit\n\n`docker run -p 80:80 streamlit`\n\n\n然后它会提示你`External URL: http://101.37.146.225:80`，由于80是http的默认端口，所以你在浏览器中直接输入`101.37.146.225`就可以了（换成你的阿里云公网ip地址）\n\n> 本文最后将streamlit部署在另一个服务器的8501端口了，所以应当访问这个：[http://47.115.79.16:8501](http://47.115.79.16:8501/)  \n> Done!! 搞定！你可以在网址中愉快地玩耍了  \n> ![picture 11](https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-33-45.png)\n\n### 六、下一步[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%85%AD%E4%B8%8B%E4%B8%80%E6%AD%A5 \"Permanent link\")\n\n1. 学习docker和streamlit创建更好玩的网站！学习资料在此\n    - [docker从入门到实践](https://yeasy.gitbook.io/)\n    - streamlit：[王树义老师的教程](https://sspai.com/post/58474)或者[streamlit官网](https://www.streamlit.io/)\n    - [使用nginx优化部署](https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561)\n2. 购买域名并将域名指向这个服务器，方便你的同学、老师、客户查看\n\n## 参考资料[#](https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99 \"Permanent link\")\n\n1. [docker部署一个超简单的flask应用](https://zhuanlan.zhihu.com/p/78432719)\n2. [docker+streamlit展示spacy命名实体识别功能](https://maelfabien.github.io/project/Streamlit/)\n3. [在AWS上用docker+nginx部署streamlit](https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561)","slug":"presentation","published":1,"date":"2024-08-25T09:13:16.280Z","updated":"2024-08-25T09:13:16.280Z","comments":1,"layout":"post","photos":[],"_id":"cm0admg6z000254uia8maaupj","content":"<h1 id=\"使用docker和streamlit阿里云服务器部署简单的演示网页\"><a href=\"#使用docker和streamlit阿里云服务器部署简单的演示网页\" class=\"headerlink\" title=\"使用docker和streamlit阿里云服务器部署简单的演示网页\"></a>使用docker和streamlit阿里云服务器部署简单的演示网页</h1><p>这是一篇尽可能新手向的文章，适合首次购买阿里云服务器，想要建一个简单的，用于演示网站的用户，比如深度学习&#x2F;数据的交互式页面。不需要你有什么web开发经验，一步一步跟着搭建就好。我自己前后折腾了两天，写下这篇文章以免其他人绕弯路。</p>\n<blockquote>\n<p>不用学前端编程，你就能用 Python 简单高效写出漂亮的交互式 Web 应用，将你的数据分析成果立即展示给团队和客户。</p>\n</blockquote>\n<h2 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果#\"></a>最终效果<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C\" title=\"Permanent link\">#</a></h2><p>一个网站（ip地址）： <a href=\"http://47.115.79.16:8501/\">http://47.115.79.16:8501</a></p>\n<p><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-46-47.png\" alt=\"picture 12\"></p>\n<blockquote>\n<p>如果你购买了域名并且备案成功-国内需要，你就可以用域名来访问这个ip网址了，域名以及解析不在本文讨论范围内，可以上网自查，也不难</p>\n</blockquote>\n<h2 id=\"为了实现这个效果，你需要？\"><a href=\"#为了实现这个效果，你需要？\" class=\"headerlink\" title=\"为了实现这个效果，你需要？#\"></a>为了实现这个效果，你需要？<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%BA%E4%BA%86%E5%AE%9E%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%95%88%E6%9E%9C%E4%BD%A0%E9%9C%80%E8%A6%81\" title=\"Permanent link\">#</a></h2><ul>\n<li><strong>一点钱</strong>：购买一台最低配置的阿里云服务器，参考价格：16￥&#x2F;周；50￥&#x2F;月；500￥&#x2F;年。本文为了演示，买了一台最最便宜的，只花了16元。</li>\n<li><strong>一点docker知识</strong>：不过不用担心，照着本文依样画葫芦也可以。如果你想学习docker，推荐：<a href=\"https://yeasy.gitbook.io/\">docker从入门到实践</a></li>\n<li><strong>一点时间</strong>：半小时到5小时不等，取决于你想学到什么程度</li>\n<li>ssh客户端（xshell&#x2F;vscode之类），连接服务器的时候用。（不会也没问题，可以用阿里云的网页连接服务器终端）</li>\n</ul>\n<blockquote>\n<p>为什么使用docker？</p>\n<p>方便部署，不需要在每一台新的服务器上都折腾很久。搞定这个你也可以用相同的方法弄flask、django的部署</p>\n<p>为什么使用streamlit？</p>\n<p>flask和django无疑更好，但加上前端的知识，学习成本较高，但我的目标只是搭建一个简单的交互页面，streamlit足够了而且非常简单</p>\n</blockquote>\n<h2 id=\"开始干吧！\"><a href=\"#开始干吧！\" class=\"headerlink\" title=\"开始干吧！#\"></a>开始干吧！<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%BC%80%E5%A7%8B%E5%B9%B2%E5%90%A7\" title=\"Permanent link\">#</a></h2><h3 id=\"一、购买阿里云服务器\"><a href=\"#一、购买阿里云服务器\" class=\"headerlink\" title=\"一、购买阿里云服务器#\"></a>一、购买阿里云服务器<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%80%E8%B4%AD%E4%B9%B0%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"Permanent link\">#</a></h3><ol>\n<li><p>访问<a href=\"https://www.aliyun.com/\">阿里云官网</a>，选择<code>云服务器ECS</code>，在跳转后的页面中选择<code>立即购买</code><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_02-14-17.png\" alt=\"picture 1\"></p>\n<blockquote>\n<p>你会看到很多其他类型的服务器，适用场景不同。</p>\n<ol>\n<li>ECS(Elastic Compute Service)服务器可以简单理解为“弹性”服务器，也就是随时可以根据你的需求提高&#x2F;降低电脑的配置，比如CPU更强，内存更大，更多服务器。</li>\n<li>轻量应用服务器：适合建立轻量的网站，配置也很简单。不过我个人希望自由度高一些，就没有用这个了。</li>\n</ol>\n</blockquote>\n</li>\n<li><p>本文为了方便起见，<strong>选择</strong><code>一键购买</code>，然后基本上按默认配置购买即可。注意点：服务器选最低配的（够用了），镜像那里选<code>ubuntu 18.04</code>，本文仅供演示，购买时长只选了一周（16元），付款搞定</p>\n<blockquote>\n<p>如果你对服务器比较熟悉或者能折腾想学习，可以选择<code>自定义购买</code>，稍微费点时间</p>\n</blockquote>\n</li>\n</ol>\n<blockquote>\n<p>镜像的说明：ubuntu其他版本也可以，ubuntu用的人比较多，centos 和 aliyun linux（基于centos）也可以，后两者商用多一些。</p>\n</blockquote>\n<p><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-03-37.png\" alt=\"picture 2\"></p>\n<p><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-14-20.png\" alt=\"picture 3\"></p>\n<h3 id=\"二、配置服务器\"><a href=\"#二、配置服务器\" class=\"headerlink\" title=\"二、配置服务器#\"></a>二、配置服务器<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%8C%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"Permanent link\">#</a></h3><p>由于我们刚才选的是<code>一键购买</code>，省略了一点配置，现在需要补上。做好心理准备，阿里云控制台有些复杂，我第一次用也很懵逼。如果你之前用<code>自定义购买</code>，下面可以跳过（记得开启80端口），不过你终究还是要熟悉控制台页面的，也可以看一下。</p>\n<ol>\n<li><p>回到<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/aliyun.com\">阿里云官网</a>，登录后在页面右上角有<code>控制台</code>按钮</p>\n</li>\n<li><p>进入控制台后，选择左上角的符号，展开选择<code>云服务器ECS</code><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-21-31.png\" alt=\"picture 4\"></p>\n</li>\n<li><p>仿照图片，选择<code>实例</code>，在实例<code>更多</code>那里选择<code>重置密码</code>，之后我们要用这个密码，通过ssh连接服务器<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-27-08.png\" alt=\"picture 6\"></p>\n<blockquote>\n<p>有更加安全的连接服务器的方式，你可以在阿里云的帮助文档中看到</p>\n</blockquote>\n</li>\n<li><p>仿照下面几张图片，我们要修改安全组配置，加入80端口（http端口），以便之后能够访问网页<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-30-11.png\" alt=\"picture 7\"><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-10.png\" alt=\"picture 8\"><br>选择快速添加（手动添加也差不多），这里我顺带把443https端口也开了<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-52.png\" alt=\"picture 9\"></p>\n</li>\n</ol>\n<h3 id=\"三、ssh连接服务器\"><a href=\"#三、ssh连接服务器\" class=\"headerlink\" title=\"三、ssh连接服务器#\"></a>三、ssh连接服务器<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%89ssh%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"Permanent link\">#</a></h3><p>实例列表那里有公网ip，复制一下，我的是：<code>101.37.146.225</code><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-37-04.png\" alt=\"picture 10\"><br>然后找一个ssh客户端（xshell&#x2F;vscode），通过<code>ssh root@101.37.146.225</code>连接阿里云服务器，你也可以使用阿里云提供的其他连接方式（在实例页面选择<code>远程连接</code>）</p>\n<h3 id=\"四、安装docker\"><a href=\"#四、安装docker\" class=\"headerlink\" title=\"四、安装docker#\"></a>四、安装docker<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%9B%9B%E5%AE%89%E8%A3%85docker\" title=\"Permanent link\">#</a></h3><blockquote>\n<p>你也完全可以不使用docker，在服务器上安装python环境和streamlint就可以了，不过docker可以简化这个流程</p>\n</blockquote>\n<p>在阿里云服务器的终端中输入以下指令</p>\n<p><code>apt update # 必须先update，才能安装软件 curl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun # mirror是镜像，为了加速</code></p>\n<blockquote>\n<p>正常来讲为了权限控制，还需要创建一个docker用户，不过这里为了方便省略掉了</p>\n</blockquote>\n<h3 id=\"五、使用docker创建streamlit镜像并部署\"><a href=\"#五、使用docker创建streamlit镜像并部署\" class=\"headerlink\" title=\"五、使用docker创建streamlit镜像并部署#\"></a>五、使用docker创建streamlit镜像并部署<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%94%E4%BD%BF%E7%94%A8docker%E5%88%9B%E5%BB%BAstreamlit%E9%95%9C%E5%83%8F%E5%B9%B6%E9%83%A8%E7%BD%B2\" title=\"Permanent link\">#</a></h3><blockquote>\n<p>这是一个简单的演示，并非是使用docker的最佳实践</p>\n</blockquote>\n<p>创建一个文件夹，创建Dockerfile，内容为（注释可以删掉）</p>\n<p><code># 从python3.6镜像基础上创建 FROM python:3.6 # 设置镜像源，提高pip install 速度 RUN pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ \\         &amp;&amp; pip install streamlit # streamlit hello创建一个演示页面，映射80端口以便网页访问 CMD [&quot;streamlit&quot;,&quot;hello&quot;, &quot;--server.port&quot;,&quot;80&quot;]</code></p>\n<p>然后执行<code>docker build -t streamlit .</code> （注意结尾有一个<code>.</code>符号），耐心等待一段时间</p>\n<blockquote>\n<p>这个指令用于创建一个streamlit的镜像（docker术语），<code>-t streamlit</code>指定了这个镜像的名字，最后一个<code>.</code>表示构建的上下文路径</p>\n</blockquote>\n<p>然后使用streamlit镜像创建容器，运行streamlit</p>\n<p><code>docker run -p 80:80 streamlit</code></p>\n<p>然后它会提示你<code>External URL: http://101.37.146.225:80</code>，由于80是http的默认端口，所以你在浏览器中直接输入<code>101.37.146.225</code>就可以了（换成你的阿里云公网ip地址）</p>\n<blockquote>\n<p>本文最后将streamlit部署在另一个服务器的8501端口了，所以应当访问这个：<a href=\"http://47.115.79.16:8501/\">http://47.115.79.16:8501</a><br>Done!! 搞定！你可以在网址中愉快地玩耍了<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-33-45.png\" alt=\"picture 11\"></p>\n</blockquote>\n<h3 id=\"六、下一步\"><a href=\"#六、下一步\" class=\"headerlink\" title=\"六、下一步#\"></a>六、下一步<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%85%AD%E4%B8%8B%E4%B8%80%E6%AD%A5\" title=\"Permanent link\">#</a></h3><ol>\n<li>学习docker和streamlit创建更好玩的网站！学习资料在此<ul>\n<li><a href=\"https://yeasy.gitbook.io/\">docker从入门到实践</a></li>\n<li>streamlit：<a href=\"https://sspai.com/post/58474\">王树义老师的教程</a>或者<a href=\"https://www.streamlit.io/\">streamlit官网</a></li>\n<li><a href=\"https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561\">使用nginx优化部署</a></li>\n</ul>\n</li>\n<li>购买域名并将域名指向这个服务器，方便你的同学、老师、客户查看</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料#\"></a>参考资料<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\" title=\"Permanent link\">#</a></h2><ol>\n<li><a href=\"https://zhuanlan.zhihu.com/p/78432719\">docker部署一个超简单的flask应用</a></li>\n<li><a href=\"https://maelfabien.github.io/project/Streamlit/\">docker+streamlit展示spacy命名实体识别功能</a></li>\n<li><a href=\"https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561\">在AWS上用docker+nginx部署streamlit</a></li>\n</ol>\n","excerpt":"","more":"<h1 id=\"使用docker和streamlit阿里云服务器部署简单的演示网页\"><a href=\"#使用docker和streamlit阿里云服务器部署简单的演示网页\" class=\"headerlink\" title=\"使用docker和streamlit阿里云服务器部署简单的演示网页\"></a>使用docker和streamlit阿里云服务器部署简单的演示网页</h1><p>这是一篇尽可能新手向的文章，适合首次购买阿里云服务器，想要建一个简单的，用于演示网站的用户，比如深度学习&#x2F;数据的交互式页面。不需要你有什么web开发经验，一步一步跟着搭建就好。我自己前后折腾了两天，写下这篇文章以免其他人绕弯路。</p>\n<blockquote>\n<p>不用学前端编程，你就能用 Python 简单高效写出漂亮的交互式 Web 应用，将你的数据分析成果立即展示给团队和客户。</p>\n</blockquote>\n<h2 id=\"最终效果\"><a href=\"#最终效果\" class=\"headerlink\" title=\"最终效果#\"></a>最终效果<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C\" title=\"Permanent link\">#</a></h2><p>一个网站（ip地址）： <a href=\"http://47.115.79.16:8501/\">http://47.115.79.16:8501</a></p>\n<p><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-46-47.png\" alt=\"picture 12\"></p>\n<blockquote>\n<p>如果你购买了域名并且备案成功-国内需要，你就可以用域名来访问这个ip网址了，域名以及解析不在本文讨论范围内，可以上网自查，也不难</p>\n</blockquote>\n<h2 id=\"为了实现这个效果，你需要？\"><a href=\"#为了实现这个效果，你需要？\" class=\"headerlink\" title=\"为了实现这个效果，你需要？#\"></a>为了实现这个效果，你需要？<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%BA%E4%BA%86%E5%AE%9E%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%95%88%E6%9E%9C%E4%BD%A0%E9%9C%80%E8%A6%81\" title=\"Permanent link\">#</a></h2><ul>\n<li><strong>一点钱</strong>：购买一台最低配置的阿里云服务器，参考价格：16￥&#x2F;周；50￥&#x2F;月；500￥&#x2F;年。本文为了演示，买了一台最最便宜的，只花了16元。</li>\n<li><strong>一点docker知识</strong>：不过不用担心，照着本文依样画葫芦也可以。如果你想学习docker，推荐：<a href=\"https://yeasy.gitbook.io/\">docker从入门到实践</a></li>\n<li><strong>一点时间</strong>：半小时到5小时不等，取决于你想学到什么程度</li>\n<li>ssh客户端（xshell&#x2F;vscode之类），连接服务器的时候用。（不会也没问题，可以用阿里云的网页连接服务器终端）</li>\n</ul>\n<blockquote>\n<p>为什么使用docker？</p>\n<p>方便部署，不需要在每一台新的服务器上都折腾很久。搞定这个你也可以用相同的方法弄flask、django的部署</p>\n<p>为什么使用streamlit？</p>\n<p>flask和django无疑更好，但加上前端的知识，学习成本较高，但我的目标只是搭建一个简单的交互页面，streamlit足够了而且非常简单</p>\n</blockquote>\n<h2 id=\"开始干吧！\"><a href=\"#开始干吧！\" class=\"headerlink\" title=\"开始干吧！#\"></a>开始干吧！<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%BC%80%E5%A7%8B%E5%B9%B2%E5%90%A7\" title=\"Permanent link\">#</a></h2><h3 id=\"一、购买阿里云服务器\"><a href=\"#一、购买阿里云服务器\" class=\"headerlink\" title=\"一、购买阿里云服务器#\"></a>一、购买阿里云服务器<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%80%E8%B4%AD%E4%B9%B0%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"Permanent link\">#</a></h3><ol>\n<li><p>访问<a href=\"https://www.aliyun.com/\">阿里云官网</a>，选择<code>云服务器ECS</code>，在跳转后的页面中选择<code>立即购买</code><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_02-14-17.png\" alt=\"picture 1\"></p>\n<blockquote>\n<p>你会看到很多其他类型的服务器，适用场景不同。</p>\n<ol>\n<li>ECS(Elastic Compute Service)服务器可以简单理解为“弹性”服务器，也就是随时可以根据你的需求提高&#x2F;降低电脑的配置，比如CPU更强，内存更大，更多服务器。</li>\n<li>轻量应用服务器：适合建立轻量的网站，配置也很简单。不过我个人希望自由度高一些，就没有用这个了。</li>\n</ol>\n</blockquote>\n</li>\n<li><p>本文为了方便起见，<strong>选择</strong><code>一键购买</code>，然后基本上按默认配置购买即可。注意点：服务器选最低配的（够用了），镜像那里选<code>ubuntu 18.04</code>，本文仅供演示，购买时长只选了一周（16元），付款搞定</p>\n<blockquote>\n<p>如果你对服务器比较熟悉或者能折腾想学习，可以选择<code>自定义购买</code>，稍微费点时间</p>\n</blockquote>\n</li>\n</ol>\n<blockquote>\n<p>镜像的说明：ubuntu其他版本也可以，ubuntu用的人比较多，centos 和 aliyun linux（基于centos）也可以，后两者商用多一些。</p>\n</blockquote>\n<p><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-03-37.png\" alt=\"picture 2\"></p>\n<p><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-14-20.png\" alt=\"picture 3\"></p>\n<h3 id=\"二、配置服务器\"><a href=\"#二、配置服务器\" class=\"headerlink\" title=\"二、配置服务器#\"></a>二、配置服务器<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%8C%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"Permanent link\">#</a></h3><p>由于我们刚才选的是<code>一键购买</code>，省略了一点配置，现在需要补上。做好心理准备，阿里云控制台有些复杂，我第一次用也很懵逼。如果你之前用<code>自定义购买</code>，下面可以跳过（记得开启80端口），不过你终究还是要熟悉控制台页面的，也可以看一下。</p>\n<ol>\n<li><p>回到<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/aliyun.com\">阿里云官网</a>，登录后在页面右上角有<code>控制台</code>按钮</p>\n</li>\n<li><p>进入控制台后，选择左上角的符号，展开选择<code>云服务器ECS</code><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-21-31.png\" alt=\"picture 4\"></p>\n</li>\n<li><p>仿照图片，选择<code>实例</code>，在实例<code>更多</code>那里选择<code>重置密码</code>，之后我们要用这个密码，通过ssh连接服务器<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-27-08.png\" alt=\"picture 6\"></p>\n<blockquote>\n<p>有更加安全的连接服务器的方式，你可以在阿里云的帮助文档中看到</p>\n</blockquote>\n</li>\n<li><p>仿照下面几张图片，我们要修改安全组配置，加入80端口（http端口），以便之后能够访问网页<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-30-11.png\" alt=\"picture 7\"><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-10.png\" alt=\"picture 8\"><br>选择快速添加（手动添加也差不多），这里我顺带把443https端口也开了<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-33-52.png\" alt=\"picture 9\"></p>\n</li>\n</ol>\n<h3 id=\"三、ssh连接服务器\"><a href=\"#三、ssh连接服务器\" class=\"headerlink\" title=\"三、ssh连接服务器#\"></a>三、ssh连接服务器<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%B8%89ssh%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8\" title=\"Permanent link\">#</a></h3><p>实例列表那里有公网ip，复制一下，我的是：<code>101.37.146.225</code><br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_03-37-04.png\" alt=\"picture 10\"><br>然后找一个ssh客户端（xshell&#x2F;vscode），通过<code>ssh root@101.37.146.225</code>连接阿里云服务器，你也可以使用阿里云提供的其他连接方式（在实例页面选择<code>远程连接</code>）</p>\n<h3 id=\"四、安装docker\"><a href=\"#四、安装docker\" class=\"headerlink\" title=\"四、安装docker#\"></a>四、安装docker<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%9B%9B%E5%AE%89%E8%A3%85docker\" title=\"Permanent link\">#</a></h3><blockquote>\n<p>你也完全可以不使用docker，在服务器上安装python环境和streamlint就可以了，不过docker可以简化这个流程</p>\n</blockquote>\n<p>在阿里云服务器的终端中输入以下指令</p>\n<p><code>apt update # 必须先update，才能安装软件 curl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun # mirror是镜像，为了加速</code></p>\n<blockquote>\n<p>正常来讲为了权限控制，还需要创建一个docker用户，不过这里为了方便省略掉了</p>\n</blockquote>\n<h3 id=\"五、使用docker创建streamlit镜像并部署\"><a href=\"#五、使用docker创建streamlit镜像并部署\" class=\"headerlink\" title=\"五、使用docker创建streamlit镜像并部署#\"></a>五、使用docker创建streamlit镜像并部署<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E4%BA%94%E4%BD%BF%E7%94%A8docker%E5%88%9B%E5%BB%BAstreamlit%E9%95%9C%E5%83%8F%E5%B9%B6%E9%83%A8%E7%BD%B2\" title=\"Permanent link\">#</a></h3><blockquote>\n<p>这是一个简单的演示，并非是使用docker的最佳实践</p>\n</blockquote>\n<p>创建一个文件夹，创建Dockerfile，内容为（注释可以删掉）</p>\n<p><code># 从python3.6镜像基础上创建 FROM python:3.6 # 设置镜像源，提高pip install 速度 RUN pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/ \\         &amp;&amp; pip install streamlit # streamlit hello创建一个演示页面，映射80端口以便网页访问 CMD [&quot;streamlit&quot;,&quot;hello&quot;, &quot;--server.port&quot;,&quot;80&quot;]</code></p>\n<p>然后执行<code>docker build -t streamlit .</code> （注意结尾有一个<code>.</code>符号），耐心等待一段时间</p>\n<blockquote>\n<p>这个指令用于创建一个streamlit的镜像（docker术语），<code>-t streamlit</code>指定了这个镜像的名字，最后一个<code>.</code>表示构建的上下文路径</p>\n</blockquote>\n<p>然后使用streamlit镜像创建容器，运行streamlit</p>\n<p><code>docker run -p 80:80 streamlit</code></p>\n<p>然后它会提示你<code>External URL: http://101.37.146.225:80</code>，由于80是http的默认端口，所以你在浏览器中直接输入<code>101.37.146.225</code>就可以了（换成你的阿里云公网ip地址）</p>\n<blockquote>\n<p>本文最后将streamlit部署在另一个服务器的8501端口了，所以应当访问这个：<a href=\"http://47.115.79.16:8501/\">http://47.115.79.16:8501</a><br>Done!! 搞定！你可以在网址中愉快地玩耍了<br><img src=\"https://jackiegeek.gitee.io/blog/attachment/2020-09-16_04-33-45.png\" alt=\"picture 11\"></p>\n</blockquote>\n<h3 id=\"六、下一步\"><a href=\"#六、下一步\" class=\"headerlink\" title=\"六、下一步#\"></a>六、下一步<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%85%AD%E4%B8%8B%E4%B8%80%E6%AD%A5\" title=\"Permanent link\">#</a></h3><ol>\n<li>学习docker和streamlit创建更好玩的网站！学习资料在此<ul>\n<li><a href=\"https://yeasy.gitbook.io/\">docker从入门到实践</a></li>\n<li>streamlit：<a href=\"https://sspai.com/post/58474\">王树义老师的教程</a>或者<a href=\"https://www.streamlit.io/\">streamlit官网</a></li>\n<li><a href=\"https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561\">使用nginx优化部署</a></li>\n</ul>\n</li>\n<li>购买域名并将域名指向这个服务器，方便你的同学、老师、客户查看</li>\n</ol>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料#\"></a>参考资料<a href=\"https://jackiegeek.gitee.io/blog/%E6%8A%80%E6%9C%AF/%E4%BD%BF%E7%94%A8docker%E5%92%8Cstreamlit%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E7%9A%84%E6%BC%94%E7%A4%BA%E7%BD%91%E9%A1%B5/#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99\" title=\"Permanent link\">#</a></h2><ol>\n<li><a href=\"https://zhuanlan.zhihu.com/p/78432719\">docker部署一个超简单的flask应用</a></li>\n<li><a href=\"https://maelfabien.github.io/project/Streamlit/\">docker+streamlit展示spacy命名实体识别功能</a></li>\n<li><a href=\"https://discuss.streamlit.io/t/tutorial-deploying-streamlit-app-to-aws-lightsail-with-docker-and-nginx/5561\">在AWS上用docker+nginx部署streamlit</a></li>\n</ol>\n"},{"title":"Kafka消息中间件","_content":"\n1、Kafka概述\n---------\n\n### 1.1 Kafka定义\n\nApache Kafka 是一款开源的消息系统。可以在系统中起到“肖峰填谷”的作用，也可以用于异构、分布式系统中海量数据的异步化处理。\n\n### 1.2 Kafka使用场景\n\n*   **消息中间件：** 作为消息中间件进行消息传递，作为TCP HTTP或者RPC的替代方案，可以实现异步、解耦、削峰（RabbitMQ和RocketMQ能做的事情，它也能做）。因为kafka的吞吐量更高，在大规模消息系统中更有优势。\n*   **大数据领域：** 例如日志归集、行为跟踪、应用监控。\n*   **数据集成+流计算：** 对流式数据进行继承和实时计算。\n\n2、Kafka服务端基本认识\n\n\n目前比较流行的服务端管理界面主要是 kafka-manager 和 kafka-eagle （国产）。\n\n### 2.1 Kafka与ZK的关系\n\n总结起来：利用ZK的有序节点、临时节点和监听机制，ZK帮kafka做了这些事情：配置中心(管理Broker、Topic、Partition、Consumer的信息，包括元数据的变动)、负载均衡、命名服务、分布式通知、集群管理和选举、分布式锁。\n\n### 2.2 Kafka脚本介绍\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417112654325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n3、Kafka架构分析\n-----------\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417113222162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 3.1 Broker\n\nKafka作为一个中间件，是帮我们存储和转发消息的，它做的事情有点像中介，所以我们把kafka的服务叫做Broker，默认是9092的端口。生产者和消费者都需要跟这个Broker建立一个连接，才可以实现消息的收发。\n\n### 3.2 消息\n\n客户端之间传输的数据叫做消息，或者叫做记录（Record）。在客户端的代码中，Record可以是一个KV键值对，生产者的封装类是ProducerRecord，消费者的封装类是ConsumerRecord。  \n  消息在传输过程中需要序列化，所以在代码中要指定序列化工具。\n\n### 3.3 生产者\n\n发送消息的一方叫做生产者。为了提升发送效率，生产者不是逐条发送消息给Broker，而是批量发送的，发送的数据大小和时间间隔由以下参数决定：\n\n    batch.size=16384\n    linger.ms=0\n\n\n### 3.4 消费者\n\n接收消息的一方叫做消费者。  \n  —般来说消费者获取消息有两种模式，一种是pull模式，一种是push模式。Pull模式就是消费放在Broker,消费者自己决定什么时候去获取。Push模式是消息放在Consumer，只要有消息到达Broker,都直接推给消费者。  \n  Kafka只支持pull模式，因为在push模式下，如果消息产生速度远远大于消费者消费消息的速率，那消费者就会不堪重负（你已经吃不下了，但是还要不断地往你嘴里塞），直到挂掉。而且在pull模式下消费者一次pull获取多少条消息由以下参数决定：\n\n    max.poll.records=500\n\n\n### 3.5 Topic\n\n生产者跟消费者是怎么关联起来的呢？或者说，生产者发送的消息，怎么才能到达某个特定的消费者？他们要通过队列关联起来，也就是说，生产者发送消息，要指定发给哪个队列。消费者接收消息，要指定从哪个队列接收。在Kafka里面，这个队列叫做Topic。它是一个逻辑的概念，可以理解为一组消息的集合（用以区分不同业务用途的消息）。  \n  注意，生产者发送消息时，如果Topic不存在，会自动创建。由以下参数决定：\n\n    auto.create.topics.enable=true\n\n\n### 3.6 Partition\n\n如果说一个Topic中的消息太多，会带来两个问题：  \n  第一个是不方便横向扩展，比如我想要在集群中把数据分布在不同的机器上实现扩展，而不是通过升级硬件做到，如果一个Topic的消息无法在物理上拆分到多台机器的时候，这个是做不到的。  \n  第二个是并发或者负载的问题，所有的客户端操作的都是同一个Topic,在高并发的场景下性能会大大下降。  \n  怎么解决这个问题呢？我们想到的就是把一个Topic进行拆分。 Kafka引入了一个分区(Partition)的概念。一个Topic可以划分成多个分区。 分区在创建topic的时候指定，每个topic至少有一个分区。  \n  在创建topic时需要指定分区数由以下参数决定：\n\n    num.partitions=1\n\n\nPartition思想上有点类似于分库分表，实现的也是横向扩展和负载的目的。举个例子，Topic有3个分区，生产者依次发送9条消息，对消息进行编号。 第一个分区存1 4 7,第二个分区存2 5 8,第三个分区存3 6 9，这个就实现了负载。\n\n### 3.7 Replica\n\n如果partition的数据只存储一份，在发生网络或者硬件故障的时候，该分区的数据就无法访问或者无法恢复了。  \n  Kafka在0.8的版本之后增加了副本机制。每个partition可以有若干个副本(Replica)，副本必须在不同的Broker 上面。—般我们说的副本包括其中的主节点。由 replication-factor指定一个Topic 的副本数。默认副本数由以下参数决定\n\n    offsets.topic.replication.factor=1\n\n\n举例：部署了 3个Broker,该topic有3个分区，每个分区一共3个副本。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417123522406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  注意：这些存放相同数据的partition副本有leader（图中红色）和follower（图中绿色）的概念。leader在哪台机器是不一定的，选举岀来的。\n\n### 3.8 Segment\n\nKafka的数据是放在后缀.log的文件里面的。如果一个partition只有一个log文件，消息不断地追加，这个log文件也会变得越来越大，这个时候要检索数据效率就很低了。所以干脆把partition再做一个切分，切分岀来的单位就叫做段（segment）。实际上kafka的存储文件是划分成段来存储的。默认存储路径：/tmp/kafka-logs/ 。每个segment都有至少有1个数据文件和2个索引文件，这3个文件是成套出现的。\n\n### 3.9 Consumer Group\n\n我们知道消息中间件一般会支持发布/订阅模式和广播模式，那么在Kafka中是如何实现的呢？或者换一种问法，当多个消费者订阅了同一个topic的时候，该如何区分这条消息是要单发还是群发呢？  \n  Kafka引入了消费者组Consumer Group的概念，通过group.id来配置，group.id相同的消费者属于同一个消费者组，Kafka对不同消费者组进行广播，而同一个消费者组中的消费者只消费一次消息。  \n  具体点说，同一个消费者组的消费者不能订阅相同的分区。当消费者数量小于分区数时，一个消费者消费多个分区，当消费者数量大于分区数时，多余的消费者将不进行工作。\n\n### 3.10 Consumer Offset\n\n我们已经知道Kafka消息是写在日志文件中，并且不会在消费过后就被删除。那么当一个消费者组在消费一半时重启了，该如何继续上一次的位置读取消息呢？为此，Kafka引入Consumer Offset的概念。  \n  Consumer Offset是标记一个消费者组在一个partition即将消费的下一条记录，这个信息直接保存在Kafka本身一个特殊的topic中，叫\\_\\_consumer\\_offsets，默认创建50个分区。\n\n4、Kafka原理\n---------\n\n### 4.1 Kafka生产者原理\n\n#### 4.1.1 生产者发送流程\n\n消息发送的整体流程。生产端主要由两个线程协调运行。这两条线程分别为main线程和sender线程（发送线程）。  \n  在创建KafkaProducer的时候，创建了一个Sender对象，并且启动了—个IO线程。\n\n##### 4.1.1.1 拦截器\n\n第二步是执行拦截器的逻辑，在producer.send方法中:\n\n    ProducerRecord<K, V> interceptedRecord = this.interceptors.onSend(record);\n\n\n拦截器的作用是实现消息的定制化（类似于Spring Interceptor、MyBatis的插件、Quartz的监听器）。那这个拦截器是在哪里定义的呢？生产者代码：\n\n    List<String> interceptors = new ArrayList<>(); \n    interceptors.add(\" com.xxx.interceptor.Charginginterceptor\"); \n    props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n\n\n举个例子，假设发送消息的时候要扣钱，发一条消息1分钱（我把这个功能叫做按量付费），就可以用拦截器实现。\n\n    public class Charginginterceptor implements ProducerInterceptor<String, String> {\n    \t//发送消息的时候触发\n    \t@Override\n    \tpublic ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n    \t \tSystem.out.println(\"1分钱1条消息，不管那么多反正先扣钱”);\n    \t\treturn record;\n    \t}\n    \n    \t//收到服务端的ACK的时候触发\n    \t@Override\n    \tpublic void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    \t\tSystem.out.pnntln(n消息被服务端接收啦”);\n    \t}\n    \t\n    \t@Override \n    \tpublic void close() {\n    \t\tSystem.out.printin(”生产者关闭了\");\n    \t}\n    \t\n    \t//用键值对配置的时候触发\n    \t@Override\n    \tpublic void configure(Map<String, ?> configs) {\n    \t\tSystem. out.piintln(n configure...H);\n    \t}\n    }\n\n\n##### 4.1.1.2 序列化\n\n接下来是利用指定的工具对key和value进行序列化：\n\n    serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());\n\n\nkafka针对不同的数据类型自带了相应的序列化工具。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417162458711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  除了自带的序列化工具之外，可以使用如Avro、JSON、Thrift. Protobuf等，或者使用自定义类型的序列化器来实现，实现Serializer接口即可。\n\n##### 4.1.1.3 分区路由\n\n然后是分区指定：\n\n    int partition = partition(record, serializedKey, serialized Value, cluster);\n\n\n一条消息会发送到哪个partition呢？它返回的是一个分区的编号，从0开始。有四种情况:\n\n1.  指定了partition——直接将指定的值直接作为partiton值。\n2.  没有指定partition,自定义了分区器——将使用自定义的分区器算法选择分区。\n3.  没有指定partition,没有自定义分区器，但是key不为空——使用默认分区器DefaultPartitioner,将  \n    key的hash值与topic的partition数进行取余得到partition值；\n4.  没有指定partition,没有自定义分区器，但是key是空的——第一次调用时随机生成一个整数(后面每次调用在这个整数上自增)，将这个值与topic可用的partition总数取余得到 partition值，也就是常说的round-robin算法。\n\n##### 4.1.1.4 消息累加器\n\n选择分区以后并没有直接发送消息，而是把消息放入了消息累加器：\n\n    RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptcallback, remainingWaitMs);\n\n\nRecordAccumulator 本质上是一个 ConcurrentMap:\n\n    ConcurrentMap<TopicPailition Deque<ProducerBatc>> batches;\n\n\n—个partition —个Batch。batch满了之后，会唤醒Sender线程，发送消息:\n\n    if (result.batchlsFull || result.newBatchCreated) {\n    \tlog.trace(Waking up the sender since topic {} partition {} is either full or getting a new batch\", record.topic(), partition);\n    \tthis.sender.wakeup();\n    }\n\n\n#### 4.1.2 消息应答机制ACK\n\n##### 4.1.2.1 服务端响应策略\n\n生产者的消息是不是发出去就完事了？如果说网络出了问题，或者说kafka服务端接收的时候出了问题，这个消息发送失败了，生产者是不知道的。所以，kafka服务端应该要有一种响应客户端的方式，只有在服务端确认以后，生产者才发送下一轮的消息，否则重新发送数据。  \n  服务端什么时候才算接收成功呢？因为消息是存储在不同的partition里面的，所以是写入到partition之后响应生产者。当然，单个partition (leader)写入成功，还是不够可靠，如果有多个副本，follower 也要写入成功才可以。  \n  为了安全性考虑，Kafka会等待所有的follower全部完成同步，才发送ACK给客户端，延迟相对来说高一些，但是节点挂掉的影响相对来说小一些，因为所有的节点数据都是完整的。\n\n##### 4.1.2.2 ISR\n\n然而以上方案仍然存在问题：假设leader收到数据，所有follower都开始同步数据，但是有一个follower出了问题，没有办法从leader同步数据。按照这个规则，leader就要一致等待，无法发送 ack。  \n  从概率的角度来讲，这种问题肯定是会出现的，就是某个follower出问题了，怎么解决呢？所以我们的规则就不能那么粗暴了，把规则改一下，不是所有的follower都有权利 让我等待，而是只有那些正常工作的follower同步数据的时候我才会等待。  \n  我们应该把那些正常和leader保持同步的replica维护起来，放到一个动态set里面，这个就叫做in-sync replica set (ISR)。现在只要ISR里面的follower同步完数据之后，我就给客户端发送ACK。如果一个follower长时间不同步数据，就要从ISR剔除。同样，如果后面这个follower重新与leader保持同步，就会重新加入ISR。时间间隔由以下参数决定：\n\n    replica.lag.time.max.ms=10000\n\n\n##### 4.1.2.3 ACK应答\n\n当然，如果所有的数据都一视同仁，而且这种策略只能由服务端决定，这就不是很灵活了。有一些数据丢了无所谓，我只想要快，不管它落没落盘同没同步，怎么办呢？  \n  Kafka为客户端提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择相应的配置。\n\n*   **acks=0：** producer不等待broker的ack,这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；\n*   **acks=1（默认）：** producer 等待 broker 的 ack, partition 的 leader 落盘成功后 返回ack,如果在follower同步成功之前leader故障，那么将会丢失数据；\n*   **acks=-1 (all) ：** producer等待 broker 的 ack, partition 的 Ieader和 follower全部落盘成功后才返回ack。\n\n三种机制，性能依次递减（producer吞吐量降低），数据健壮性则依次递增。我们可 以根据业务场景使用不同的参数。\n\n### 4.2 Kafka消息存储原理\n\n#### 4.2.1 数据存储目录\n\n目录配置在配置文件config/env.properties，由以下参数决定：\n\n    logs.dir=/tmp/kafka-logs\n\n\n#### 4.2.2 partition分区\n\n为了实现横向扩展，把不同的数据存放在不同的Broker上,同时降低单台服务器的访问压力，我们把一个topic中的数据分隔成多个partition。—个partition中的消息是有序的，顺序写入，但是全局不一定有序。  \n  在服务器上，每个partition都有一个物理目录，topic名字后面的数字标号即代表分区。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417170640277.png)\n\n#### 4.2.3 replica副本\n\n为了提高分区的可靠性，kafka又设计了副本机制。创建topic的时候，通过指定replication-factor确定topic的副本数。  \n  注意：副本数必须小于等于节点数，而不能大于Broker的数量，否则会报错。  \n  这些所有的副本分为两种角色，leader对外提供读写服务。follower唯一的任务就是从leader异步拉取数据。\n\n#### 4.2.4 副本分布规则\n\n副本在Broker的分布有什么规则吗？例如有个topic：a4part2rep, 4个分区每个2个副本，一共8份副本，怎么分布到3台机器呢？  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417171144308.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  实际副本分布规则是由AdminUtils.scala——assignReplicasToBrokers决定的，具体规则如下：\n\n1.  副本因子不能大于Broker的个数；\n2.  第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；\n3.  其他分区的第一个副本放置位置相对于第0个分区依次往后移 （nextReplicaShift）。\n\n这样设计可以提高容灾能力。在每个分区的第一个副本错开之后，一般第一个分区的第一个副本（按Broker编号排序）都是leader。leader是错开的，不至于一挂影响太大。\n\n#### 4.2.5 Segment\n\n为了防止log不断追加导致文件过大，导致检索消息效率变低，一个partition又被划分成多个segment来组织数据。在磁盘上，每个segment由一个log文件和2个index文件组成。这三个文件是成套出现的。另外还有一个leader-epoch-checkpoint文件中保存了每一任leader开始写入消息时的offset。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418150929793.png)\n\n1 .log日志文件（日志就是数据）  \n  在一个segment文件里面，日志是追加写入的。如果满足一定条件，就会切分日志文件，产生一个新的segment什么时候会触发segment的切分呢？  \n  第一种是根据日志文件大小。当一个segment写满以后，会创建一个新的segment, 用最新的offset作为名称。文件大小由以下参数控制（默认1G）：\n\n    log.segment.bytes=1073741824\n\n\n第二种是根据消息的最大时间戳，和当前系统时间戳的差值。还可以从更加精细的时间单位进行控制，如果配置了毫秒级别的日志切分间隔，会优先使用这个单位。否则就用小时的。间隔时间由以下参数决定：\n\n    log.roll.hours=168\n    log.roll.ms\n\n\n还有第三种情况，offset索引文件或者timestamp索引文件达到了一定的大小。由参数**log.index.size.max.bytes（默认10M）** 控制。如果要减少日志文件的切分，可以把这个值调大一点。  \n2\\. .index偏移量(offset)索引文件  \n3\\. .timeindex 时间戳(timestamp)索引文件\n\n#### 4.2.6 索引\n\n由于一个segment的文件里面可能存放很多消息，如果要根据offset获取消息，必须要有一种快速检索消息的机制。这个就是索引。在Kafka中设计了两种索引：偏移量索引文件记录的是。offset和消息物理地址（在log文件中的位置）的映射关系。时间戳索引文件记录的是时间戳和offset的关系。  \n  内容是二进制的文件，不能以纯文本形式查看。bin目录下有dumplog工具。 查看最后10条offset索引：\n\n    ./kafka-dump-log.sh —files /tmp/kafl<a-logs/mytopic-0/00000000000000000000.index|head -n 10\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418154758336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n注意，Kafka的索引并不是每一条消息都会建立索引，而是一种稀疏索引sparse index（DB2和Mongdb中都有稀疏索引）。至于这个索引有多稀疏，由以下参数决定：\n\n    log.index.interval.bytes=4096\n\n\n只要写入的消息超过了 4KB,偏移量索引文件index和时间戳索引文件.timeindex就会増加一条索引记录(索引项)。这个值设置越小，索引越密集。值设置越大，索引越稀疏。相对来说，越稠密的索引检索数据更快，但是会消耗更多的存储空间。越的稀疏索引占用存储空间小，但是插入和删除时所需的维护开销也小。Kafka索引的时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。  \n  第二种索引类型是时间戳索引。时间戳有两种，一种是消息创建的时间戳，一种是消费在Broker追加写入的时间。到底用哪个时间由以下参数控制：\n\n    log.message.timestamp.type=CreateTime\n\n\n默认是创建时间。如果要改成日志追加时间，则修改为LogAppendTime。査看最早的10条时间戳索引：\n\n    ./kafka-dump-log.sh —files /tmp/kafka-logs/mytopic-0/00000000000000000000.timeindex|head -n 10\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418154859613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  那么Kafka如何基于索引快速检索消息？比如我要检索偏移量是10002673的消息。\n\n1.  消费的时候是能够确定分区的，所以第一步是找到在哪个segment中。Segment 文件是用base offset命名的，所以可以用二分法很快确定（找到名字不大于10002673 的 最大segment）。\n2.  这个segment有对应的索引文件，它们是成套出现的。所以现在要在索引文件中根据offset找position。\n3.  得到position之后，到对应的log文件开始査找offset,和消息的offset进行比较，直到找到消息。  \n    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418155346397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n#### 4.2.7 日志清理策略\n\n由于Kafka的日志并没有在消费后马上删除，随着时间的推移，日志越来越多，需要有相应的清理策略来保证系统的健康，日志清理的开关由以下参数控制：\n\n    log.cleaner.enable=true\n\n\nKafka提供了两种清理方式，分别是删除delete和压缩compact，由以下参数控制：\n\n    log.cleanup.policy=delete\n\n\n日志删除的功能是由定时任务完成的，定时任务运行的时间间隔由以下参数控制：\n\n    log.retention.check.interval.ms=300000\n\n\n删除多久以前的数据由以下参数控制（精度越小优先级越高）：\n\n    log.retention.hours=168\n    log.retention.minutes\n    log.retention.ms\n\n\n还可以根据保留日志的大小来删除数据，超出该大小则删除最早的数据，由以下参数控制（默认-1代表不限制）：\n\n    log.retention.bytes=-1\n\n\n若采取压缩的清理方式，则会根据相同的key进行压缩，当消息的key相同时，只保留最新的value。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418164159281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n#### 4.2.8 Controller选举\n\n当创建添加一个的分区或者分区增加了副本的时候，都要从所有副本中选举一个新的Leader出来。  \n  投票怎么玩？是不是所有的partition副本直接发起投票，开始竞选呢？比如用ZK 实现。  \n  利用ZK怎么实现选举？ZK的什么功能可以感知到节点的变化（增加或者减少）? 或者说，ZK为什么能实现加锁和释放锁？  \n  3个特点：watch机制；节点不允许重复写入；临时节点。  \n  这样实现是比较简单，但是也会存在一定的弊端。如果分区和副本数量过多，所有的副本都直接进行选举的话，一旦某个出现节点的增减，就会造成大量的watch事件被触发，ZK的负载就会过重。  \n  Kafka早期的版本（0.82及以前）就是这样做的，后来换了一种实现方式。  \n  不是所有的repalica都参与leader选举，而是由其中的一个Broker统一来指挥， 这个Broker的角色就叫做Controller（控制器）。  \n  就像Redis Sentinel的架构，执行故障转移的时候，必须要先从所有哨兵中选一个负责做故障转移的节点一样。Kafka也要先从所有Broker中选出唯一的一个Controller，所有的Broker会尝试在zookeeper中创建临时节点/controller,只有一个能创建成功（先到先得）。  \n  如果Controller挂掉了或者网络出现了问题，ZK上的临时节点会消失。其他的Broker通过watch监听到Controller下线的消息后，开始竞选新的Controller。方法跟之前还是一样的,谁先在ZK里面写入一个/controller节点,谁就成为新的Controller。  \n  一个节点成为Controller之后，它肩上的责任也比别人重了几份，正所谓劳力越戴, 责任越大：\n\n*   监听Broker变化。\n*   监听Topic变化。\n*   监听Partition变化。\n*   获取和管理Broker、Topic、Partition的信息。\n*   管理Partiontion的主从信息。\n\n#### 4.2.9 分区副本Leader选举\n\nController确定以后，开始进行leader选举。副本有3个概念：\n\n*   **Assigned-Replicas (AR)**：一个分区的所有副本\n*   **In-Sync Replicas (ISR)**：一个分区中跟leader数据保持一定程度的同步的副本\n*   **Out-Sync-Replicas (OSR)**：跟leader副本同步滞后过多的副本\n\n只有ISR有资格参加leader选举。而且这个ISR不是固定不变的，它是一个动态的列表。  \n如果同步延迟超过30秒，就踢出ISR，进入OSR。如果赶上来了， 就加入ISR。默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader。极端情况下，如果ISR为空，则可以允许ISR之外的副本参与选举，由以下参数控制：\n\n    unclean.leader.election.enable=true\n\n\n注意，这种情况下可能造成数据丢失。  \n  那么leader的选举规则是什么呢？它使用一种类似微软的PacificA算法，在这种算法中，默认是让ISR中第一个replica变成leader。比如ISR是1、5、9, 优先让1成为leader。这个跟中国古代皇帝传位是一样的，优先传给皇长子。\n\n#### 4.2.10 主从同步\n\nLeader确定之后，客户端的读写只能操作leader节点。follower需要向leader同步数据。不同的raplica的offset是不一样的，同步到底怎么同步呢？  \n  首先需要认识几个概念：  \n**LEO (Log End Offset)：** 下一条等待写入的消息的offset (最新的offset + 1),图中分别是9, 8, 6。  \n**HW (Hign Watermark):** ISR中最小的LEO。Leader会管理所有ISR中最小的 LEO作为HW,目前是6。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418214659821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  consumer最多只能消费到HW之前的位置(消费到offset 5的消息)。也就是说: 其他的副本没有同步过去的消息，是不能被消费的。  \n  有了这两个offset之后，再来看看消息怎么同步：\n\nfollowerl同步了1条消息，follower2同步了2条消息。此时HW推进了2,变成8。![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418214946178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  followerl同步了0条消息，follower2同步了1条消息。此时HW推进了1，变成9。LEO和HW重叠，所有的消息都可以消费了。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418215103808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  这里，我们关注一下，从节点怎么跟主节点保持同步？\n\n1.  follower节点会向Leader发送一个fetch请求，leader向follower发送数据后，既需要更新follower的LEO。\n2.  follower接收到数据响应后，依次写入消息并且更新LEO。\n3.  leader 更新 HW （ISR 最小的 LEO）。\n\nkafka设计了独特的ISR复制，可以在保障数据一致性情况下又可提供高吞吐量。\n\n#### 4.2.11 replica故障处理\n\n##### 4.2.11.1 follower故障\n\n首先follower发生故障，会被先踢出ISR。follower恢复之后，从哪里开始同步数据呢？假设第1个replica宕机（中间这个）。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418220330233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  恢复以后，首先根据之前记录的HW （6）,把高于HW的消息截掉（6、7）。然 后向leader同步消息。追上leader之后（30秒），重新加入ISR。\n\n##### 4.2.11.2 leader故障\n\n假设图中leader发生故障。首先选一个leader。因为replica 1 （中间这个）优先，它成为leader。为了保证数据一致，其他的follower需要把高于HW的消息截取掉（这里没有消息需要截取）。然后replica2同步数据。注意：这种机制只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。\n\n##### 4.2.11.3 上面这两种方式没有问题吗？（全文重点！！！）\n\n实际上，副本同步机制并没有上面说的那么简单。假设有A(leader)、B两个副本——  \n  作为leader，A还会维护每个副本的远程LEO值remoteLEO;  \n  作为follower，B会定时发送fetch请求给A拉取数据，在fetch时将自己当前的LEO和HW发送给A。  \n1）初始化状态时：  \n  LEO(A)=0, HW(A)=0，remoteLEO=0;  \n  LEO(B)=0，HW(B)=0;\n\n2）当生产者发送一条数据m1时：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=0，HW(B)=0;\n\n3）B向A发起fetch请求，发送自己当前的LEO给A：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=0，HW(B)=0;\n\n4）A根据B发送的LEO,更新remoteLEO=0，更新HW(A)=min(LEO(A), remoteLEO(B))=0，同时将HW(A)和未同步的数据m1发送给B：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=0，HW(B)=0;\n\n5）B根据A返回的HW(A)，写入数据m1，同时更新LEO(B)=1，HW(B)=min(HW(A), LEO(B))=0，  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=1，HW(B)=0;\\[m1\\]\n\n6）B向A发起第二次fetch请求，发送自己当前的LEO(B)=1：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=1，HW(B)=0;\\[m1\\]\n\n7）此时A更新remoteLEO=1，HW(A)=min(LEO(A), remoteLEO(B))=1，同时返回HW给B：  \n  LEO(A)=1, HW(A)=1，remoteLEO=1;\\[m1\\]  \n  LEO(B)=1，HW(B)=0;\\[m1\\]\n\n8）B根据A返回的HW(A)，更新HW(B)=min(HW(A), LEO(B))=1，  \n  LEO(A)=1, HW(A)=1，remoteLEO=1;\\[m1\\]  \n  LEO(B)=1，HW(B)=1;\\[m1\\]\n\n这是一轮常规的数据同步，设想一下，当leader或者follower出现故障时，会导致什么问题？我们知道可以通过acks来控制消息的可靠性，那么当acks=-1(all)的时候是否数据一定不会丢失？  \n  首先，我们要明白数据丢失的概念，一定是在leader返回ack但是数据不存在的情况下才叫数据丢失，如果leader没有返回ack，也就是说生产者知道消息没发送成功的话，不算数据丢失。那么假设acks=-1的话，实际上leader是在步骤7）执行完毕后就返回ack给生产者。在这个前提下我们分析几个场景。  \n场景一：  \n  假设ISR中只有一个leader副本，且成功写入数据。此时leader挂掉，若参数设置允许OSR中的副本抢占leader的话，可能导致数据丢失。  \n  这种场景系统也无法处理，所以Kafka交给用户自行选择，若unclean.leader.election.enable=true则无法保证消息的可靠性，若unclean.leader.election.enable=false则无法保证系统的效率和可用性。  \n场景二：  \n  在执行完步骤7）之后B挂掉了，而当B重启之后（注意此时HW(B)=0），根据4.2.11.1的做法，会先将超出HW(B)的消息m1抛弃，重新从A拉取数据。更极端的情况下，此时A恰好也挂掉，这时候B就会通过选举成为leader。而A重启之后成为follower，会通过截取m1的方式与leader保持同步。至此，消息m1丢失。更严重的是，若A重启之前，B又接收了生产者发送的新的数据m2，那么A重启后由于HW(A)=1，将不会从B拉取到消息m2，结果如下：  \n  LEO(A)=1, HW(A)=1，remoteLEO=1;\\[m1\\]  \n  LEO(B)=1，HW(B)=1;\\[m2\\]\n\n鉴于场景2，Kafka在0.11版本后增加了一个**leader-epoch-checkpoint**的概念，以文件的形式保存在日志目录下，当一个新的leader在写入第一条消息时，会在文件中记录一条信息，包括leader年代（即leader更换次数）epoch和当前leader写入的第一个offset。  \n  举个例子，当这个分区写入第一条消息时，leader-epoch-checkpoint文件中会记录一条信息（0 0），在写入50条消息之后leader挂掉并发生选举，leader-epoch-checkpoint会增加一条记录（1 50）。  \n  有了这种机制，当follower重启之后就不需要直接丢弃HW之后的数据，而是会发起一次请求对比leader中的epoch与自身的epoch：  \n  若epoch相等则只丢弃自身LEO大于leader的LEO的部分（即，若自身LEO不大于leader的LEO则不进行截取，与原来直接截取到HW有所差别）；  \n  若epoch不相等（自身小于leader的LEO）则将自身LEO与leader-epoch-checkpoint中epoch大于自身epoch的最小值的LEO相比较，丢弃自身LEO大于该LEO的数据。\n\n这部分有点绕，以刚才的例子说明，假设步骤7）执行完毕后B重启，此时：  \n  若B重启期间未发生leader选举，则A的leader-epoch-checkpoint文件与B一致，都是(0 0)，即epoch(A)=epoch(B),此时LEO(B)=LEO(A)=1，无需截取。  \n  若B重启期间发生过leader选举（假设存在副本C、D），则leader-epoch-checkpoint文件存在多条记录(0 0)，(1 10)，(2 50)（又发生两次选举），此时B的epoch小于2，会将B的LEO与10比较（大于epoch(B)的最小epoch是1），同样不会丢弃数据。  \n  以上，就是0.11版本Kafka的数据同步方案。\n\n### 4.3 Kafka消费者原理\n\n#### 4.3.1 Offset的维护\n\n##### 4.3.1.1 Offset的存储\n\n我们知道在partition中，消息是不会删除的，所以才可以追加写入，写入的消息连续有序的。这种特性决定了 kafka可以消费历史消息，而且按照消息的顺序消费指定消息，而不是只能消费队头的消息。正常情况下，我们希望消费没有被消费过的数据，而且是从最先发送（序号小的） 的开始消费（这样才是有序和公平的）。  \n  那么对于一个partition,消费者组怎么才能做到接着上次消费的位置（offset）继续消费呢？肯定要把这个对应关系保存起来，下次消费的时候查找一下。  \n  首先这个对应关系确实是可以查看的。比如消费者组gp-assign-group-1和 ass5part （5个分区）的partition的偏移量关系，可使用如下命令査看：\n\n    ./kafka-consumer-groups.sh “bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 —describe —group gp-assign-group-1\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419010135861.png)\n\n*   CURRENT-OFFSET指的是下一个未使用的offset。\n*   LEO , Log End Offset:下一条等待写入的消息的offset （最新的offset + 1）\n*   LAG是延迟量\n\n注意：这不是表示一个消费者和一个Topic的关系，而是一个consumer group和topic中的一个partition的关系（offset在partition中连续编号而不是全局连续编号）。\n\n那么这个对应关系到底是保存在哪里的呢？  \n  首先肯定是不可能放在消费者本地的。因为所有的消费者都可以使用这个consumer group id，放在本地是做不到统一维护的，肯定要放到服务端。  \n  Kafka早期的版本把消费者组和partition的offset直接维护在ZK中，但是读写的性能消耗太大了。后来就放在一个特殊的topic中，名字叫—consumer_offsets，默认有 50 个分区(offsets.topic.num.partitions 默认是 50)，每个分区默认一个replication。\n\n    ./kafka・topics・sh —topic  \tconsumer_offsets —describe —zookeeper localhost:2181\n\n\n那么这样一个特殊的Topic怎么存储消费者组gp-assign-group-1对于分区的偏移量的？Topic里面是可以存放对象类型的value的（经过序列化和反序列化）。这个Topic 里面主要存储两种对象：  \n  GroupMetadata:保存了消费者组中各个消费者的信息（每个消费者有编号）。  \n  OffsetAndMetadata:保存了消费者组和各个partition的offset位移信息元数据。\n\n    ./kafka-console-consumer.sh —topic consumer_offsets --bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 -formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" —from-beginning\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2021041901084354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  怎么知道一个consumer group的offset会放在这个特殊的Topic的哪个分区呢? 可以通过哈希取模计算得到：\n\n    Math.abs(\"gp-assign-group-1\".hashCode()) % 50;\n\n\n##### 4.3.1.2 如果找不到Offset\n\n如果增加了一个新的消费者组去消费—个topic的某个partion,没有offset的记录，这个时候应该从哪里开始消费呢？ 由以下参数控制：\n\n    auto.offset.reset=latest\n\n\n**latest：** 从最新的消息（最后发送的）开始消费。  \n**earliest：** 从最早的（最先发送的）消息开始消费。可以消费到历史消息。  \n**none：** 如果consumer group在服务端找不到offset会报错。\n\n##### 4.3.1.3 Offset的更新\n\n我们知道消费者组的offset是保存在Broker的，但是是由消费者上报给 Broker的。并不是消费者组消费了消息，Offset就会更新，消费者必须要有一个commit （提交）的动作。消费者可以自动提交或者手动提交。由以下参数控制：\n\n    enable.auto.commit=true\n\n\n另外还可以使用一个参数来控制自动提交的频率：\n\n    auto.commit.interval.ms=5000\n\n\n如果我们要在消费完消息做完业务逻辑处理之后才commit,就要把这个值改成 false。如果是false,消费者就必须要调用一个方法让Broker更新offset。有两种方式：  \n  consumer.commitSync()手动同步提交。  \n  consumer.commitAsync()手动异步提交。  \n  如果不提交或者提交失败,Broker的Offset不会更新，消费者下次消费的时候会受到重复消息。\n\n#### 4.3.2 消费者和消费策略\n\n##### 4.3.2.1 分区分配策略\n\n我们已经知道，在同一个消费者组中，一个分区只能被一个消费者消费。所以当消费者数量大于分区数量时，多余的消费者是无法消费消息的。那么如果分区数大于消费者数呢，Kafka又是如何分配的？  \n  为了保证系统最大的利用率，Kafka的分配策略一定会遵循一个最基本的原则——平均分配，简单理解，不会有任意两个消费者消费的分区数差大于1。在此基础上，Kafka有3种分区分配方式。以8个partition分配给3个consumer为例：  \n**1）Range（范围）**  \n  顾名思义，无需解释。  \n  C1：P0 P1 P2  \n  C2：P3 P4 P5  \n  C3：P6 P7  \n**2）RoundRobin（轮询）**  \n  顾名思义，无需解释。  \n  C1：P0 P3 P6  \n  C2：P1 P4 P7  \n  C3：P2 P5  \n**3）sticky（粘滞）**  \n  粘滞的分配策略较为复杂，它的核心思想是在分区重新分配时保证最小的移动（类似Redis的一致性hash思想，实现方式不同）。\n\n第一次分配类似轮询，结果如下：  \n  C1：P0 P3 P6  \n  C2：P1 P4 P7  \n  C3：P2 P5\n\n假设此时C2挂掉：  \n若按照RoundRobin，结果如下：  \n  C1：P0 P2 P4 P6  \n  C3：P1 P3 P5 P7\n\nsticky结果如下（尽量保证P0 P3 P6 P2 P5不动）：  \n  C1：P0 P3 P6 P1  \n  C3：P2 P5 P4 P7\n\n我们知道在分区分配时是会造成性能损耗的，若采用sticky分配策略可以尽可能减少性能损耗。该思想与Redis的一致性Hash是类似的，只是实现方式不同。\n\n##### 4.3.2.2 分区重分配Rebalance\n\n那么什么时候会触发分区重分配Rebalance呢？显然有两种情况，一种是消费者数量发生变化，一种是分区数量发生变化。Rebalance过程如下：\n\n1.  确定协调者coordinator，通常由集群中负载最小的Broker承担。\n2.  所有consumer向coordinator发送join group请求，确认自己是该组成员。\n3.  coordinator在所有consumer中确定leader（通常是第一个）并由leader确定分区分配结果。\n4.  coordinator向所有consumer发送分区分配结果。\n\n#### 4.3.3 Kafka为什么这么快？\n\n##### 4.3.3.1 顺序读写\n\n首先我们需要了解随机I/O和顺序I/O。  \n  磁盘的构造如图。磁盘的盘片不停地旋转，磁头会在磁盘表面画出一个圆形轨迹，这个就叫磁道。从内到位半径不同有很多磁道。然后又用半径线，把磁道分割成了扇区（两根射线之内的扇区组成扇面）。如果要读写数据, 必须找到数据对应的扇区，这个过程就叫寻址。  \n随机I/O：读写的多条数据在磁盘上是分散的，寻址会很耗时。  \n顺序I/O：读写的数据在磁盘上是集中的，不需要重复寻址的过程。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419015453527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得 Kafka写入吞吐量得到了显著提升。  \n  顺序IO到底有多快呢？下图显示，在一定条件下测试，磁盘的顺序读写可以达到53.2M每秒，比内存的随机读写还要快。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419015622131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n##### 4.3.3.2 索引\n\n我们在写入日志的时候会建立关于Offset和时间的稀疏索引，提升了查找效率，这个上面已经提到过了。\n\n##### 4.3.3.3 批量读写\n\nKafka无论是生产者发送消息还是消费者消费消息都是批量操作的，大大提高读写性能。\n\n##### 4.3.3.4 零拷贝\n\n首先需要了解两个名词。  \n  第一个是操作系统虚拟内存的内核空间和用户空间。操作系统的虚拟内存分成了两块，一部分是内核空间，一部分是用户空间。这样就可以避免用户进程直接操作内核，保证内核安全。进程在内核空间可以执行任意命令，调用系统的一切资源；在用户空间必须要通过  \n—些系统接口才能向内核发出指令。如果用户要从磁盘读取数据(比如kafka消费消息)，必须先把数据从磁盘拷贝到内核缓冲区，然后在从内核缓冲区到用户缓冲区，最后才能返回给用户。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419020156610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  第二个是DMA拷贝。没有DMA技术的时候，拷贝数据的事情需要CPU亲自去做, 这个时候它没法干其他的事情，如果传输的数据量大那就有问题了。DMA技术叫做直接内存访问(Direct Memory Access),其实可以理解为CPU给 自己找了一个小弟帮它做数据搬运的事情。在进行I/O设备和内存的数据传输的时候， 数据搬运的工作全部交给DMA控制器，解放了 CPU的双手。  \n  理解了这两个东西之后，我们来看下传统的I/O模型：  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419020246212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  比如kafka要消费消息，比如要先把数据从磁盘拷贝到内核缓冲区，然后拷贝到用户缓冲区，再拷贝到socket缓冲区，再拷贝到网卡设备。这里面发生了 4次用户态和内核态的切换和4次数据拷贝，2次系统函数的调用（read、write）,这个过程是非常耗费时间的。怎么优化呢?  \n  在Linux操作系统里面提供了一个sendfile函数（并不是所有操作系统都支持sendfile），可以实现\"零拷贝\"。这个时候就不需要经过用户缓冲区了，直接把数据拷贝到网卡（这里画的是支持SG-DMA拷贝的情况）。因为这个只有DMA拷贝，没有CPU拷贝，所以叫做”零拷贝”。零拷贝至少可以提高一倍的性能。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419020413177.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n5、MQ选型：Kafka对比RabbitMQ/RocketMQ\n-------------------------------\n\n### 5.1 Kafka特性\n\n*   **高吞吐、低延迟：** kakfa最大的特点就是收发消息非常快，kafka每秒可以处理几十万条消息，它的最低延迟只有几毫秒；\n*   **高伸缩性：** 如果可以通过增加分区partition来实现扩容。不同的分区可以在不同的Broker中。通过ZK来管理Broker实现扩展，ZK管理Consumer可以实现负载；\n*   **持久性、可靠性：** Kafka能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失；\n*   **容错性：** 允许集群中的节点失败，某个节点宕机，Kafka集群能够正常工作；\n*   **高并发：** 支持数千个客户端同时读写。\n\n### 5.2 Kafka对比RabbitMQ\n\n*   产品侧重：kafka:流式消息处理、消息引擎；RabbitMQ:消息代理。\n*   性能：kafka有更高的吞吐量。RabbitMQ主要是push, kafka只有pull。\n*   消息顺序：分区里面的消息是有序的，同一个consumer group里面的一个消费者只能消费一个partition,能保证消息的顺序性。\n*   消息的路由和分发：RabbitMQ更加灵活。\n*   延迟消息、死信队列：RabbitMQ支持。\n*   消息的留存：kafka消费完之后消息会留存，RabbitMQ消费完就会删除。Kafka可以设置retention,清理消息。\n\n**优先选择RabbitMQ的情况：**\n\n*   高级灵活的路由规则；\n*   消息时序控制（控制消息过期或者消息延迟）；\n*   高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）;\n*   更简单的消费者实现。\n\n**优先选择Kafka的情况：**\n\n*   严格的消息顺序；\n*   延长消息留存时间，包括过去消息重放的可能；\n*   传统解决方案无法满足的高伸缩能力。\n\n### 5.3 MQ选型分析\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417132358379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n6、Kafka参数配置说明\n-------------\n\n### 6.1 Kafka生产者参数配置\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417140452763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 6.2 Kafka服务端参数配置\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417135422252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 6.3 Kafka消费者参数配置\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417135759333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 6.4 Kafka增加数据可靠性的配置\n\n1.  设置acks = all。acks是Producer的一个参数，代表已提交消息的定义。如果设置成all,则表明所有Broker都要接收到消息，该消息才算是”已提交”。\n2.  设置retries为一个较大的值。同样是Producer的参数。当出现网络抖动时，消息发送可能会失败，此时配置了retries的Producer能够自动重试发送消息，尽量避免消息丢失。\n3.  设置 unclean.leader.election.enable=false。\n4.  设置replication.factor >= 3。需要三个以上的副本。\n5.  设置min.insync.replicas > 1。Broker端参数，控制消息至少要被写入到多少个副本才算是\"已提交\"。设置成大于1可以提升消息持久性。在生产环境中不要使用默认值1。确保replication.factor > min.insync.replicas。如果两者相等，那么只要有 —个副本离线整个分区就无法正常工作了。推荐设置成replication.factor = min.insync.replicas + 1。\n6.  确保消息消费完成再提交。Consumer端有个参数enable.auto.commit,最好设置成false,并自己来处理offset的提交更新。\n\n","source":"_posts/kafka.md","raw":"---\ntitle: Kafka消息中间件\n---\n\n1、Kafka概述\n---------\n\n### 1.1 Kafka定义\n\nApache Kafka 是一款开源的消息系统。可以在系统中起到“肖峰填谷”的作用，也可以用于异构、分布式系统中海量数据的异步化处理。\n\n### 1.2 Kafka使用场景\n\n*   **消息中间件：** 作为消息中间件进行消息传递，作为TCP HTTP或者RPC的替代方案，可以实现异步、解耦、削峰（RabbitMQ和RocketMQ能做的事情，它也能做）。因为kafka的吞吐量更高，在大规模消息系统中更有优势。\n*   **大数据领域：** 例如日志归集、行为跟踪、应用监控。\n*   **数据集成+流计算：** 对流式数据进行继承和实时计算。\n\n2、Kafka服务端基本认识\n\n\n目前比较流行的服务端管理界面主要是 kafka-manager 和 kafka-eagle （国产）。\n\n### 2.1 Kafka与ZK的关系\n\n总结起来：利用ZK的有序节点、临时节点和监听机制，ZK帮kafka做了这些事情：配置中心(管理Broker、Topic、Partition、Consumer的信息，包括元数据的变动)、负载均衡、命名服务、分布式通知、集群管理和选举、分布式锁。\n\n### 2.2 Kafka脚本介绍\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417112654325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n3、Kafka架构分析\n-----------\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417113222162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 3.1 Broker\n\nKafka作为一个中间件，是帮我们存储和转发消息的，它做的事情有点像中介，所以我们把kafka的服务叫做Broker，默认是9092的端口。生产者和消费者都需要跟这个Broker建立一个连接，才可以实现消息的收发。\n\n### 3.2 消息\n\n客户端之间传输的数据叫做消息，或者叫做记录（Record）。在客户端的代码中，Record可以是一个KV键值对，生产者的封装类是ProducerRecord，消费者的封装类是ConsumerRecord。  \n  消息在传输过程中需要序列化，所以在代码中要指定序列化工具。\n\n### 3.3 生产者\n\n发送消息的一方叫做生产者。为了提升发送效率，生产者不是逐条发送消息给Broker，而是批量发送的，发送的数据大小和时间间隔由以下参数决定：\n\n    batch.size=16384\n    linger.ms=0\n\n\n### 3.4 消费者\n\n接收消息的一方叫做消费者。  \n  —般来说消费者获取消息有两种模式，一种是pull模式，一种是push模式。Pull模式就是消费放在Broker,消费者自己决定什么时候去获取。Push模式是消息放在Consumer，只要有消息到达Broker,都直接推给消费者。  \n  Kafka只支持pull模式，因为在push模式下，如果消息产生速度远远大于消费者消费消息的速率，那消费者就会不堪重负（你已经吃不下了，但是还要不断地往你嘴里塞），直到挂掉。而且在pull模式下消费者一次pull获取多少条消息由以下参数决定：\n\n    max.poll.records=500\n\n\n### 3.5 Topic\n\n生产者跟消费者是怎么关联起来的呢？或者说，生产者发送的消息，怎么才能到达某个特定的消费者？他们要通过队列关联起来，也就是说，生产者发送消息，要指定发给哪个队列。消费者接收消息，要指定从哪个队列接收。在Kafka里面，这个队列叫做Topic。它是一个逻辑的概念，可以理解为一组消息的集合（用以区分不同业务用途的消息）。  \n  注意，生产者发送消息时，如果Topic不存在，会自动创建。由以下参数决定：\n\n    auto.create.topics.enable=true\n\n\n### 3.6 Partition\n\n如果说一个Topic中的消息太多，会带来两个问题：  \n  第一个是不方便横向扩展，比如我想要在集群中把数据分布在不同的机器上实现扩展，而不是通过升级硬件做到，如果一个Topic的消息无法在物理上拆分到多台机器的时候，这个是做不到的。  \n  第二个是并发或者负载的问题，所有的客户端操作的都是同一个Topic,在高并发的场景下性能会大大下降。  \n  怎么解决这个问题呢？我们想到的就是把一个Topic进行拆分。 Kafka引入了一个分区(Partition)的概念。一个Topic可以划分成多个分区。 分区在创建topic的时候指定，每个topic至少有一个分区。  \n  在创建topic时需要指定分区数由以下参数决定：\n\n    num.partitions=1\n\n\nPartition思想上有点类似于分库分表，实现的也是横向扩展和负载的目的。举个例子，Topic有3个分区，生产者依次发送9条消息，对消息进行编号。 第一个分区存1 4 7,第二个分区存2 5 8,第三个分区存3 6 9，这个就实现了负载。\n\n### 3.7 Replica\n\n如果partition的数据只存储一份，在发生网络或者硬件故障的时候，该分区的数据就无法访问或者无法恢复了。  \n  Kafka在0.8的版本之后增加了副本机制。每个partition可以有若干个副本(Replica)，副本必须在不同的Broker 上面。—般我们说的副本包括其中的主节点。由 replication-factor指定一个Topic 的副本数。默认副本数由以下参数决定\n\n    offsets.topic.replication.factor=1\n\n\n举例：部署了 3个Broker,该topic有3个分区，每个分区一共3个副本。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417123522406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  注意：这些存放相同数据的partition副本有leader（图中红色）和follower（图中绿色）的概念。leader在哪台机器是不一定的，选举岀来的。\n\n### 3.8 Segment\n\nKafka的数据是放在后缀.log的文件里面的。如果一个partition只有一个log文件，消息不断地追加，这个log文件也会变得越来越大，这个时候要检索数据效率就很低了。所以干脆把partition再做一个切分，切分岀来的单位就叫做段（segment）。实际上kafka的存储文件是划分成段来存储的。默认存储路径：/tmp/kafka-logs/ 。每个segment都有至少有1个数据文件和2个索引文件，这3个文件是成套出现的。\n\n### 3.9 Consumer Group\n\n我们知道消息中间件一般会支持发布/订阅模式和广播模式，那么在Kafka中是如何实现的呢？或者换一种问法，当多个消费者订阅了同一个topic的时候，该如何区分这条消息是要单发还是群发呢？  \n  Kafka引入了消费者组Consumer Group的概念，通过group.id来配置，group.id相同的消费者属于同一个消费者组，Kafka对不同消费者组进行广播，而同一个消费者组中的消费者只消费一次消息。  \n  具体点说，同一个消费者组的消费者不能订阅相同的分区。当消费者数量小于分区数时，一个消费者消费多个分区，当消费者数量大于分区数时，多余的消费者将不进行工作。\n\n### 3.10 Consumer Offset\n\n我们已经知道Kafka消息是写在日志文件中，并且不会在消费过后就被删除。那么当一个消费者组在消费一半时重启了，该如何继续上一次的位置读取消息呢？为此，Kafka引入Consumer Offset的概念。  \n  Consumer Offset是标记一个消费者组在一个partition即将消费的下一条记录，这个信息直接保存在Kafka本身一个特殊的topic中，叫\\_\\_consumer\\_offsets，默认创建50个分区。\n\n4、Kafka原理\n---------\n\n### 4.1 Kafka生产者原理\n\n#### 4.1.1 生产者发送流程\n\n消息发送的整体流程。生产端主要由两个线程协调运行。这两条线程分别为main线程和sender线程（发送线程）。  \n  在创建KafkaProducer的时候，创建了一个Sender对象，并且启动了—个IO线程。\n\n##### 4.1.1.1 拦截器\n\n第二步是执行拦截器的逻辑，在producer.send方法中:\n\n    ProducerRecord<K, V> interceptedRecord = this.interceptors.onSend(record);\n\n\n拦截器的作用是实现消息的定制化（类似于Spring Interceptor、MyBatis的插件、Quartz的监听器）。那这个拦截器是在哪里定义的呢？生产者代码：\n\n    List<String> interceptors = new ArrayList<>(); \n    interceptors.add(\" com.xxx.interceptor.Charginginterceptor\"); \n    props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n\n\n举个例子，假设发送消息的时候要扣钱，发一条消息1分钱（我把这个功能叫做按量付费），就可以用拦截器实现。\n\n    public class Charginginterceptor implements ProducerInterceptor<String, String> {\n    \t//发送消息的时候触发\n    \t@Override\n    \tpublic ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n    \t \tSystem.out.println(\"1分钱1条消息，不管那么多反正先扣钱”);\n    \t\treturn record;\n    \t}\n    \n    \t//收到服务端的ACK的时候触发\n    \t@Override\n    \tpublic void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    \t\tSystem.out.pnntln(n消息被服务端接收啦”);\n    \t}\n    \t\n    \t@Override \n    \tpublic void close() {\n    \t\tSystem.out.printin(”生产者关闭了\");\n    \t}\n    \t\n    \t//用键值对配置的时候触发\n    \t@Override\n    \tpublic void configure(Map<String, ?> configs) {\n    \t\tSystem. out.piintln(n configure...H);\n    \t}\n    }\n\n\n##### 4.1.1.2 序列化\n\n接下来是利用指定的工具对key和value进行序列化：\n\n    serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());\n\n\nkafka针对不同的数据类型自带了相应的序列化工具。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417162458711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  除了自带的序列化工具之外，可以使用如Avro、JSON、Thrift. Protobuf等，或者使用自定义类型的序列化器来实现，实现Serializer接口即可。\n\n##### 4.1.1.3 分区路由\n\n然后是分区指定：\n\n    int partition = partition(record, serializedKey, serialized Value, cluster);\n\n\n一条消息会发送到哪个partition呢？它返回的是一个分区的编号，从0开始。有四种情况:\n\n1.  指定了partition——直接将指定的值直接作为partiton值。\n2.  没有指定partition,自定义了分区器——将使用自定义的分区器算法选择分区。\n3.  没有指定partition,没有自定义分区器，但是key不为空——使用默认分区器DefaultPartitioner,将  \n    key的hash值与topic的partition数进行取余得到partition值；\n4.  没有指定partition,没有自定义分区器，但是key是空的——第一次调用时随机生成一个整数(后面每次调用在这个整数上自增)，将这个值与topic可用的partition总数取余得到 partition值，也就是常说的round-robin算法。\n\n##### 4.1.1.4 消息累加器\n\n选择分区以后并没有直接发送消息，而是把消息放入了消息累加器：\n\n    RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptcallback, remainingWaitMs);\n\n\nRecordAccumulator 本质上是一个 ConcurrentMap:\n\n    ConcurrentMap<TopicPailition Deque<ProducerBatc>> batches;\n\n\n—个partition —个Batch。batch满了之后，会唤醒Sender线程，发送消息:\n\n    if (result.batchlsFull || result.newBatchCreated) {\n    \tlog.trace(Waking up the sender since topic {} partition {} is either full or getting a new batch\", record.topic(), partition);\n    \tthis.sender.wakeup();\n    }\n\n\n#### 4.1.2 消息应答机制ACK\n\n##### 4.1.2.1 服务端响应策略\n\n生产者的消息是不是发出去就完事了？如果说网络出了问题，或者说kafka服务端接收的时候出了问题，这个消息发送失败了，生产者是不知道的。所以，kafka服务端应该要有一种响应客户端的方式，只有在服务端确认以后，生产者才发送下一轮的消息，否则重新发送数据。  \n  服务端什么时候才算接收成功呢？因为消息是存储在不同的partition里面的，所以是写入到partition之后响应生产者。当然，单个partition (leader)写入成功，还是不够可靠，如果有多个副本，follower 也要写入成功才可以。  \n  为了安全性考虑，Kafka会等待所有的follower全部完成同步，才发送ACK给客户端，延迟相对来说高一些，但是节点挂掉的影响相对来说小一些，因为所有的节点数据都是完整的。\n\n##### 4.1.2.2 ISR\n\n然而以上方案仍然存在问题：假设leader收到数据，所有follower都开始同步数据，但是有一个follower出了问题，没有办法从leader同步数据。按照这个规则，leader就要一致等待，无法发送 ack。  \n  从概率的角度来讲，这种问题肯定是会出现的，就是某个follower出问题了，怎么解决呢？所以我们的规则就不能那么粗暴了，把规则改一下，不是所有的follower都有权利 让我等待，而是只有那些正常工作的follower同步数据的时候我才会等待。  \n  我们应该把那些正常和leader保持同步的replica维护起来，放到一个动态set里面，这个就叫做in-sync replica set (ISR)。现在只要ISR里面的follower同步完数据之后，我就给客户端发送ACK。如果一个follower长时间不同步数据，就要从ISR剔除。同样，如果后面这个follower重新与leader保持同步，就会重新加入ISR。时间间隔由以下参数决定：\n\n    replica.lag.time.max.ms=10000\n\n\n##### 4.1.2.3 ACK应答\n\n当然，如果所有的数据都一视同仁，而且这种策略只能由服务端决定，这就不是很灵活了。有一些数据丢了无所谓，我只想要快，不管它落没落盘同没同步，怎么办呢？  \n  Kafka为客户端提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择相应的配置。\n\n*   **acks=0：** producer不等待broker的ack,这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；\n*   **acks=1（默认）：** producer 等待 broker 的 ack, partition 的 leader 落盘成功后 返回ack,如果在follower同步成功之前leader故障，那么将会丢失数据；\n*   **acks=-1 (all) ：** producer等待 broker 的 ack, partition 的 Ieader和 follower全部落盘成功后才返回ack。\n\n三种机制，性能依次递减（producer吞吐量降低），数据健壮性则依次递增。我们可 以根据业务场景使用不同的参数。\n\n### 4.2 Kafka消息存储原理\n\n#### 4.2.1 数据存储目录\n\n目录配置在配置文件config/env.properties，由以下参数决定：\n\n    logs.dir=/tmp/kafka-logs\n\n\n#### 4.2.2 partition分区\n\n为了实现横向扩展，把不同的数据存放在不同的Broker上,同时降低单台服务器的访问压力，我们把一个topic中的数据分隔成多个partition。—个partition中的消息是有序的，顺序写入，但是全局不一定有序。  \n  在服务器上，每个partition都有一个物理目录，topic名字后面的数字标号即代表分区。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417170640277.png)\n\n#### 4.2.3 replica副本\n\n为了提高分区的可靠性，kafka又设计了副本机制。创建topic的时候，通过指定replication-factor确定topic的副本数。  \n  注意：副本数必须小于等于节点数，而不能大于Broker的数量，否则会报错。  \n  这些所有的副本分为两种角色，leader对外提供读写服务。follower唯一的任务就是从leader异步拉取数据。\n\n#### 4.2.4 副本分布规则\n\n副本在Broker的分布有什么规则吗？例如有个topic：a4part2rep, 4个分区每个2个副本，一共8份副本，怎么分布到3台机器呢？  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417171144308.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  实际副本分布规则是由AdminUtils.scala——assignReplicasToBrokers决定的，具体规则如下：\n\n1.  副本因子不能大于Broker的个数；\n2.  第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；\n3.  其他分区的第一个副本放置位置相对于第0个分区依次往后移 （nextReplicaShift）。\n\n这样设计可以提高容灾能力。在每个分区的第一个副本错开之后，一般第一个分区的第一个副本（按Broker编号排序）都是leader。leader是错开的，不至于一挂影响太大。\n\n#### 4.2.5 Segment\n\n为了防止log不断追加导致文件过大，导致检索消息效率变低，一个partition又被划分成多个segment来组织数据。在磁盘上，每个segment由一个log文件和2个index文件组成。这三个文件是成套出现的。另外还有一个leader-epoch-checkpoint文件中保存了每一任leader开始写入消息时的offset。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418150929793.png)\n\n1 .log日志文件（日志就是数据）  \n  在一个segment文件里面，日志是追加写入的。如果满足一定条件，就会切分日志文件，产生一个新的segment什么时候会触发segment的切分呢？  \n  第一种是根据日志文件大小。当一个segment写满以后，会创建一个新的segment, 用最新的offset作为名称。文件大小由以下参数控制（默认1G）：\n\n    log.segment.bytes=1073741824\n\n\n第二种是根据消息的最大时间戳，和当前系统时间戳的差值。还可以从更加精细的时间单位进行控制，如果配置了毫秒级别的日志切分间隔，会优先使用这个单位。否则就用小时的。间隔时间由以下参数决定：\n\n    log.roll.hours=168\n    log.roll.ms\n\n\n还有第三种情况，offset索引文件或者timestamp索引文件达到了一定的大小。由参数**log.index.size.max.bytes（默认10M）** 控制。如果要减少日志文件的切分，可以把这个值调大一点。  \n2\\. .index偏移量(offset)索引文件  \n3\\. .timeindex 时间戳(timestamp)索引文件\n\n#### 4.2.6 索引\n\n由于一个segment的文件里面可能存放很多消息，如果要根据offset获取消息，必须要有一种快速检索消息的机制。这个就是索引。在Kafka中设计了两种索引：偏移量索引文件记录的是。offset和消息物理地址（在log文件中的位置）的映射关系。时间戳索引文件记录的是时间戳和offset的关系。  \n  内容是二进制的文件，不能以纯文本形式查看。bin目录下有dumplog工具。 查看最后10条offset索引：\n\n    ./kafka-dump-log.sh —files /tmp/kafl<a-logs/mytopic-0/00000000000000000000.index|head -n 10\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418154758336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n注意，Kafka的索引并不是每一条消息都会建立索引，而是一种稀疏索引sparse index（DB2和Mongdb中都有稀疏索引）。至于这个索引有多稀疏，由以下参数决定：\n\n    log.index.interval.bytes=4096\n\n\n只要写入的消息超过了 4KB,偏移量索引文件index和时间戳索引文件.timeindex就会増加一条索引记录(索引项)。这个值设置越小，索引越密集。值设置越大，索引越稀疏。相对来说，越稠密的索引检索数据更快，但是会消耗更多的存储空间。越的稀疏索引占用存储空间小，但是插入和删除时所需的维护开销也小。Kafka索引的时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。  \n  第二种索引类型是时间戳索引。时间戳有两种，一种是消息创建的时间戳，一种是消费在Broker追加写入的时间。到底用哪个时间由以下参数控制：\n\n    log.message.timestamp.type=CreateTime\n\n\n默认是创建时间。如果要改成日志追加时间，则修改为LogAppendTime。査看最早的10条时间戳索引：\n\n    ./kafka-dump-log.sh —files /tmp/kafka-logs/mytopic-0/00000000000000000000.timeindex|head -n 10\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418154859613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  那么Kafka如何基于索引快速检索消息？比如我要检索偏移量是10002673的消息。\n\n1.  消费的时候是能够确定分区的，所以第一步是找到在哪个segment中。Segment 文件是用base offset命名的，所以可以用二分法很快确定（找到名字不大于10002673 的 最大segment）。\n2.  这个segment有对应的索引文件，它们是成套出现的。所以现在要在索引文件中根据offset找position。\n3.  得到position之后，到对应的log文件开始査找offset,和消息的offset进行比较，直到找到消息。  \n    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418155346397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n#### 4.2.7 日志清理策略\n\n由于Kafka的日志并没有在消费后马上删除，随着时间的推移，日志越来越多，需要有相应的清理策略来保证系统的健康，日志清理的开关由以下参数控制：\n\n    log.cleaner.enable=true\n\n\nKafka提供了两种清理方式，分别是删除delete和压缩compact，由以下参数控制：\n\n    log.cleanup.policy=delete\n\n\n日志删除的功能是由定时任务完成的，定时任务运行的时间间隔由以下参数控制：\n\n    log.retention.check.interval.ms=300000\n\n\n删除多久以前的数据由以下参数控制（精度越小优先级越高）：\n\n    log.retention.hours=168\n    log.retention.minutes\n    log.retention.ms\n\n\n还可以根据保留日志的大小来删除数据，超出该大小则删除最早的数据，由以下参数控制（默认-1代表不限制）：\n\n    log.retention.bytes=-1\n\n\n若采取压缩的清理方式，则会根据相同的key进行压缩，当消息的key相同时，只保留最新的value。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418164159281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n#### 4.2.8 Controller选举\n\n当创建添加一个的分区或者分区增加了副本的时候，都要从所有副本中选举一个新的Leader出来。  \n  投票怎么玩？是不是所有的partition副本直接发起投票，开始竞选呢？比如用ZK 实现。  \n  利用ZK怎么实现选举？ZK的什么功能可以感知到节点的变化（增加或者减少）? 或者说，ZK为什么能实现加锁和释放锁？  \n  3个特点：watch机制；节点不允许重复写入；临时节点。  \n  这样实现是比较简单，但是也会存在一定的弊端。如果分区和副本数量过多，所有的副本都直接进行选举的话，一旦某个出现节点的增减，就会造成大量的watch事件被触发，ZK的负载就会过重。  \n  Kafka早期的版本（0.82及以前）就是这样做的，后来换了一种实现方式。  \n  不是所有的repalica都参与leader选举，而是由其中的一个Broker统一来指挥， 这个Broker的角色就叫做Controller（控制器）。  \n  就像Redis Sentinel的架构，执行故障转移的时候，必须要先从所有哨兵中选一个负责做故障转移的节点一样。Kafka也要先从所有Broker中选出唯一的一个Controller，所有的Broker会尝试在zookeeper中创建临时节点/controller,只有一个能创建成功（先到先得）。  \n  如果Controller挂掉了或者网络出现了问题，ZK上的临时节点会消失。其他的Broker通过watch监听到Controller下线的消息后，开始竞选新的Controller。方法跟之前还是一样的,谁先在ZK里面写入一个/controller节点,谁就成为新的Controller。  \n  一个节点成为Controller之后，它肩上的责任也比别人重了几份，正所谓劳力越戴, 责任越大：\n\n*   监听Broker变化。\n*   监听Topic变化。\n*   监听Partition变化。\n*   获取和管理Broker、Topic、Partition的信息。\n*   管理Partiontion的主从信息。\n\n#### 4.2.9 分区副本Leader选举\n\nController确定以后，开始进行leader选举。副本有3个概念：\n\n*   **Assigned-Replicas (AR)**：一个分区的所有副本\n*   **In-Sync Replicas (ISR)**：一个分区中跟leader数据保持一定程度的同步的副本\n*   **Out-Sync-Replicas (OSR)**：跟leader副本同步滞后过多的副本\n\n只有ISR有资格参加leader选举。而且这个ISR不是固定不变的，它是一个动态的列表。  \n如果同步延迟超过30秒，就踢出ISR，进入OSR。如果赶上来了， 就加入ISR。默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader。极端情况下，如果ISR为空，则可以允许ISR之外的副本参与选举，由以下参数控制：\n\n    unclean.leader.election.enable=true\n\n\n注意，这种情况下可能造成数据丢失。  \n  那么leader的选举规则是什么呢？它使用一种类似微软的PacificA算法，在这种算法中，默认是让ISR中第一个replica变成leader。比如ISR是1、5、9, 优先让1成为leader。这个跟中国古代皇帝传位是一样的，优先传给皇长子。\n\n#### 4.2.10 主从同步\n\nLeader确定之后，客户端的读写只能操作leader节点。follower需要向leader同步数据。不同的raplica的offset是不一样的，同步到底怎么同步呢？  \n  首先需要认识几个概念：  \n**LEO (Log End Offset)：** 下一条等待写入的消息的offset (最新的offset + 1),图中分别是9, 8, 6。  \n**HW (Hign Watermark):** ISR中最小的LEO。Leader会管理所有ISR中最小的 LEO作为HW,目前是6。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418214659821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  consumer最多只能消费到HW之前的位置(消费到offset 5的消息)。也就是说: 其他的副本没有同步过去的消息，是不能被消费的。  \n  有了这两个offset之后，再来看看消息怎么同步：\n\nfollowerl同步了1条消息，follower2同步了2条消息。此时HW推进了2,变成8。![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418214946178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  followerl同步了0条消息，follower2同步了1条消息。此时HW推进了1，变成9。LEO和HW重叠，所有的消息都可以消费了。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418215103808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  这里，我们关注一下，从节点怎么跟主节点保持同步？\n\n1.  follower节点会向Leader发送一个fetch请求，leader向follower发送数据后，既需要更新follower的LEO。\n2.  follower接收到数据响应后，依次写入消息并且更新LEO。\n3.  leader 更新 HW （ISR 最小的 LEO）。\n\nkafka设计了独特的ISR复制，可以在保障数据一致性情况下又可提供高吞吐量。\n\n#### 4.2.11 replica故障处理\n\n##### 4.2.11.1 follower故障\n\n首先follower发生故障，会被先踢出ISR。follower恢复之后，从哪里开始同步数据呢？假设第1个replica宕机（中间这个）。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210418220330233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  恢复以后，首先根据之前记录的HW （6）,把高于HW的消息截掉（6、7）。然 后向leader同步消息。追上leader之后（30秒），重新加入ISR。\n\n##### 4.2.11.2 leader故障\n\n假设图中leader发生故障。首先选一个leader。因为replica 1 （中间这个）优先，它成为leader。为了保证数据一致，其他的follower需要把高于HW的消息截取掉（这里没有消息需要截取）。然后replica2同步数据。注意：这种机制只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。\n\n##### 4.2.11.3 上面这两种方式没有问题吗？（全文重点！！！）\n\n实际上，副本同步机制并没有上面说的那么简单。假设有A(leader)、B两个副本——  \n  作为leader，A还会维护每个副本的远程LEO值remoteLEO;  \n  作为follower，B会定时发送fetch请求给A拉取数据，在fetch时将自己当前的LEO和HW发送给A。  \n1）初始化状态时：  \n  LEO(A)=0, HW(A)=0，remoteLEO=0;  \n  LEO(B)=0，HW(B)=0;\n\n2）当生产者发送一条数据m1时：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=0，HW(B)=0;\n\n3）B向A发起fetch请求，发送自己当前的LEO给A：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=0，HW(B)=0;\n\n4）A根据B发送的LEO,更新remoteLEO=0，更新HW(A)=min(LEO(A), remoteLEO(B))=0，同时将HW(A)和未同步的数据m1发送给B：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=0，HW(B)=0;\n\n5）B根据A返回的HW(A)，写入数据m1，同时更新LEO(B)=1，HW(B)=min(HW(A), LEO(B))=0，  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=1，HW(B)=0;\\[m1\\]\n\n6）B向A发起第二次fetch请求，发送自己当前的LEO(B)=1：  \n  LEO(A)=1, HW(A)=0，remoteLEO=0;\\[m1\\]  \n  LEO(B)=1，HW(B)=0;\\[m1\\]\n\n7）此时A更新remoteLEO=1，HW(A)=min(LEO(A), remoteLEO(B))=1，同时返回HW给B：  \n  LEO(A)=1, HW(A)=1，remoteLEO=1;\\[m1\\]  \n  LEO(B)=1，HW(B)=0;\\[m1\\]\n\n8）B根据A返回的HW(A)，更新HW(B)=min(HW(A), LEO(B))=1，  \n  LEO(A)=1, HW(A)=1，remoteLEO=1;\\[m1\\]  \n  LEO(B)=1，HW(B)=1;\\[m1\\]\n\n这是一轮常规的数据同步，设想一下，当leader或者follower出现故障时，会导致什么问题？我们知道可以通过acks来控制消息的可靠性，那么当acks=-1(all)的时候是否数据一定不会丢失？  \n  首先，我们要明白数据丢失的概念，一定是在leader返回ack但是数据不存在的情况下才叫数据丢失，如果leader没有返回ack，也就是说生产者知道消息没发送成功的话，不算数据丢失。那么假设acks=-1的话，实际上leader是在步骤7）执行完毕后就返回ack给生产者。在这个前提下我们分析几个场景。  \n场景一：  \n  假设ISR中只有一个leader副本，且成功写入数据。此时leader挂掉，若参数设置允许OSR中的副本抢占leader的话，可能导致数据丢失。  \n  这种场景系统也无法处理，所以Kafka交给用户自行选择，若unclean.leader.election.enable=true则无法保证消息的可靠性，若unclean.leader.election.enable=false则无法保证系统的效率和可用性。  \n场景二：  \n  在执行完步骤7）之后B挂掉了，而当B重启之后（注意此时HW(B)=0），根据4.2.11.1的做法，会先将超出HW(B)的消息m1抛弃，重新从A拉取数据。更极端的情况下，此时A恰好也挂掉，这时候B就会通过选举成为leader。而A重启之后成为follower，会通过截取m1的方式与leader保持同步。至此，消息m1丢失。更严重的是，若A重启之前，B又接收了生产者发送的新的数据m2，那么A重启后由于HW(A)=1，将不会从B拉取到消息m2，结果如下：  \n  LEO(A)=1, HW(A)=1，remoteLEO=1;\\[m1\\]  \n  LEO(B)=1，HW(B)=1;\\[m2\\]\n\n鉴于场景2，Kafka在0.11版本后增加了一个**leader-epoch-checkpoint**的概念，以文件的形式保存在日志目录下，当一个新的leader在写入第一条消息时，会在文件中记录一条信息，包括leader年代（即leader更换次数）epoch和当前leader写入的第一个offset。  \n  举个例子，当这个分区写入第一条消息时，leader-epoch-checkpoint文件中会记录一条信息（0 0），在写入50条消息之后leader挂掉并发生选举，leader-epoch-checkpoint会增加一条记录（1 50）。  \n  有了这种机制，当follower重启之后就不需要直接丢弃HW之后的数据，而是会发起一次请求对比leader中的epoch与自身的epoch：  \n  若epoch相等则只丢弃自身LEO大于leader的LEO的部分（即，若自身LEO不大于leader的LEO则不进行截取，与原来直接截取到HW有所差别）；  \n  若epoch不相等（自身小于leader的LEO）则将自身LEO与leader-epoch-checkpoint中epoch大于自身epoch的最小值的LEO相比较，丢弃自身LEO大于该LEO的数据。\n\n这部分有点绕，以刚才的例子说明，假设步骤7）执行完毕后B重启，此时：  \n  若B重启期间未发生leader选举，则A的leader-epoch-checkpoint文件与B一致，都是(0 0)，即epoch(A)=epoch(B),此时LEO(B)=LEO(A)=1，无需截取。  \n  若B重启期间发生过leader选举（假设存在副本C、D），则leader-epoch-checkpoint文件存在多条记录(0 0)，(1 10)，(2 50)（又发生两次选举），此时B的epoch小于2，会将B的LEO与10比较（大于epoch(B)的最小epoch是1），同样不会丢弃数据。  \n  以上，就是0.11版本Kafka的数据同步方案。\n\n### 4.3 Kafka消费者原理\n\n#### 4.3.1 Offset的维护\n\n##### 4.3.1.1 Offset的存储\n\n我们知道在partition中，消息是不会删除的，所以才可以追加写入，写入的消息连续有序的。这种特性决定了 kafka可以消费历史消息，而且按照消息的顺序消费指定消息，而不是只能消费队头的消息。正常情况下，我们希望消费没有被消费过的数据，而且是从最先发送（序号小的） 的开始消费（这样才是有序和公平的）。  \n  那么对于一个partition,消费者组怎么才能做到接着上次消费的位置（offset）继续消费呢？肯定要把这个对应关系保存起来，下次消费的时候查找一下。  \n  首先这个对应关系确实是可以查看的。比如消费者组gp-assign-group-1和 ass5part （5个分区）的partition的偏移量关系，可使用如下命令査看：\n\n    ./kafka-consumer-groups.sh “bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 —describe —group gp-assign-group-1\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419010135861.png)\n\n*   CURRENT-OFFSET指的是下一个未使用的offset。\n*   LEO , Log End Offset:下一条等待写入的消息的offset （最新的offset + 1）\n*   LAG是延迟量\n\n注意：这不是表示一个消费者和一个Topic的关系，而是一个consumer group和topic中的一个partition的关系（offset在partition中连续编号而不是全局连续编号）。\n\n那么这个对应关系到底是保存在哪里的呢？  \n  首先肯定是不可能放在消费者本地的。因为所有的消费者都可以使用这个consumer group id，放在本地是做不到统一维护的，肯定要放到服务端。  \n  Kafka早期的版本把消费者组和partition的offset直接维护在ZK中，但是读写的性能消耗太大了。后来就放在一个特殊的topic中，名字叫—consumer_offsets，默认有 50 个分区(offsets.topic.num.partitions 默认是 50)，每个分区默认一个replication。\n\n    ./kafka・topics・sh —topic  \tconsumer_offsets —describe —zookeeper localhost:2181\n\n\n那么这样一个特殊的Topic怎么存储消费者组gp-assign-group-1对于分区的偏移量的？Topic里面是可以存放对象类型的value的（经过序列化和反序列化）。这个Topic 里面主要存储两种对象：  \n  GroupMetadata:保存了消费者组中各个消费者的信息（每个消费者有编号）。  \n  OffsetAndMetadata:保存了消费者组和各个partition的offset位移信息元数据。\n\n    ./kafka-console-consumer.sh —topic consumer_offsets --bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 -formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" —from-beginning\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2021041901084354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  怎么知道一个consumer group的offset会放在这个特殊的Topic的哪个分区呢? 可以通过哈希取模计算得到：\n\n    Math.abs(\"gp-assign-group-1\".hashCode()) % 50;\n\n\n##### 4.3.1.2 如果找不到Offset\n\n如果增加了一个新的消费者组去消费—个topic的某个partion,没有offset的记录，这个时候应该从哪里开始消费呢？ 由以下参数控制：\n\n    auto.offset.reset=latest\n\n\n**latest：** 从最新的消息（最后发送的）开始消费。  \n**earliest：** 从最早的（最先发送的）消息开始消费。可以消费到历史消息。  \n**none：** 如果consumer group在服务端找不到offset会报错。\n\n##### 4.3.1.3 Offset的更新\n\n我们知道消费者组的offset是保存在Broker的，但是是由消费者上报给 Broker的。并不是消费者组消费了消息，Offset就会更新，消费者必须要有一个commit （提交）的动作。消费者可以自动提交或者手动提交。由以下参数控制：\n\n    enable.auto.commit=true\n\n\n另外还可以使用一个参数来控制自动提交的频率：\n\n    auto.commit.interval.ms=5000\n\n\n如果我们要在消费完消息做完业务逻辑处理之后才commit,就要把这个值改成 false。如果是false,消费者就必须要调用一个方法让Broker更新offset。有两种方式：  \n  consumer.commitSync()手动同步提交。  \n  consumer.commitAsync()手动异步提交。  \n  如果不提交或者提交失败,Broker的Offset不会更新，消费者下次消费的时候会受到重复消息。\n\n#### 4.3.2 消费者和消费策略\n\n##### 4.3.2.1 分区分配策略\n\n我们已经知道，在同一个消费者组中，一个分区只能被一个消费者消费。所以当消费者数量大于分区数量时，多余的消费者是无法消费消息的。那么如果分区数大于消费者数呢，Kafka又是如何分配的？  \n  为了保证系统最大的利用率，Kafka的分配策略一定会遵循一个最基本的原则——平均分配，简单理解，不会有任意两个消费者消费的分区数差大于1。在此基础上，Kafka有3种分区分配方式。以8个partition分配给3个consumer为例：  \n**1）Range（范围）**  \n  顾名思义，无需解释。  \n  C1：P0 P1 P2  \n  C2：P3 P4 P5  \n  C3：P6 P7  \n**2）RoundRobin（轮询）**  \n  顾名思义，无需解释。  \n  C1：P0 P3 P6  \n  C2：P1 P4 P7  \n  C3：P2 P5  \n**3）sticky（粘滞）**  \n  粘滞的分配策略较为复杂，它的核心思想是在分区重新分配时保证最小的移动（类似Redis的一致性hash思想，实现方式不同）。\n\n第一次分配类似轮询，结果如下：  \n  C1：P0 P3 P6  \n  C2：P1 P4 P7  \n  C3：P2 P5\n\n假设此时C2挂掉：  \n若按照RoundRobin，结果如下：  \n  C1：P0 P2 P4 P6  \n  C3：P1 P3 P5 P7\n\nsticky结果如下（尽量保证P0 P3 P6 P2 P5不动）：  \n  C1：P0 P3 P6 P1  \n  C3：P2 P5 P4 P7\n\n我们知道在分区分配时是会造成性能损耗的，若采用sticky分配策略可以尽可能减少性能损耗。该思想与Redis的一致性Hash是类似的，只是实现方式不同。\n\n##### 4.3.2.2 分区重分配Rebalance\n\n那么什么时候会触发分区重分配Rebalance呢？显然有两种情况，一种是消费者数量发生变化，一种是分区数量发生变化。Rebalance过程如下：\n\n1.  确定协调者coordinator，通常由集群中负载最小的Broker承担。\n2.  所有consumer向coordinator发送join group请求，确认自己是该组成员。\n3.  coordinator在所有consumer中确定leader（通常是第一个）并由leader确定分区分配结果。\n4.  coordinator向所有consumer发送分区分配结果。\n\n#### 4.3.3 Kafka为什么这么快？\n\n##### 4.3.3.1 顺序读写\n\n首先我们需要了解随机I/O和顺序I/O。  \n  磁盘的构造如图。磁盘的盘片不停地旋转，磁头会在磁盘表面画出一个圆形轨迹，这个就叫磁道。从内到位半径不同有很多磁道。然后又用半径线，把磁道分割成了扇区（两根射线之内的扇区组成扇面）。如果要读写数据, 必须找到数据对应的扇区，这个过程就叫寻址。  \n随机I/O：读写的多条数据在磁盘上是分散的，寻址会很耗时。  \n顺序I/O：读写的数据在磁盘上是集中的，不需要重复寻址的过程。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419015453527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得 Kafka写入吞吐量得到了显著提升。  \n  顺序IO到底有多快呢？下图显示，在一定条件下测试，磁盘的顺序读写可以达到53.2M每秒，比内存的随机读写还要快。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419015622131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n##### 4.3.3.2 索引\n\n我们在写入日志的时候会建立关于Offset和时间的稀疏索引，提升了查找效率，这个上面已经提到过了。\n\n##### 4.3.3.3 批量读写\n\nKafka无论是生产者发送消息还是消费者消费消息都是批量操作的，大大提高读写性能。\n\n##### 4.3.3.4 零拷贝\n\n首先需要了解两个名词。  \n  第一个是操作系统虚拟内存的内核空间和用户空间。操作系统的虚拟内存分成了两块，一部分是内核空间，一部分是用户空间。这样就可以避免用户进程直接操作内核，保证内核安全。进程在内核空间可以执行任意命令，调用系统的一切资源；在用户空间必须要通过  \n—些系统接口才能向内核发出指令。如果用户要从磁盘读取数据(比如kafka消费消息)，必须先把数据从磁盘拷贝到内核缓冲区，然后在从内核缓冲区到用户缓冲区，最后才能返回给用户。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419020156610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  第二个是DMA拷贝。没有DMA技术的时候，拷贝数据的事情需要CPU亲自去做, 这个时候它没法干其他的事情，如果传输的数据量大那就有问题了。DMA技术叫做直接内存访问(Direct Memory Access),其实可以理解为CPU给 自己找了一个小弟帮它做数据搬运的事情。在进行I/O设备和内存的数据传输的时候， 数据搬运的工作全部交给DMA控制器，解放了 CPU的双手。  \n  理解了这两个东西之后，我们来看下传统的I/O模型：  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419020246212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)  \n  比如kafka要消费消息，比如要先把数据从磁盘拷贝到内核缓冲区，然后拷贝到用户缓冲区，再拷贝到socket缓冲区，再拷贝到网卡设备。这里面发生了 4次用户态和内核态的切换和4次数据拷贝，2次系统函数的调用（read、write）,这个过程是非常耗费时间的。怎么优化呢?  \n  在Linux操作系统里面提供了一个sendfile函数（并不是所有操作系统都支持sendfile），可以实现\"零拷贝\"。这个时候就不需要经过用户缓冲区了，直接把数据拷贝到网卡（这里画的是支持SG-DMA拷贝的情况）。因为这个只有DMA拷贝，没有CPU拷贝，所以叫做”零拷贝”。零拷贝至少可以提高一倍的性能。  \n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210419020413177.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n5、MQ选型：Kafka对比RabbitMQ/RocketMQ\n-------------------------------\n\n### 5.1 Kafka特性\n\n*   **高吞吐、低延迟：** kakfa最大的特点就是收发消息非常快，kafka每秒可以处理几十万条消息，它的最低延迟只有几毫秒；\n*   **高伸缩性：** 如果可以通过增加分区partition来实现扩容。不同的分区可以在不同的Broker中。通过ZK来管理Broker实现扩展，ZK管理Consumer可以实现负载；\n*   **持久性、可靠性：** Kafka能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失；\n*   **容错性：** 允许集群中的节点失败，某个节点宕机，Kafka集群能够正常工作；\n*   **高并发：** 支持数千个客户端同时读写。\n\n### 5.2 Kafka对比RabbitMQ\n\n*   产品侧重：kafka:流式消息处理、消息引擎；RabbitMQ:消息代理。\n*   性能：kafka有更高的吞吐量。RabbitMQ主要是push, kafka只有pull。\n*   消息顺序：分区里面的消息是有序的，同一个consumer group里面的一个消费者只能消费一个partition,能保证消息的顺序性。\n*   消息的路由和分发：RabbitMQ更加灵活。\n*   延迟消息、死信队列：RabbitMQ支持。\n*   消息的留存：kafka消费完之后消息会留存，RabbitMQ消费完就会删除。Kafka可以设置retention,清理消息。\n\n**优先选择RabbitMQ的情况：**\n\n*   高级灵活的路由规则；\n*   消息时序控制（控制消息过期或者消息延迟）；\n*   高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）;\n*   更简单的消费者实现。\n\n**优先选择Kafka的情况：**\n\n*   严格的消息顺序；\n*   延长消息留存时间，包括过去消息重放的可能；\n*   传统解决方案无法满足的高伸缩能力。\n\n### 5.3 MQ选型分析\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417132358379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n6、Kafka参数配置说明\n-------------\n\n### 6.1 Kafka生产者参数配置\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417140452763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 6.2 Kafka服务端参数配置\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417135422252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 6.3 Kafka消费者参数配置\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20210417135759333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70)\n\n### 6.4 Kafka增加数据可靠性的配置\n\n1.  设置acks = all。acks是Producer的一个参数，代表已提交消息的定义。如果设置成all,则表明所有Broker都要接收到消息，该消息才算是”已提交”。\n2.  设置retries为一个较大的值。同样是Producer的参数。当出现网络抖动时，消息发送可能会失败，此时配置了retries的Producer能够自动重试发送消息，尽量避免消息丢失。\n3.  设置 unclean.leader.election.enable=false。\n4.  设置replication.factor >= 3。需要三个以上的副本。\n5.  设置min.insync.replicas > 1。Broker端参数，控制消息至少要被写入到多少个副本才算是\"已提交\"。设置成大于1可以提升消息持久性。在生产环境中不要使用默认值1。确保replication.factor > min.insync.replicas。如果两者相等，那么只要有 —个副本离线整个分区就无法正常工作了。推荐设置成replication.factor = min.insync.replicas + 1。\n6.  确保消息消费完成再提交。Consumer端有个参数enable.auto.commit,最好设置成false,并自己来处理offset的提交更新。\n\n","slug":"kafka","published":1,"date":"2024-08-25T09:13:16.278Z","updated":"2024-08-25T09:13:16.279Z","comments":1,"layout":"post","photos":[],"_id":"cm0admg70000354ui0cta4z26","content":"<h2 id=\"1、Kafka概述\"><a href=\"#1、Kafka概述\" class=\"headerlink\" title=\"1、Kafka概述\"></a>1、Kafka概述</h2><h3 id=\"1-1-Kafka定义\"><a href=\"#1-1-Kafka定义\" class=\"headerlink\" title=\"1.1 Kafka定义\"></a>1.1 Kafka定义</h3><p>Apache Kafka 是一款开源的消息系统。可以在系统中起到“肖峰填谷”的作用，也可以用于异构、分布式系统中海量数据的异步化处理。</p>\n<h3 id=\"1-2-Kafka使用场景\"><a href=\"#1-2-Kafka使用场景\" class=\"headerlink\" title=\"1.2 Kafka使用场景\"></a>1.2 Kafka使用场景</h3><ul>\n<li><strong>消息中间件：</strong> 作为消息中间件进行消息传递，作为TCP HTTP或者RPC的替代方案，可以实现异步、解耦、削峰（RabbitMQ和RocketMQ能做的事情，它也能做）。因为kafka的吞吐量更高，在大规模消息系统中更有优势。</li>\n<li><strong>大数据领域：</strong> 例如日志归集、行为跟踪、应用监控。</li>\n<li><strong>数据集成+流计算：</strong> 对流式数据进行继承和实时计算。</li>\n</ul>\n<p>2、Kafka服务端基本认识</p>\n<p>目前比较流行的服务端管理界面主要是 kafka-manager 和 kafka-eagle （国产）。</p>\n<h3 id=\"2-1-Kafka与ZK的关系\"><a href=\"#2-1-Kafka与ZK的关系\" class=\"headerlink\" title=\"2.1 Kafka与ZK的关系\"></a>2.1 Kafka与ZK的关系</h3><p>总结起来：利用ZK的有序节点、临时节点和监听机制，ZK帮kafka做了这些事情：配置中心(管理Broker、Topic、Partition、Consumer的信息，包括元数据的变动)、负载均衡、命名服务、分布式通知、集群管理和选举、分布式锁。</p>\n<h3 id=\"2-2-Kafka脚本介绍\"><a href=\"#2-2-Kafka脚本介绍\" class=\"headerlink\" title=\"2.2 Kafka脚本介绍\"></a>2.2 Kafka脚本介绍</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417112654325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"3、Kafka架构分析\"><a href=\"#3、Kafka架构分析\" class=\"headerlink\" title=\"3、Kafka架构分析\"></a>3、Kafka架构分析</h2><p><img src=\"https://img-blog.csdnimg.cn/20210417113222162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"3-1-Broker\"><a href=\"#3-1-Broker\" class=\"headerlink\" title=\"3.1 Broker\"></a>3.1 Broker</h3><p>Kafka作为一个中间件，是帮我们存储和转发消息的，它做的事情有点像中介，所以我们把kafka的服务叫做Broker，默认是9092的端口。生产者和消费者都需要跟这个Broker建立一个连接，才可以实现消息的收发。</p>\n<h3 id=\"3-2-消息\"><a href=\"#3-2-消息\" class=\"headerlink\" title=\"3.2 消息\"></a>3.2 消息</h3><p>客户端之间传输的数据叫做消息，或者叫做记录（Record）。在客户端的代码中，Record可以是一个KV键值对，生产者的封装类是ProducerRecord，消费者的封装类是ConsumerRecord。<br>  消息在传输过程中需要序列化，所以在代码中要指定序列化工具。</p>\n<h3 id=\"3-3-生产者\"><a href=\"#3-3-生产者\" class=\"headerlink\" title=\"3.3 生产者\"></a>3.3 生产者</h3><p>发送消息的一方叫做生产者。为了提升发送效率，生产者不是逐条发送消息给Broker，而是批量发送的，发送的数据大小和时间间隔由以下参数决定：</p>\n<pre><code class=\"hljs\">batch.size=16384\nlinger.ms=0\n</code></pre>\n<h3 id=\"3-4-消费者\"><a href=\"#3-4-消费者\" class=\"headerlink\" title=\"3.4 消费者\"></a>3.4 消费者</h3><p>接收消息的一方叫做消费者。<br>  —般来说消费者获取消息有两种模式，一种是pull模式，一种是push模式。Pull模式就是消费放在Broker,消费者自己决定什么时候去获取。Push模式是消息放在Consumer，只要有消息到达Broker,都直接推给消费者。<br>  Kafka只支持pull模式，因为在push模式下，如果消息产生速度远远大于消费者消费消息的速率，那消费者就会不堪重负（你已经吃不下了，但是还要不断地往你嘴里塞），直到挂掉。而且在pull模式下消费者一次pull获取多少条消息由以下参数决定：</p>\n<pre><code class=\"hljs\">max.poll.records=500\n</code></pre>\n<h3 id=\"3-5-Topic\"><a href=\"#3-5-Topic\" class=\"headerlink\" title=\"3.5 Topic\"></a>3.5 Topic</h3><p>生产者跟消费者是怎么关联起来的呢？或者说，生产者发送的消息，怎么才能到达某个特定的消费者？他们要通过队列关联起来，也就是说，生产者发送消息，要指定发给哪个队列。消费者接收消息，要指定从哪个队列接收。在Kafka里面，这个队列叫做Topic。它是一个逻辑的概念，可以理解为一组消息的集合（用以区分不同业务用途的消息）。<br>  注意，生产者发送消息时，如果Topic不存在，会自动创建。由以下参数决定：</p>\n<pre><code class=\"hljs\">auto.create.topics.enable=true\n</code></pre>\n<h3 id=\"3-6-Partition\"><a href=\"#3-6-Partition\" class=\"headerlink\" title=\"3.6 Partition\"></a>3.6 Partition</h3><p>如果说一个Topic中的消息太多，会带来两个问题：<br>  第一个是不方便横向扩展，比如我想要在集群中把数据分布在不同的机器上实现扩展，而不是通过升级硬件做到，如果一个Topic的消息无法在物理上拆分到多台机器的时候，这个是做不到的。<br>  第二个是并发或者负载的问题，所有的客户端操作的都是同一个Topic,在高并发的场景下性能会大大下降。<br>  怎么解决这个问题呢？我们想到的就是把一个Topic进行拆分。 Kafka引入了一个分区(Partition)的概念。一个Topic可以划分成多个分区。 分区在创建topic的时候指定，每个topic至少有一个分区。<br>  在创建topic时需要指定分区数由以下参数决定：</p>\n<pre><code class=\"hljs\">num.partitions=1\n</code></pre>\n<p>Partition思想上有点类似于分库分表，实现的也是横向扩展和负载的目的。举个例子，Topic有3个分区，生产者依次发送9条消息，对消息进行编号。 第一个分区存1 4 7,第二个分区存2 5 8,第三个分区存3 6 9，这个就实现了负载。</p>\n<h3 id=\"3-7-Replica\"><a href=\"#3-7-Replica\" class=\"headerlink\" title=\"3.7 Replica\"></a>3.7 Replica</h3><p>如果partition的数据只存储一份，在发生网络或者硬件故障的时候，该分区的数据就无法访问或者无法恢复了。<br>  Kafka在0.8的版本之后增加了副本机制。每个partition可以有若干个副本(Replica)，副本必须在不同的Broker 上面。—般我们说的副本包括其中的主节点。由 replication-factor指定一个Topic 的副本数。默认副本数由以下参数决定</p>\n<pre><code class=\"hljs\">offsets.topic.replication.factor=1\n</code></pre>\n<p>举例：部署了 3个Broker,该topic有3个分区，每个分区一共3个副本。<br><img src=\"https://img-blog.csdnimg.cn/20210417123522406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  注意：这些存放相同数据的partition副本有leader（图中红色）和follower（图中绿色）的概念。leader在哪台机器是不一定的，选举岀来的。</p>\n<h3 id=\"3-8-Segment\"><a href=\"#3-8-Segment\" class=\"headerlink\" title=\"3.8 Segment\"></a>3.8 Segment</h3><p>Kafka的数据是放在后缀.log的文件里面的。如果一个partition只有一个log文件，消息不断地追加，这个log文件也会变得越来越大，这个时候要检索数据效率就很低了。所以干脆把partition再做一个切分，切分岀来的单位就叫做段（segment）。实际上kafka的存储文件是划分成段来存储的。默认存储路径：&#x2F;tmp&#x2F;kafka-logs&#x2F; 。每个segment都有至少有1个数据文件和2个索引文件，这3个文件是成套出现的。</p>\n<h3 id=\"3-9-Consumer-Group\"><a href=\"#3-9-Consumer-Group\" class=\"headerlink\" title=\"3.9 Consumer Group\"></a>3.9 Consumer Group</h3><p>我们知道消息中间件一般会支持发布&#x2F;订阅模式和广播模式，那么在Kafka中是如何实现的呢？或者换一种问法，当多个消费者订阅了同一个topic的时候，该如何区分这条消息是要单发还是群发呢？<br>  Kafka引入了消费者组Consumer Group的概念，通过group.id来配置，group.id相同的消费者属于同一个消费者组，Kafka对不同消费者组进行广播，而同一个消费者组中的消费者只消费一次消息。<br>  具体点说，同一个消费者组的消费者不能订阅相同的分区。当消费者数量小于分区数时，一个消费者消费多个分区，当消费者数量大于分区数时，多余的消费者将不进行工作。</p>\n<h3 id=\"3-10-Consumer-Offset\"><a href=\"#3-10-Consumer-Offset\" class=\"headerlink\" title=\"3.10 Consumer Offset\"></a>3.10 Consumer Offset</h3><p>我们已经知道Kafka消息是写在日志文件中，并且不会在消费过后就被删除。那么当一个消费者组在消费一半时重启了，该如何继续上一次的位置读取消息呢？为此，Kafka引入Consumer Offset的概念。<br>  Consumer Offset是标记一个消费者组在一个partition即将消费的下一条记录，这个信息直接保存在Kafka本身一个特殊的topic中，叫__consumer_offsets，默认创建50个分区。</p>\n<h2 id=\"4、Kafka原理\"><a href=\"#4、Kafka原理\" class=\"headerlink\" title=\"4、Kafka原理\"></a>4、Kafka原理</h2><h3 id=\"4-1-Kafka生产者原理\"><a href=\"#4-1-Kafka生产者原理\" class=\"headerlink\" title=\"4.1 Kafka生产者原理\"></a>4.1 Kafka生产者原理</h3><h4 id=\"4-1-1-生产者发送流程\"><a href=\"#4-1-1-生产者发送流程\" class=\"headerlink\" title=\"4.1.1 生产者发送流程\"></a>4.1.1 生产者发送流程</h4><p>消息发送的整体流程。生产端主要由两个线程协调运行。这两条线程分别为main线程和sender线程（发送线程）。<br>  在创建KafkaProducer的时候，创建了一个Sender对象，并且启动了—个IO线程。</p>\n<h5 id=\"4-1-1-1-拦截器\"><a href=\"#4-1-1-1-拦截器\" class=\"headerlink\" title=\"4.1.1.1 拦截器\"></a>4.1.1.1 拦截器</h5><p>第二步是执行拦截器的逻辑，在producer.send方法中:</p>\n<pre><code class=\"hljs\">ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors.onSend(record);\n</code></pre>\n<p>拦截器的作用是实现消息的定制化（类似于Spring Interceptor、MyBatis的插件、Quartz的监听器）。那这个拦截器是在哪里定义的呢？生产者代码：</p>\n<pre><code class=\"hljs\">List&lt;String&gt; interceptors = new ArrayList&lt;&gt;(); \ninterceptors.add(&quot; com.xxx.interceptor.Charginginterceptor&quot;); \nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n</code></pre>\n<p>举个例子，假设发送消息的时候要扣钱，发一条消息1分钱（我把这个功能叫做按量付费），就可以用拦截器实现。</p>\n<pre><code class=\"hljs\">public class Charginginterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;\n    //发送消息的时候触发\n    @Override\n    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;\n     \tSystem.out.println(&quot;1分钱1条消息，不管那么多反正先扣钱”);\n        return record;\n    &#125;\n\n    //收到服务端的ACK的时候触发\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;\n        System.out.pnntln(n消息被服务端接收啦”);\n    &#125;\n    \n    @Override \n    public void close() &#123;\n        System.out.printin(”生产者关闭了&quot;);\n    &#125;\n    \n    //用键值对配置的时候触发\n    @Override\n    public void configure(Map&lt;String, ?&gt; configs) &#123;\n        System. out.piintln(n configure...H);\n    &#125;\n&#125;\n</code></pre>\n<h5 id=\"4-1-1-2-序列化\"><a href=\"#4-1-1-2-序列化\" class=\"headerlink\" title=\"4.1.1.2 序列化\"></a>4.1.1.2 序列化</h5><p>接下来是利用指定的工具对key和value进行序列化：</p>\n<pre><code class=\"hljs\">serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());\n</code></pre>\n<p>kafka针对不同的数据类型自带了相应的序列化工具。<br><img src=\"https://img-blog.csdnimg.cn/20210417162458711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  除了自带的序列化工具之外，可以使用如Avro、JSON、Thrift. Protobuf等，或者使用自定义类型的序列化器来实现，实现Serializer接口即可。</p>\n<h5 id=\"4-1-1-3-分区路由\"><a href=\"#4-1-1-3-分区路由\" class=\"headerlink\" title=\"4.1.1.3 分区路由\"></a>4.1.1.3 分区路由</h5><p>然后是分区指定：</p>\n<pre><code class=\"hljs\">int partition = partition(record, serializedKey, serialized Value, cluster);\n</code></pre>\n<p>一条消息会发送到哪个partition呢？它返回的是一个分区的编号，从0开始。有四种情况:</p>\n<ol>\n<li>指定了partition——直接将指定的值直接作为partiton值。</li>\n<li>没有指定partition,自定义了分区器——将使用自定义的分区器算法选择分区。</li>\n<li>没有指定partition,没有自定义分区器，但是key不为空——使用默认分区器DefaultPartitioner,将<br>key的hash值与topic的partition数进行取余得到partition值；</li>\n<li>没有指定partition,没有自定义分区器，但是key是空的——第一次调用时随机生成一个整数(后面每次调用在这个整数上自增)，将这个值与topic可用的partition总数取余得到 partition值，也就是常说的round-robin算法。</li>\n</ol>\n<h5 id=\"4-1-1-4-消息累加器\"><a href=\"#4-1-1-4-消息累加器\" class=\"headerlink\" title=\"4.1.1.4 消息累加器\"></a>4.1.1.4 消息累加器</h5><p>选择分区以后并没有直接发送消息，而是把消息放入了消息累加器：</p>\n<pre><code class=\"hljs\">RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptcallback, remainingWaitMs);\n</code></pre>\n<p>RecordAccumulator 本质上是一个 ConcurrentMap:</p>\n<pre><code class=\"hljs\">ConcurrentMap&lt;TopicPailition Deque&lt;ProducerBatc&gt;&gt; batches;\n</code></pre>\n<p>—个partition —个Batch。batch满了之后，会唤醒Sender线程，发送消息:</p>\n<pre><code class=\"hljs\">if (result.batchlsFull || result.newBatchCreated) &#123;\n    log.trace(Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;, record.topic(), partition);\n    this.sender.wakeup();\n&#125;\n</code></pre>\n<h4 id=\"4-1-2-消息应答机制ACK\"><a href=\"#4-1-2-消息应答机制ACK\" class=\"headerlink\" title=\"4.1.2 消息应答机制ACK\"></a>4.1.2 消息应答机制ACK</h4><h5 id=\"4-1-2-1-服务端响应策略\"><a href=\"#4-1-2-1-服务端响应策略\" class=\"headerlink\" title=\"4.1.2.1 服务端响应策略\"></a>4.1.2.1 服务端响应策略</h5><p>生产者的消息是不是发出去就完事了？如果说网络出了问题，或者说kafka服务端接收的时候出了问题，这个消息发送失败了，生产者是不知道的。所以，kafka服务端应该要有一种响应客户端的方式，只有在服务端确认以后，生产者才发送下一轮的消息，否则重新发送数据。<br>  服务端什么时候才算接收成功呢？因为消息是存储在不同的partition里面的，所以是写入到partition之后响应生产者。当然，单个partition (leader)写入成功，还是不够可靠，如果有多个副本，follower 也要写入成功才可以。<br>  为了安全性考虑，Kafka会等待所有的follower全部完成同步，才发送ACK给客户端，延迟相对来说高一些，但是节点挂掉的影响相对来说小一些，因为所有的节点数据都是完整的。</p>\n<h5 id=\"4-1-2-2-ISR\"><a href=\"#4-1-2-2-ISR\" class=\"headerlink\" title=\"4.1.2.2 ISR\"></a>4.1.2.2 ISR</h5><p>然而以上方案仍然存在问题：假设leader收到数据，所有follower都开始同步数据，但是有一个follower出了问题，没有办法从leader同步数据。按照这个规则，leader就要一致等待，无法发送 ack。<br>  从概率的角度来讲，这种问题肯定是会出现的，就是某个follower出问题了，怎么解决呢？所以我们的规则就不能那么粗暴了，把规则改一下，不是所有的follower都有权利 让我等待，而是只有那些正常工作的follower同步数据的时候我才会等待。<br>  我们应该把那些正常和leader保持同步的replica维护起来，放到一个动态set里面，这个就叫做in-sync replica set (ISR)。现在只要ISR里面的follower同步完数据之后，我就给客户端发送ACK。如果一个follower长时间不同步数据，就要从ISR剔除。同样，如果后面这个follower重新与leader保持同步，就会重新加入ISR。时间间隔由以下参数决定：</p>\n<pre><code class=\"hljs\">replica.lag.time.max.ms=10000\n</code></pre>\n<h5 id=\"4-1-2-3-ACK应答\"><a href=\"#4-1-2-3-ACK应答\" class=\"headerlink\" title=\"4.1.2.3 ACK应答\"></a>4.1.2.3 ACK应答</h5><p>当然，如果所有的数据都一视同仁，而且这种策略只能由服务端决定，这就不是很灵活了。有一些数据丢了无所谓，我只想要快，不管它落没落盘同没同步，怎么办呢？<br>  Kafka为客户端提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择相应的配置。</p>\n<ul>\n<li><strong>acks&#x3D;0：</strong> producer不等待broker的ack,这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</li>\n<li><strong>acks&#x3D;1（默认）：</strong> producer 等待 broker 的 ack, partition 的 leader 落盘成功后 返回ack,如果在follower同步成功之前leader故障，那么将会丢失数据；</li>\n<li><strong>acks&#x3D;-1 (all) ：</strong> producer等待 broker 的 ack, partition 的 Ieader和 follower全部落盘成功后才返回ack。</li>\n</ul>\n<p>三种机制，性能依次递减（producer吞吐量降低），数据健壮性则依次递增。我们可 以根据业务场景使用不同的参数。</p>\n<h3 id=\"4-2-Kafka消息存储原理\"><a href=\"#4-2-Kafka消息存储原理\" class=\"headerlink\" title=\"4.2 Kafka消息存储原理\"></a>4.2 Kafka消息存储原理</h3><h4 id=\"4-2-1-数据存储目录\"><a href=\"#4-2-1-数据存储目录\" class=\"headerlink\" title=\"4.2.1 数据存储目录\"></a>4.2.1 数据存储目录</h4><p>目录配置在配置文件config&#x2F;env.properties，由以下参数决定：</p>\n<pre><code class=\"hljs\">logs.dir=/tmp/kafka-logs\n</code></pre>\n<h4 id=\"4-2-2-partition分区\"><a href=\"#4-2-2-partition分区\" class=\"headerlink\" title=\"4.2.2 partition分区\"></a>4.2.2 partition分区</h4><p>为了实现横向扩展，把不同的数据存放在不同的Broker上,同时降低单台服务器的访问压力，我们把一个topic中的数据分隔成多个partition。—个partition中的消息是有序的，顺序写入，但是全局不一定有序。<br>  在服务器上，每个partition都有一个物理目录，topic名字后面的数字标号即代表分区。<br><img src=\"https://img-blog.csdnimg.cn/20210417170640277.png\" alt=\"在这里插入图片描述\"></p>\n<h4 id=\"4-2-3-replica副本\"><a href=\"#4-2-3-replica副本\" class=\"headerlink\" title=\"4.2.3 replica副本\"></a>4.2.3 replica副本</h4><p>为了提高分区的可靠性，kafka又设计了副本机制。创建topic的时候，通过指定replication-factor确定topic的副本数。<br>  注意：副本数必须小于等于节点数，而不能大于Broker的数量，否则会报错。<br>  这些所有的副本分为两种角色，leader对外提供读写服务。follower唯一的任务就是从leader异步拉取数据。</p>\n<h4 id=\"4-2-4-副本分布规则\"><a href=\"#4-2-4-副本分布规则\" class=\"headerlink\" title=\"4.2.4 副本分布规则\"></a>4.2.4 副本分布规则</h4><p>副本在Broker的分布有什么规则吗？例如有个topic：a4part2rep, 4个分区每个2个副本，一共8份副本，怎么分布到3台机器呢？<br><img src=\"https://img-blog.csdnimg.cn/20210417171144308.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  实际副本分布规则是由AdminUtils.scala——assignReplicasToBrokers决定的，具体规则如下：</p>\n<ol>\n<li>副本因子不能大于Broker的个数；</li>\n<li>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；</li>\n<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移 （nextReplicaShift）。</li>\n</ol>\n<p>这样设计可以提高容灾能力。在每个分区的第一个副本错开之后，一般第一个分区的第一个副本（按Broker编号排序）都是leader。leader是错开的，不至于一挂影响太大。</p>\n<h4 id=\"4-2-5-Segment\"><a href=\"#4-2-5-Segment\" class=\"headerlink\" title=\"4.2.5 Segment\"></a>4.2.5 Segment</h4><p>为了防止log不断追加导致文件过大，导致检索消息效率变低，一个partition又被划分成多个segment来组织数据。在磁盘上，每个segment由一个log文件和2个index文件组成。这三个文件是成套出现的。另外还有一个leader-epoch-checkpoint文件中保存了每一任leader开始写入消息时的offset。<br><img src=\"https://img-blog.csdnimg.cn/20210418150929793.png\" alt=\"在这里插入图片描述\"></p>\n<p>1 .log日志文件（日志就是数据）<br>  在一个segment文件里面，日志是追加写入的。如果满足一定条件，就会切分日志文件，产生一个新的segment什么时候会触发segment的切分呢？<br>  第一种是根据日志文件大小。当一个segment写满以后，会创建一个新的segment, 用最新的offset作为名称。文件大小由以下参数控制（默认1G）：</p>\n<pre><code class=\"hljs\">log.segment.bytes=1073741824\n</code></pre>\n<p>第二种是根据消息的最大时间戳，和当前系统时间戳的差值。还可以从更加精细的时间单位进行控制，如果配置了毫秒级别的日志切分间隔，会优先使用这个单位。否则就用小时的。间隔时间由以下参数决定：</p>\n<pre><code class=\"hljs\">log.roll.hours=168\nlog.roll.ms\n</code></pre>\n<p>还有第三种情况，offset索引文件或者timestamp索引文件达到了一定的大小。由参数<strong>log.index.size.max.bytes（默认10M）</strong> 控制。如果要减少日志文件的切分，可以把这个值调大一点。<br>2. .index偏移量(offset)索引文件<br>3. .timeindex 时间戳(timestamp)索引文件</p>\n<h4 id=\"4-2-6-索引\"><a href=\"#4-2-6-索引\" class=\"headerlink\" title=\"4.2.6 索引\"></a>4.2.6 索引</h4><p>由于一个segment的文件里面可能存放很多消息，如果要根据offset获取消息，必须要有一种快速检索消息的机制。这个就是索引。在Kafka中设计了两种索引：偏移量索引文件记录的是。offset和消息物理地址（在log文件中的位置）的映射关系。时间戳索引文件记录的是时间戳和offset的关系。<br>  内容是二进制的文件，不能以纯文本形式查看。bin目录下有dumplog工具。 查看最后10条offset索引：</p>\n<pre><code class=\"hljs\">./kafka-dump-log.sh —files /tmp/kafl&lt;a-logs/mytopic-0/00000000000000000000.index|head -n 10\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/20210418154758336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>注意，Kafka的索引并不是每一条消息都会建立索引，而是一种稀疏索引sparse index（DB2和Mongdb中都有稀疏索引）。至于这个索引有多稀疏，由以下参数决定：</p>\n<pre><code class=\"hljs\">log.index.interval.bytes=4096\n</code></pre>\n<p>只要写入的消息超过了 4KB,偏移量索引文件index和时间戳索引文件.timeindex就会増加一条索引记录(索引项)。这个值设置越小，索引越密集。值设置越大，索引越稀疏。相对来说，越稠密的索引检索数据更快，但是会消耗更多的存储空间。越的稀疏索引占用存储空间小，但是插入和删除时所需的维护开销也小。Kafka索引的时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。<br>  第二种索引类型是时间戳索引。时间戳有两种，一种是消息创建的时间戳，一种是消费在Broker追加写入的时间。到底用哪个时间由以下参数控制：</p>\n<pre><code class=\"hljs\">log.message.timestamp.type=CreateTime\n</code></pre>\n<p>默认是创建时间。如果要改成日志追加时间，则修改为LogAppendTime。査看最早的10条时间戳索引：</p>\n<pre><code class=\"hljs\">./kafka-dump-log.sh —files /tmp/kafka-logs/mytopic-0/00000000000000000000.timeindex|head -n 10\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/20210418154859613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  那么Kafka如何基于索引快速检索消息？比如我要检索偏移量是10002673的消息。</p>\n<ol>\n<li>消费的时候是能够确定分区的，所以第一步是找到在哪个segment中。Segment 文件是用base offset命名的，所以可以用二分法很快确定（找到名字不大于10002673 的 最大segment）。</li>\n<li>这个segment有对应的索引文件，它们是成套出现的。所以现在要在索引文件中根据offset找position。</li>\n<li>得到position之后，到对应的log文件开始査找offset,和消息的offset进行比较，直到找到消息。<br><img src=\"https://img-blog.csdnimg.cn/20210418155346397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n</ol>\n<h4 id=\"4-2-7-日志清理策略\"><a href=\"#4-2-7-日志清理策略\" class=\"headerlink\" title=\"4.2.7 日志清理策略\"></a>4.2.7 日志清理策略</h4><p>由于Kafka的日志并没有在消费后马上删除，随着时间的推移，日志越来越多，需要有相应的清理策略来保证系统的健康，日志清理的开关由以下参数控制：</p>\n<pre><code class=\"hljs\">log.cleaner.enable=true\n</code></pre>\n<p>Kafka提供了两种清理方式，分别是删除delete和压缩compact，由以下参数控制：</p>\n<pre><code class=\"hljs\">log.cleanup.policy=delete\n</code></pre>\n<p>日志删除的功能是由定时任务完成的，定时任务运行的时间间隔由以下参数控制：</p>\n<pre><code class=\"hljs\">log.retention.check.interval.ms=300000\n</code></pre>\n<p>删除多久以前的数据由以下参数控制（精度越小优先级越高）：</p>\n<pre><code class=\"hljs\">log.retention.hours=168\nlog.retention.minutes\nlog.retention.ms\n</code></pre>\n<p>还可以根据保留日志的大小来删除数据，超出该大小则删除最早的数据，由以下参数控制（默认-1代表不限制）：</p>\n<pre><code class=\"hljs\">log.retention.bytes=-1\n</code></pre>\n<p>若采取压缩的清理方式，则会根据相同的key进行压缩，当消息的key相同时，只保留最新的value。<br><img src=\"https://img-blog.csdnimg.cn/20210418164159281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h4 id=\"4-2-8-Controller选举\"><a href=\"#4-2-8-Controller选举\" class=\"headerlink\" title=\"4.2.8 Controller选举\"></a>4.2.8 Controller选举</h4><p>当创建添加一个的分区或者分区增加了副本的时候，都要从所有副本中选举一个新的Leader出来。<br>  投票怎么玩？是不是所有的partition副本直接发起投票，开始竞选呢？比如用ZK 实现。<br>  利用ZK怎么实现选举？ZK的什么功能可以感知到节点的变化（增加或者减少）? 或者说，ZK为什么能实现加锁和释放锁？<br>  3个特点：watch机制；节点不允许重复写入；临时节点。<br>  这样实现是比较简单，但是也会存在一定的弊端。如果分区和副本数量过多，所有的副本都直接进行选举的话，一旦某个出现节点的增减，就会造成大量的watch事件被触发，ZK的负载就会过重。<br>  Kafka早期的版本（0.82及以前）就是这样做的，后来换了一种实现方式。<br>  不是所有的repalica都参与leader选举，而是由其中的一个Broker统一来指挥， 这个Broker的角色就叫做Controller（控制器）。<br>  就像Redis Sentinel的架构，执行故障转移的时候，必须要先从所有哨兵中选一个负责做故障转移的节点一样。Kafka也要先从所有Broker中选出唯一的一个Controller，所有的Broker会尝试在zookeeper中创建临时节点&#x2F;controller,只有一个能创建成功（先到先得）。<br>  如果Controller挂掉了或者网络出现了问题，ZK上的临时节点会消失。其他的Broker通过watch监听到Controller下线的消息后，开始竞选新的Controller。方法跟之前还是一样的,谁先在ZK里面写入一个&#x2F;controller节点,谁就成为新的Controller。<br>  一个节点成为Controller之后，它肩上的责任也比别人重了几份，正所谓劳力越戴, 责任越大：</p>\n<ul>\n<li>监听Broker变化。</li>\n<li>监听Topic变化。</li>\n<li>监听Partition变化。</li>\n<li>获取和管理Broker、Topic、Partition的信息。</li>\n<li>管理Partiontion的主从信息。</li>\n</ul>\n<h4 id=\"4-2-9-分区副本Leader选举\"><a href=\"#4-2-9-分区副本Leader选举\" class=\"headerlink\" title=\"4.2.9 分区副本Leader选举\"></a>4.2.9 分区副本Leader选举</h4><p>Controller确定以后，开始进行leader选举。副本有3个概念：</p>\n<ul>\n<li>**Assigned-Replicas (AR)**：一个分区的所有副本</li>\n<li>**In-Sync Replicas (ISR)**：一个分区中跟leader数据保持一定程度的同步的副本</li>\n<li>**Out-Sync-Replicas (OSR)**：跟leader副本同步滞后过多的副本</li>\n</ul>\n<p>只有ISR有资格参加leader选举。而且这个ISR不是固定不变的，它是一个动态的列表。<br>如果同步延迟超过30秒，就踢出ISR，进入OSR。如果赶上来了， 就加入ISR。默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader。极端情况下，如果ISR为空，则可以允许ISR之外的副本参与选举，由以下参数控制：</p>\n<pre><code class=\"hljs\">unclean.leader.election.enable=true\n</code></pre>\n<p>注意，这种情况下可能造成数据丢失。<br>  那么leader的选举规则是什么呢？它使用一种类似微软的PacificA算法，在这种算法中，默认是让ISR中第一个replica变成leader。比如ISR是1、5、9, 优先让1成为leader。这个跟中国古代皇帝传位是一样的，优先传给皇长子。</p>\n<h4 id=\"4-2-10-主从同步\"><a href=\"#4-2-10-主从同步\" class=\"headerlink\" title=\"4.2.10 主从同步\"></a>4.2.10 主从同步</h4><p>Leader确定之后，客户端的读写只能操作leader节点。follower需要向leader同步数据。不同的raplica的offset是不一样的，同步到底怎么同步呢？<br>  首先需要认识几个概念：<br><strong>LEO (Log End Offset)：</strong> 下一条等待写入的消息的offset (最新的offset + 1),图中分别是9, 8, 6。<br><strong>HW (Hign Watermark):</strong> ISR中最小的LEO。Leader会管理所有ISR中最小的 LEO作为HW,目前是6。<br><img src=\"https://img-blog.csdnimg.cn/20210418214659821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  consumer最多只能消费到HW之前的位置(消费到offset 5的消息)。也就是说: 其他的副本没有同步过去的消息，是不能被消费的。<br>  有了这两个offset之后，再来看看消息怎么同步：</p>\n<p>followerl同步了1条消息，follower2同步了2条消息。此时HW推进了2,变成8。<img src=\"https://img-blog.csdnimg.cn/20210418214946178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  followerl同步了0条消息，follower2同步了1条消息。此时HW推进了1，变成9。LEO和HW重叠，所有的消息都可以消费了。<br><img src=\"https://img-blog.csdnimg.cn/20210418215103808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  这里，我们关注一下，从节点怎么跟主节点保持同步？</p>\n<ol>\n<li>follower节点会向Leader发送一个fetch请求，leader向follower发送数据后，既需要更新follower的LEO。</li>\n<li>follower接收到数据响应后，依次写入消息并且更新LEO。</li>\n<li>leader 更新 HW （ISR 最小的 LEO）。</li>\n</ol>\n<p>kafka设计了独特的ISR复制，可以在保障数据一致性情况下又可提供高吞吐量。</p>\n<h4 id=\"4-2-11-replica故障处理\"><a href=\"#4-2-11-replica故障处理\" class=\"headerlink\" title=\"4.2.11 replica故障处理\"></a>4.2.11 replica故障处理</h4><h5 id=\"4-2-11-1-follower故障\"><a href=\"#4-2-11-1-follower故障\" class=\"headerlink\" title=\"4.2.11.1 follower故障\"></a>4.2.11.1 follower故障</h5><p>首先follower发生故障，会被先踢出ISR。follower恢复之后，从哪里开始同步数据呢？假设第1个replica宕机（中间这个）。<br><img src=\"https://img-blog.csdnimg.cn/20210418220330233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  恢复以后，首先根据之前记录的HW （6）,把高于HW的消息截掉（6、7）。然 后向leader同步消息。追上leader之后（30秒），重新加入ISR。</p>\n<h5 id=\"4-2-11-2-leader故障\"><a href=\"#4-2-11-2-leader故障\" class=\"headerlink\" title=\"4.2.11.2 leader故障\"></a>4.2.11.2 leader故障</h5><p>假设图中leader发生故障。首先选一个leader。因为replica 1 （中间这个）优先，它成为leader。为了保证数据一致，其他的follower需要把高于HW的消息截取掉（这里没有消息需要截取）。然后replica2同步数据。注意：这种机制只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>\n<h5 id=\"4-2-11-3-上面这两种方式没有问题吗？（全文重点！！！）\"><a href=\"#4-2-11-3-上面这两种方式没有问题吗？（全文重点！！！）\" class=\"headerlink\" title=\"4.2.11.3 上面这两种方式没有问题吗？（全文重点！！！）\"></a>4.2.11.3 上面这两种方式没有问题吗？（全文重点！！！）</h5><p>实际上，副本同步机制并没有上面说的那么简单。假设有A(leader)、B两个副本——<br>  作为leader，A还会维护每个副本的远程LEO值remoteLEO;<br>  作为follower，B会定时发送fetch请求给A拉取数据，在fetch时将自己当前的LEO和HW发送给A。<br>1）初始化状态时：<br>  LEO(A)&#x3D;0, HW(A)&#x3D;0，remoteLEO&#x3D;0;<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>2）当生产者发送一条数据m1时：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>3）B向A发起fetch请求，发送自己当前的LEO给A：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>4）A根据B发送的LEO,更新remoteLEO&#x3D;0，更新HW(A)&#x3D;min(LEO(A), remoteLEO(B))&#x3D;0，同时将HW(A)和未同步的数据m1发送给B：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>5）B根据A返回的HW(A)，写入数据m1，同时更新LEO(B)&#x3D;1，HW(B)&#x3D;min(HW(A), LEO(B))&#x3D;0，<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;0;[m1]</p>\n<p>6）B向A发起第二次fetch请求，发送自己当前的LEO(B)&#x3D;1：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;0;[m1]</p>\n<p>7）此时A更新remoteLEO&#x3D;1，HW(A)&#x3D;min(LEO(A), remoteLEO(B))&#x3D;1，同时返回HW给B：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;1，remoteLEO&#x3D;1;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;0;[m1]</p>\n<p>8）B根据A返回的HW(A)，更新HW(B)&#x3D;min(HW(A), LEO(B))&#x3D;1，<br>  LEO(A)&#x3D;1, HW(A)&#x3D;1，remoteLEO&#x3D;1;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;1;[m1]</p>\n<p>这是一轮常规的数据同步，设想一下，当leader或者follower出现故障时，会导致什么问题？我们知道可以通过acks来控制消息的可靠性，那么当acks&#x3D;-1(all)的时候是否数据一定不会丢失？<br>  首先，我们要明白数据丢失的概念，一定是在leader返回ack但是数据不存在的情况下才叫数据丢失，如果leader没有返回ack，也就是说生产者知道消息没发送成功的话，不算数据丢失。那么假设acks&#x3D;-1的话，实际上leader是在步骤7）执行完毕后就返回ack给生产者。在这个前提下我们分析几个场景。<br>场景一：<br>  假设ISR中只有一个leader副本，且成功写入数据。此时leader挂掉，若参数设置允许OSR中的副本抢占leader的话，可能导致数据丢失。<br>  这种场景系统也无法处理，所以Kafka交给用户自行选择，若unclean.leader.election.enable&#x3D;true则无法保证消息的可靠性，若unclean.leader.election.enable&#x3D;false则无法保证系统的效率和可用性。<br>场景二：<br>  在执行完步骤7）之后B挂掉了，而当B重启之后（注意此时HW(B)&#x3D;0），根据4.2.11.1的做法，会先将超出HW(B)的消息m1抛弃，重新从A拉取数据。更极端的情况下，此时A恰好也挂掉，这时候B就会通过选举成为leader。而A重启之后成为follower，会通过截取m1的方式与leader保持同步。至此，消息m1丢失。更严重的是，若A重启之前，B又接收了生产者发送的新的数据m2，那么A重启后由于HW(A)&#x3D;1，将不会从B拉取到消息m2，结果如下：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;1，remoteLEO&#x3D;1;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;1;[m2]</p>\n<p>鉴于场景2，Kafka在0.11版本后增加了一个<strong>leader-epoch-checkpoint</strong>的概念，以文件的形式保存在日志目录下，当一个新的leader在写入第一条消息时，会在文件中记录一条信息，包括leader年代（即leader更换次数）epoch和当前leader写入的第一个offset。<br>  举个例子，当这个分区写入第一条消息时，leader-epoch-checkpoint文件中会记录一条信息（0 0），在写入50条消息之后leader挂掉并发生选举，leader-epoch-checkpoint会增加一条记录（1 50）。<br>  有了这种机制，当follower重启之后就不需要直接丢弃HW之后的数据，而是会发起一次请求对比leader中的epoch与自身的epoch：<br>  若epoch相等则只丢弃自身LEO大于leader的LEO的部分（即，若自身LEO不大于leader的LEO则不进行截取，与原来直接截取到HW有所差别）；<br>  若epoch不相等（自身小于leader的LEO）则将自身LEO与leader-epoch-checkpoint中epoch大于自身epoch的最小值的LEO相比较，丢弃自身LEO大于该LEO的数据。</p>\n<p>这部分有点绕，以刚才的例子说明，假设步骤7）执行完毕后B重启，此时：<br>  若B重启期间未发生leader选举，则A的leader-epoch-checkpoint文件与B一致，都是(0 0)，即epoch(A)&#x3D;epoch(B),此时LEO(B)&#x3D;LEO(A)&#x3D;1，无需截取。<br>  若B重启期间发生过leader选举（假设存在副本C、D），则leader-epoch-checkpoint文件存在多条记录(0 0)，(1 10)，(2 50)（又发生两次选举），此时B的epoch小于2，会将B的LEO与10比较（大于epoch(B)的最小epoch是1），同样不会丢弃数据。<br>  以上，就是0.11版本Kafka的数据同步方案。</p>\n<h3 id=\"4-3-Kafka消费者原理\"><a href=\"#4-3-Kafka消费者原理\" class=\"headerlink\" title=\"4.3 Kafka消费者原理\"></a>4.3 Kafka消费者原理</h3><h4 id=\"4-3-1-Offset的维护\"><a href=\"#4-3-1-Offset的维护\" class=\"headerlink\" title=\"4.3.1 Offset的维护\"></a>4.3.1 Offset的维护</h4><h5 id=\"4-3-1-1-Offset的存储\"><a href=\"#4-3-1-1-Offset的存储\" class=\"headerlink\" title=\"4.3.1.1 Offset的存储\"></a>4.3.1.1 Offset的存储</h5><p>我们知道在partition中，消息是不会删除的，所以才可以追加写入，写入的消息连续有序的。这种特性决定了 kafka可以消费历史消息，而且按照消息的顺序消费指定消息，而不是只能消费队头的消息。正常情况下，我们希望消费没有被消费过的数据，而且是从最先发送（序号小的） 的开始消费（这样才是有序和公平的）。<br>  那么对于一个partition,消费者组怎么才能做到接着上次消费的位置（offset）继续消费呢？肯定要把这个对应关系保存起来，下次消费的时候查找一下。<br>  首先这个对应关系确实是可以查看的。比如消费者组gp-assign-group-1和 ass5part （5个分区）的partition的偏移量关系，可使用如下命令査看：</p>\n<pre><code class=\"hljs\">./kafka-consumer-groups.sh “bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 —describe —group gp-assign-group-1\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/20210419010135861.png\" alt=\"在这里插入图片描述\"></p>\n<ul>\n<li>CURRENT-OFFSET指的是下一个未使用的offset。</li>\n<li>LEO , Log End Offset:下一条等待写入的消息的offset （最新的offset + 1）</li>\n<li>LAG是延迟量</li>\n</ul>\n<p>注意：这不是表示一个消费者和一个Topic的关系，而是一个consumer group和topic中的一个partition的关系（offset在partition中连续编号而不是全局连续编号）。</p>\n<p>那么这个对应关系到底是保存在哪里的呢？<br>  首先肯定是不可能放在消费者本地的。因为所有的消费者都可以使用这个consumer group id，放在本地是做不到统一维护的，肯定要放到服务端。<br>  Kafka早期的版本把消费者组和partition的offset直接维护在ZK中，但是读写的性能消耗太大了。后来就放在一个特殊的topic中，名字叫—consumer_offsets，默认有 50 个分区(offsets.topic.num.partitions 默认是 50)，每个分区默认一个replication。</p>\n<pre><code class=\"hljs\">./kafka・topics・sh —topic  \tconsumer_offsets —describe —zookeeper localhost:2181\n</code></pre>\n<p>那么这样一个特殊的Topic怎么存储消费者组gp-assign-group-1对于分区的偏移量的？Topic里面是可以存放对象类型的value的（经过序列化和反序列化）。这个Topic 里面主要存储两种对象：<br>  GroupMetadata:保存了消费者组中各个消费者的信息（每个消费者有编号）。<br>  OffsetAndMetadata:保存了消费者组和各个partition的offset位移信息元数据。</p>\n<pre><code class=\"hljs\">./kafka-console-consumer.sh —topic consumer_offsets --bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 -formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; —from-beginning\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/2021041901084354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  怎么知道一个consumer group的offset会放在这个特殊的Topic的哪个分区呢? 可以通过哈希取模计算得到：</p>\n<pre><code class=\"hljs\">Math.abs(&quot;gp-assign-group-1&quot;.hashCode()) % 50;\n</code></pre>\n<h5 id=\"4-3-1-2-如果找不到Offset\"><a href=\"#4-3-1-2-如果找不到Offset\" class=\"headerlink\" title=\"4.3.1.2 如果找不到Offset\"></a>4.3.1.2 如果找不到Offset</h5><p>如果增加了一个新的消费者组去消费—个topic的某个partion,没有offset的记录，这个时候应该从哪里开始消费呢？ 由以下参数控制：</p>\n<pre><code class=\"hljs\">auto.offset.reset=latest\n</code></pre>\n<p><strong>latest：</strong> 从最新的消息（最后发送的）开始消费。<br><strong>earliest：</strong> 从最早的（最先发送的）消息开始消费。可以消费到历史消息。<br><strong>none：</strong> 如果consumer group在服务端找不到offset会报错。</p>\n<h5 id=\"4-3-1-3-Offset的更新\"><a href=\"#4-3-1-3-Offset的更新\" class=\"headerlink\" title=\"4.3.1.3 Offset的更新\"></a>4.3.1.3 Offset的更新</h5><p>我们知道消费者组的offset是保存在Broker的，但是是由消费者上报给 Broker的。并不是消费者组消费了消息，Offset就会更新，消费者必须要有一个commit （提交）的动作。消费者可以自动提交或者手动提交。由以下参数控制：</p>\n<pre><code class=\"hljs\">enable.auto.commit=true\n</code></pre>\n<p>另外还可以使用一个参数来控制自动提交的频率：</p>\n<pre><code class=\"hljs\">auto.commit.interval.ms=5000\n</code></pre>\n<p>如果我们要在消费完消息做完业务逻辑处理之后才commit,就要把这个值改成 false。如果是false,消费者就必须要调用一个方法让Broker更新offset。有两种方式：<br>  consumer.commitSync()手动同步提交。<br>  consumer.commitAsync()手动异步提交。<br>  如果不提交或者提交失败,Broker的Offset不会更新，消费者下次消费的时候会受到重复消息。</p>\n<h4 id=\"4-3-2-消费者和消费策略\"><a href=\"#4-3-2-消费者和消费策略\" class=\"headerlink\" title=\"4.3.2 消费者和消费策略\"></a>4.3.2 消费者和消费策略</h4><h5 id=\"4-3-2-1-分区分配策略\"><a href=\"#4-3-2-1-分区分配策略\" class=\"headerlink\" title=\"4.3.2.1 分区分配策略\"></a>4.3.2.1 分区分配策略</h5><p>我们已经知道，在同一个消费者组中，一个分区只能被一个消费者消费。所以当消费者数量大于分区数量时，多余的消费者是无法消费消息的。那么如果分区数大于消费者数呢，Kafka又是如何分配的？<br>  为了保证系统最大的利用率，Kafka的分配策略一定会遵循一个最基本的原则——平均分配，简单理解，不会有任意两个消费者消费的分区数差大于1。在此基础上，Kafka有3种分区分配方式。以8个partition分配给3个consumer为例：<br><strong>1）Range（范围）</strong><br>  顾名思义，无需解释。<br>  C1：P0 P1 P2<br>  C2：P3 P4 P5<br>  C3：P6 P7<br><strong>2）RoundRobin（轮询）</strong><br>  顾名思义，无需解释。<br>  C1：P0 P3 P6<br>  C2：P1 P4 P7<br>  C3：P2 P5<br><strong>3）sticky（粘滞）</strong><br>  粘滞的分配策略较为复杂，它的核心思想是在分区重新分配时保证最小的移动（类似Redis的一致性hash思想，实现方式不同）。</p>\n<p>第一次分配类似轮询，结果如下：<br>  C1：P0 P3 P6<br>  C2：P1 P4 P7<br>  C3：P2 P5</p>\n<p>假设此时C2挂掉：<br>若按照RoundRobin，结果如下：<br>  C1：P0 P2 P4 P6<br>  C3：P1 P3 P5 P7</p>\n<p>sticky结果如下（尽量保证P0 P3 P6 P2 P5不动）：<br>  C1：P0 P3 P6 P1<br>  C3：P2 P5 P4 P7</p>\n<p>我们知道在分区分配时是会造成性能损耗的，若采用sticky分配策略可以尽可能减少性能损耗。该思想与Redis的一致性Hash是类似的，只是实现方式不同。</p>\n<h5 id=\"4-3-2-2-分区重分配Rebalance\"><a href=\"#4-3-2-2-分区重分配Rebalance\" class=\"headerlink\" title=\"4.3.2.2 分区重分配Rebalance\"></a>4.3.2.2 分区重分配Rebalance</h5><p>那么什么时候会触发分区重分配Rebalance呢？显然有两种情况，一种是消费者数量发生变化，一种是分区数量发生变化。Rebalance过程如下：</p>\n<ol>\n<li>确定协调者coordinator，通常由集群中负载最小的Broker承担。</li>\n<li>所有consumer向coordinator发送join group请求，确认自己是该组成员。</li>\n<li>coordinator在所有consumer中确定leader（通常是第一个）并由leader确定分区分配结果。</li>\n<li>coordinator向所有consumer发送分区分配结果。</li>\n</ol>\n<h4 id=\"4-3-3-Kafka为什么这么快？\"><a href=\"#4-3-3-Kafka为什么这么快？\" class=\"headerlink\" title=\"4.3.3 Kafka为什么这么快？\"></a>4.3.3 Kafka为什么这么快？</h4><h5 id=\"4-3-3-1-顺序读写\"><a href=\"#4-3-3-1-顺序读写\" class=\"headerlink\" title=\"4.3.3.1 顺序读写\"></a>4.3.3.1 顺序读写</h5><p>首先我们需要了解随机I&#x2F;O和顺序I&#x2F;O。<br>  磁盘的构造如图。磁盘的盘片不停地旋转，磁头会在磁盘表面画出一个圆形轨迹，这个就叫磁道。从内到位半径不同有很多磁道。然后又用半径线，把磁道分割成了扇区（两根射线之内的扇区组成扇面）。如果要读写数据, 必须找到数据对应的扇区，这个过程就叫寻址。<br>随机I&#x2F;O：读写的多条数据在磁盘上是分散的，寻址会很耗时。<br>顺序I&#x2F;O：读写的数据在磁盘上是集中的，不需要重复寻址的过程。<br><img src=\"https://img-blog.csdnimg.cn/20210419015453527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得 Kafka写入吞吐量得到了显著提升。<br>  顺序IO到底有多快呢？下图显示，在一定条件下测试，磁盘的顺序读写可以达到53.2M每秒，比内存的随机读写还要快。<br><img src=\"https://img-blog.csdnimg.cn/20210419015622131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h5 id=\"4-3-3-2-索引\"><a href=\"#4-3-3-2-索引\" class=\"headerlink\" title=\"4.3.3.2 索引\"></a>4.3.3.2 索引</h5><p>我们在写入日志的时候会建立关于Offset和时间的稀疏索引，提升了查找效率，这个上面已经提到过了。</p>\n<h5 id=\"4-3-3-3-批量读写\"><a href=\"#4-3-3-3-批量读写\" class=\"headerlink\" title=\"4.3.3.3 批量读写\"></a>4.3.3.3 批量读写</h5><p>Kafka无论是生产者发送消息还是消费者消费消息都是批量操作的，大大提高读写性能。</p>\n<h5 id=\"4-3-3-4-零拷贝\"><a href=\"#4-3-3-4-零拷贝\" class=\"headerlink\" title=\"4.3.3.4 零拷贝\"></a>4.3.3.4 零拷贝</h5><p>首先需要了解两个名词。<br>  第一个是操作系统虚拟内存的内核空间和用户空间。操作系统的虚拟内存分成了两块，一部分是内核空间，一部分是用户空间。这样就可以避免用户进程直接操作内核，保证内核安全。进程在内核空间可以执行任意命令，调用系统的一切资源；在用户空间必须要通过<br>—些系统接口才能向内核发出指令。如果用户要从磁盘读取数据(比如kafka消费消息)，必须先把数据从磁盘拷贝到内核缓冲区，然后在从内核缓冲区到用户缓冲区，最后才能返回给用户。<br><img src=\"https://img-blog.csdnimg.cn/20210419020156610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  第二个是DMA拷贝。没有DMA技术的时候，拷贝数据的事情需要CPU亲自去做, 这个时候它没法干其他的事情，如果传输的数据量大那就有问题了。DMA技术叫做直接内存访问(Direct Memory Access),其实可以理解为CPU给 自己找了一个小弟帮它做数据搬运的事情。在进行I&#x2F;O设备和内存的数据传输的时候， 数据搬运的工作全部交给DMA控制器，解放了 CPU的双手。<br>  理解了这两个东西之后，我们来看下传统的I&#x2F;O模型：<br><img src=\"https://img-blog.csdnimg.cn/20210419020246212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  比如kafka要消费消息，比如要先把数据从磁盘拷贝到内核缓冲区，然后拷贝到用户缓冲区，再拷贝到socket缓冲区，再拷贝到网卡设备。这里面发生了 4次用户态和内核态的切换和4次数据拷贝，2次系统函数的调用（read、write）,这个过程是非常耗费时间的。怎么优化呢?<br>  在Linux操作系统里面提供了一个sendfile函数（并不是所有操作系统都支持sendfile），可以实现”零拷贝”。这个时候就不需要经过用户缓冲区了，直接把数据拷贝到网卡（这里画的是支持SG-DMA拷贝的情况）。因为这个只有DMA拷贝，没有CPU拷贝，所以叫做”零拷贝”。零拷贝至少可以提高一倍的性能。<br><img src=\"https://img-blog.csdnimg.cn/20210419020413177.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"5、MQ选型：Kafka对比RabbitMQ-RocketMQ\"><a href=\"#5、MQ选型：Kafka对比RabbitMQ-RocketMQ\" class=\"headerlink\" title=\"5、MQ选型：Kafka对比RabbitMQ&#x2F;RocketMQ\"></a>5、MQ选型：Kafka对比RabbitMQ&#x2F;RocketMQ</h2><h3 id=\"5-1-Kafka特性\"><a href=\"#5-1-Kafka特性\" class=\"headerlink\" title=\"5.1 Kafka特性\"></a>5.1 Kafka特性</h3><ul>\n<li><strong>高吞吐、低延迟：</strong> kakfa最大的特点就是收发消息非常快，kafka每秒可以处理几十万条消息，它的最低延迟只有几毫秒；</li>\n<li><strong>高伸缩性：</strong> 如果可以通过增加分区partition来实现扩容。不同的分区可以在不同的Broker中。通过ZK来管理Broker实现扩展，ZK管理Consumer可以实现负载；</li>\n<li><strong>持久性、可靠性：</strong> Kafka能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失；</li>\n<li><strong>容错性：</strong> 允许集群中的节点失败，某个节点宕机，Kafka集群能够正常工作；</li>\n<li><strong>高并发：</strong> 支持数千个客户端同时读写。</li>\n</ul>\n<h3 id=\"5-2-Kafka对比RabbitMQ\"><a href=\"#5-2-Kafka对比RabbitMQ\" class=\"headerlink\" title=\"5.2 Kafka对比RabbitMQ\"></a>5.2 Kafka对比RabbitMQ</h3><ul>\n<li>产品侧重：kafka:流式消息处理、消息引擎；RabbitMQ:消息代理。</li>\n<li>性能：kafka有更高的吞吐量。RabbitMQ主要是push, kafka只有pull。</li>\n<li>消息顺序：分区里面的消息是有序的，同一个consumer group里面的一个消费者只能消费一个partition,能保证消息的顺序性。</li>\n<li>消息的路由和分发：RabbitMQ更加灵活。</li>\n<li>延迟消息、死信队列：RabbitMQ支持。</li>\n<li>消息的留存：kafka消费完之后消息会留存，RabbitMQ消费完就会删除。Kafka可以设置retention,清理消息。</li>\n</ul>\n<p><strong>优先选择RabbitMQ的情况：</strong></p>\n<ul>\n<li>高级灵活的路由规则；</li>\n<li>消息时序控制（控制消息过期或者消息延迟）；</li>\n<li>高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）;</li>\n<li>更简单的消费者实现。</li>\n</ul>\n<p><strong>优先选择Kafka的情况：</strong></p>\n<ul>\n<li>严格的消息顺序；</li>\n<li>延长消息留存时间，包括过去消息重放的可能；</li>\n<li>传统解决方案无法满足的高伸缩能力。</li>\n</ul>\n<h3 id=\"5-3-MQ选型分析\"><a href=\"#5-3-MQ选型分析\" class=\"headerlink\" title=\"5.3 MQ选型分析\"></a>5.3 MQ选型分析</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417132358379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"6、Kafka参数配置说明\"><a href=\"#6、Kafka参数配置说明\" class=\"headerlink\" title=\"6、Kafka参数配置说明\"></a>6、Kafka参数配置说明</h2><h3 id=\"6-1-Kafka生产者参数配置\"><a href=\"#6-1-Kafka生产者参数配置\" class=\"headerlink\" title=\"6.1 Kafka生产者参数配置\"></a>6.1 Kafka生产者参数配置</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417140452763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"6-2-Kafka服务端参数配置\"><a href=\"#6-2-Kafka服务端参数配置\" class=\"headerlink\" title=\"6.2 Kafka服务端参数配置\"></a>6.2 Kafka服务端参数配置</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417135422252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"6-3-Kafka消费者参数配置\"><a href=\"#6-3-Kafka消费者参数配置\" class=\"headerlink\" title=\"6.3 Kafka消费者参数配置\"></a>6.3 Kafka消费者参数配置</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417135759333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"6-4-Kafka增加数据可靠性的配置\"><a href=\"#6-4-Kafka增加数据可靠性的配置\" class=\"headerlink\" title=\"6.4 Kafka增加数据可靠性的配置\"></a>6.4 Kafka增加数据可靠性的配置</h3><ol>\n<li>设置acks &#x3D; all。acks是Producer的一个参数，代表已提交消息的定义。如果设置成all,则表明所有Broker都要接收到消息，该消息才算是”已提交”。</li>\n<li>设置retries为一个较大的值。同样是Producer的参数。当出现网络抖动时，消息发送可能会失败，此时配置了retries的Producer能够自动重试发送消息，尽量避免消息丢失。</li>\n<li>设置 unclean.leader.election.enable&#x3D;false。</li>\n<li>设置replication.factor &gt;&#x3D; 3。需要三个以上的副本。</li>\n<li>设置min.insync.replicas &gt; 1。Broker端参数，控制消息至少要被写入到多少个副本才算是”已提交”。设置成大于1可以提升消息持久性。在生产环境中不要使用默认值1。确保replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有 —个副本离线整个分区就无法正常工作了。推荐设置成replication.factor &#x3D; min.insync.replicas + 1。</li>\n<li>确保消息消费完成再提交。Consumer端有个参数enable.auto.commit,最好设置成false,并自己来处理offset的提交更新。</li>\n</ol>\n","excerpt":"","more":"<h2 id=\"1、Kafka概述\"><a href=\"#1、Kafka概述\" class=\"headerlink\" title=\"1、Kafka概述\"></a>1、Kafka概述</h2><h3 id=\"1-1-Kafka定义\"><a href=\"#1-1-Kafka定义\" class=\"headerlink\" title=\"1.1 Kafka定义\"></a>1.1 Kafka定义</h3><p>Apache Kafka 是一款开源的消息系统。可以在系统中起到“肖峰填谷”的作用，也可以用于异构、分布式系统中海量数据的异步化处理。</p>\n<h3 id=\"1-2-Kafka使用场景\"><a href=\"#1-2-Kafka使用场景\" class=\"headerlink\" title=\"1.2 Kafka使用场景\"></a>1.2 Kafka使用场景</h3><ul>\n<li><strong>消息中间件：</strong> 作为消息中间件进行消息传递，作为TCP HTTP或者RPC的替代方案，可以实现异步、解耦、削峰（RabbitMQ和RocketMQ能做的事情，它也能做）。因为kafka的吞吐量更高，在大规模消息系统中更有优势。</li>\n<li><strong>大数据领域：</strong> 例如日志归集、行为跟踪、应用监控。</li>\n<li><strong>数据集成+流计算：</strong> 对流式数据进行继承和实时计算。</li>\n</ul>\n<p>2、Kafka服务端基本认识</p>\n<p>目前比较流行的服务端管理界面主要是 kafka-manager 和 kafka-eagle （国产）。</p>\n<h3 id=\"2-1-Kafka与ZK的关系\"><a href=\"#2-1-Kafka与ZK的关系\" class=\"headerlink\" title=\"2.1 Kafka与ZK的关系\"></a>2.1 Kafka与ZK的关系</h3><p>总结起来：利用ZK的有序节点、临时节点和监听机制，ZK帮kafka做了这些事情：配置中心(管理Broker、Topic、Partition、Consumer的信息，包括元数据的变动)、负载均衡、命名服务、分布式通知、集群管理和选举、分布式锁。</p>\n<h3 id=\"2-2-Kafka脚本介绍\"><a href=\"#2-2-Kafka脚本介绍\" class=\"headerlink\" title=\"2.2 Kafka脚本介绍\"></a>2.2 Kafka脚本介绍</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417112654325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"3、Kafka架构分析\"><a href=\"#3、Kafka架构分析\" class=\"headerlink\" title=\"3、Kafka架构分析\"></a>3、Kafka架构分析</h2><p><img src=\"https://img-blog.csdnimg.cn/20210417113222162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"3-1-Broker\"><a href=\"#3-1-Broker\" class=\"headerlink\" title=\"3.1 Broker\"></a>3.1 Broker</h3><p>Kafka作为一个中间件，是帮我们存储和转发消息的，它做的事情有点像中介，所以我们把kafka的服务叫做Broker，默认是9092的端口。生产者和消费者都需要跟这个Broker建立一个连接，才可以实现消息的收发。</p>\n<h3 id=\"3-2-消息\"><a href=\"#3-2-消息\" class=\"headerlink\" title=\"3.2 消息\"></a>3.2 消息</h3><p>客户端之间传输的数据叫做消息，或者叫做记录（Record）。在客户端的代码中，Record可以是一个KV键值对，生产者的封装类是ProducerRecord，消费者的封装类是ConsumerRecord。<br>  消息在传输过程中需要序列化，所以在代码中要指定序列化工具。</p>\n<h3 id=\"3-3-生产者\"><a href=\"#3-3-生产者\" class=\"headerlink\" title=\"3.3 生产者\"></a>3.3 生产者</h3><p>发送消息的一方叫做生产者。为了提升发送效率，生产者不是逐条发送消息给Broker，而是批量发送的，发送的数据大小和时间间隔由以下参数决定：</p>\n<pre><code>batch.size=16384\nlinger.ms=0\n</code></pre>\n<h3 id=\"3-4-消费者\"><a href=\"#3-4-消费者\" class=\"headerlink\" title=\"3.4 消费者\"></a>3.4 消费者</h3><p>接收消息的一方叫做消费者。<br>  —般来说消费者获取消息有两种模式，一种是pull模式，一种是push模式。Pull模式就是消费放在Broker,消费者自己决定什么时候去获取。Push模式是消息放在Consumer，只要有消息到达Broker,都直接推给消费者。<br>  Kafka只支持pull模式，因为在push模式下，如果消息产生速度远远大于消费者消费消息的速率，那消费者就会不堪重负（你已经吃不下了，但是还要不断地往你嘴里塞），直到挂掉。而且在pull模式下消费者一次pull获取多少条消息由以下参数决定：</p>\n<pre><code>max.poll.records=500\n</code></pre>\n<h3 id=\"3-5-Topic\"><a href=\"#3-5-Topic\" class=\"headerlink\" title=\"3.5 Topic\"></a>3.5 Topic</h3><p>生产者跟消费者是怎么关联起来的呢？或者说，生产者发送的消息，怎么才能到达某个特定的消费者？他们要通过队列关联起来，也就是说，生产者发送消息，要指定发给哪个队列。消费者接收消息，要指定从哪个队列接收。在Kafka里面，这个队列叫做Topic。它是一个逻辑的概念，可以理解为一组消息的集合（用以区分不同业务用途的消息）。<br>  注意，生产者发送消息时，如果Topic不存在，会自动创建。由以下参数决定：</p>\n<pre><code>auto.create.topics.enable=true\n</code></pre>\n<h3 id=\"3-6-Partition\"><a href=\"#3-6-Partition\" class=\"headerlink\" title=\"3.6 Partition\"></a>3.6 Partition</h3><p>如果说一个Topic中的消息太多，会带来两个问题：<br>  第一个是不方便横向扩展，比如我想要在集群中把数据分布在不同的机器上实现扩展，而不是通过升级硬件做到，如果一个Topic的消息无法在物理上拆分到多台机器的时候，这个是做不到的。<br>  第二个是并发或者负载的问题，所有的客户端操作的都是同一个Topic,在高并发的场景下性能会大大下降。<br>  怎么解决这个问题呢？我们想到的就是把一个Topic进行拆分。 Kafka引入了一个分区(Partition)的概念。一个Topic可以划分成多个分区。 分区在创建topic的时候指定，每个topic至少有一个分区。<br>  在创建topic时需要指定分区数由以下参数决定：</p>\n<pre><code>num.partitions=1\n</code></pre>\n<p>Partition思想上有点类似于分库分表，实现的也是横向扩展和负载的目的。举个例子，Topic有3个分区，生产者依次发送9条消息，对消息进行编号。 第一个分区存1 4 7,第二个分区存2 5 8,第三个分区存3 6 9，这个就实现了负载。</p>\n<h3 id=\"3-7-Replica\"><a href=\"#3-7-Replica\" class=\"headerlink\" title=\"3.7 Replica\"></a>3.7 Replica</h3><p>如果partition的数据只存储一份，在发生网络或者硬件故障的时候，该分区的数据就无法访问或者无法恢复了。<br>  Kafka在0.8的版本之后增加了副本机制。每个partition可以有若干个副本(Replica)，副本必须在不同的Broker 上面。—般我们说的副本包括其中的主节点。由 replication-factor指定一个Topic 的副本数。默认副本数由以下参数决定</p>\n<pre><code>offsets.topic.replication.factor=1\n</code></pre>\n<p>举例：部署了 3个Broker,该topic有3个分区，每个分区一共3个副本。<br><img src=\"https://img-blog.csdnimg.cn/20210417123522406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  注意：这些存放相同数据的partition副本有leader（图中红色）和follower（图中绿色）的概念。leader在哪台机器是不一定的，选举岀来的。</p>\n<h3 id=\"3-8-Segment\"><a href=\"#3-8-Segment\" class=\"headerlink\" title=\"3.8 Segment\"></a>3.8 Segment</h3><p>Kafka的数据是放在后缀.log的文件里面的。如果一个partition只有一个log文件，消息不断地追加，这个log文件也会变得越来越大，这个时候要检索数据效率就很低了。所以干脆把partition再做一个切分，切分岀来的单位就叫做段（segment）。实际上kafka的存储文件是划分成段来存储的。默认存储路径：&#x2F;tmp&#x2F;kafka-logs&#x2F; 。每个segment都有至少有1个数据文件和2个索引文件，这3个文件是成套出现的。</p>\n<h3 id=\"3-9-Consumer-Group\"><a href=\"#3-9-Consumer-Group\" class=\"headerlink\" title=\"3.9 Consumer Group\"></a>3.9 Consumer Group</h3><p>我们知道消息中间件一般会支持发布&#x2F;订阅模式和广播模式，那么在Kafka中是如何实现的呢？或者换一种问法，当多个消费者订阅了同一个topic的时候，该如何区分这条消息是要单发还是群发呢？<br>  Kafka引入了消费者组Consumer Group的概念，通过group.id来配置，group.id相同的消费者属于同一个消费者组，Kafka对不同消费者组进行广播，而同一个消费者组中的消费者只消费一次消息。<br>  具体点说，同一个消费者组的消费者不能订阅相同的分区。当消费者数量小于分区数时，一个消费者消费多个分区，当消费者数量大于分区数时，多余的消费者将不进行工作。</p>\n<h3 id=\"3-10-Consumer-Offset\"><a href=\"#3-10-Consumer-Offset\" class=\"headerlink\" title=\"3.10 Consumer Offset\"></a>3.10 Consumer Offset</h3><p>我们已经知道Kafka消息是写在日志文件中，并且不会在消费过后就被删除。那么当一个消费者组在消费一半时重启了，该如何继续上一次的位置读取消息呢？为此，Kafka引入Consumer Offset的概念。<br>  Consumer Offset是标记一个消费者组在一个partition即将消费的下一条记录，这个信息直接保存在Kafka本身一个特殊的topic中，叫__consumer_offsets，默认创建50个分区。</p>\n<h2 id=\"4、Kafka原理\"><a href=\"#4、Kafka原理\" class=\"headerlink\" title=\"4、Kafka原理\"></a>4、Kafka原理</h2><h3 id=\"4-1-Kafka生产者原理\"><a href=\"#4-1-Kafka生产者原理\" class=\"headerlink\" title=\"4.1 Kafka生产者原理\"></a>4.1 Kafka生产者原理</h3><h4 id=\"4-1-1-生产者发送流程\"><a href=\"#4-1-1-生产者发送流程\" class=\"headerlink\" title=\"4.1.1 生产者发送流程\"></a>4.1.1 生产者发送流程</h4><p>消息发送的整体流程。生产端主要由两个线程协调运行。这两条线程分别为main线程和sender线程（发送线程）。<br>  在创建KafkaProducer的时候，创建了一个Sender对象，并且启动了—个IO线程。</p>\n<h5 id=\"4-1-1-1-拦截器\"><a href=\"#4-1-1-1-拦截器\" class=\"headerlink\" title=\"4.1.1.1 拦截器\"></a>4.1.1.1 拦截器</h5><p>第二步是执行拦截器的逻辑，在producer.send方法中:</p>\n<pre><code>ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors.onSend(record);\n</code></pre>\n<p>拦截器的作用是实现消息的定制化（类似于Spring Interceptor、MyBatis的插件、Quartz的监听器）。那这个拦截器是在哪里定义的呢？生产者代码：</p>\n<pre><code>List&lt;String&gt; interceptors = new ArrayList&lt;&gt;(); \ninterceptors.add(&quot; com.xxx.interceptor.Charginginterceptor&quot;); \nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n</code></pre>\n<p>举个例子，假设发送消息的时候要扣钱，发一条消息1分钱（我把这个功能叫做按量付费），就可以用拦截器实现。</p>\n<pre><code>public class Charginginterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;\n    //发送消息的时候触发\n    @Override\n    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;\n     \tSystem.out.println(&quot;1分钱1条消息，不管那么多反正先扣钱”);\n        return record;\n    &#125;\n\n    //收到服务端的ACK的时候触发\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;\n        System.out.pnntln(n消息被服务端接收啦”);\n    &#125;\n    \n    @Override \n    public void close() &#123;\n        System.out.printin(”生产者关闭了&quot;);\n    &#125;\n    \n    //用键值对配置的时候触发\n    @Override\n    public void configure(Map&lt;String, ?&gt; configs) &#123;\n        System. out.piintln(n configure...H);\n    &#125;\n&#125;\n</code></pre>\n<h5 id=\"4-1-1-2-序列化\"><a href=\"#4-1-1-2-序列化\" class=\"headerlink\" title=\"4.1.1.2 序列化\"></a>4.1.1.2 序列化</h5><p>接下来是利用指定的工具对key和value进行序列化：</p>\n<pre><code>serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());\n</code></pre>\n<p>kafka针对不同的数据类型自带了相应的序列化工具。<br><img src=\"https://img-blog.csdnimg.cn/20210417162458711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  除了自带的序列化工具之外，可以使用如Avro、JSON、Thrift. Protobuf等，或者使用自定义类型的序列化器来实现，实现Serializer接口即可。</p>\n<h5 id=\"4-1-1-3-分区路由\"><a href=\"#4-1-1-3-分区路由\" class=\"headerlink\" title=\"4.1.1.3 分区路由\"></a>4.1.1.3 分区路由</h5><p>然后是分区指定：</p>\n<pre><code>int partition = partition(record, serializedKey, serialized Value, cluster);\n</code></pre>\n<p>一条消息会发送到哪个partition呢？它返回的是一个分区的编号，从0开始。有四种情况:</p>\n<ol>\n<li>指定了partition——直接将指定的值直接作为partiton值。</li>\n<li>没有指定partition,自定义了分区器——将使用自定义的分区器算法选择分区。</li>\n<li>没有指定partition,没有自定义分区器，但是key不为空——使用默认分区器DefaultPartitioner,将<br>key的hash值与topic的partition数进行取余得到partition值；</li>\n<li>没有指定partition,没有自定义分区器，但是key是空的——第一次调用时随机生成一个整数(后面每次调用在这个整数上自增)，将这个值与topic可用的partition总数取余得到 partition值，也就是常说的round-robin算法。</li>\n</ol>\n<h5 id=\"4-1-1-4-消息累加器\"><a href=\"#4-1-1-4-消息累加器\" class=\"headerlink\" title=\"4.1.1.4 消息累加器\"></a>4.1.1.4 消息累加器</h5><p>选择分区以后并没有直接发送消息，而是把消息放入了消息累加器：</p>\n<pre><code>RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptcallback, remainingWaitMs);\n</code></pre>\n<p>RecordAccumulator 本质上是一个 ConcurrentMap:</p>\n<pre><code>ConcurrentMap&lt;TopicPailition Deque&lt;ProducerBatc&gt;&gt; batches;\n</code></pre>\n<p>—个partition —个Batch。batch满了之后，会唤醒Sender线程，发送消息:</p>\n<pre><code>if (result.batchlsFull || result.newBatchCreated) &#123;\n    log.trace(Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;, record.topic(), partition);\n    this.sender.wakeup();\n&#125;\n</code></pre>\n<h4 id=\"4-1-2-消息应答机制ACK\"><a href=\"#4-1-2-消息应答机制ACK\" class=\"headerlink\" title=\"4.1.2 消息应答机制ACK\"></a>4.1.2 消息应答机制ACK</h4><h5 id=\"4-1-2-1-服务端响应策略\"><a href=\"#4-1-2-1-服务端响应策略\" class=\"headerlink\" title=\"4.1.2.1 服务端响应策略\"></a>4.1.2.1 服务端响应策略</h5><p>生产者的消息是不是发出去就完事了？如果说网络出了问题，或者说kafka服务端接收的时候出了问题，这个消息发送失败了，生产者是不知道的。所以，kafka服务端应该要有一种响应客户端的方式，只有在服务端确认以后，生产者才发送下一轮的消息，否则重新发送数据。<br>  服务端什么时候才算接收成功呢？因为消息是存储在不同的partition里面的，所以是写入到partition之后响应生产者。当然，单个partition (leader)写入成功，还是不够可靠，如果有多个副本，follower 也要写入成功才可以。<br>  为了安全性考虑，Kafka会等待所有的follower全部完成同步，才发送ACK给客户端，延迟相对来说高一些，但是节点挂掉的影响相对来说小一些，因为所有的节点数据都是完整的。</p>\n<h5 id=\"4-1-2-2-ISR\"><a href=\"#4-1-2-2-ISR\" class=\"headerlink\" title=\"4.1.2.2 ISR\"></a>4.1.2.2 ISR</h5><p>然而以上方案仍然存在问题：假设leader收到数据，所有follower都开始同步数据，但是有一个follower出了问题，没有办法从leader同步数据。按照这个规则，leader就要一致等待，无法发送 ack。<br>  从概率的角度来讲，这种问题肯定是会出现的，就是某个follower出问题了，怎么解决呢？所以我们的规则就不能那么粗暴了，把规则改一下，不是所有的follower都有权利 让我等待，而是只有那些正常工作的follower同步数据的时候我才会等待。<br>  我们应该把那些正常和leader保持同步的replica维护起来，放到一个动态set里面，这个就叫做in-sync replica set (ISR)。现在只要ISR里面的follower同步完数据之后，我就给客户端发送ACK。如果一个follower长时间不同步数据，就要从ISR剔除。同样，如果后面这个follower重新与leader保持同步，就会重新加入ISR。时间间隔由以下参数决定：</p>\n<pre><code>replica.lag.time.max.ms=10000\n</code></pre>\n<h5 id=\"4-1-2-3-ACK应答\"><a href=\"#4-1-2-3-ACK应答\" class=\"headerlink\" title=\"4.1.2.3 ACK应答\"></a>4.1.2.3 ACK应答</h5><p>当然，如果所有的数据都一视同仁，而且这种策略只能由服务端决定，这就不是很灵活了。有一些数据丢了无所谓，我只想要快，不管它落没落盘同没同步，怎么办呢？<br>  Kafka为客户端提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择相应的配置。</p>\n<ul>\n<li><strong>acks&#x3D;0：</strong> producer不等待broker的ack,这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</li>\n<li><strong>acks&#x3D;1（默认）：</strong> producer 等待 broker 的 ack, partition 的 leader 落盘成功后 返回ack,如果在follower同步成功之前leader故障，那么将会丢失数据；</li>\n<li><strong>acks&#x3D;-1 (all) ：</strong> producer等待 broker 的 ack, partition 的 Ieader和 follower全部落盘成功后才返回ack。</li>\n</ul>\n<p>三种机制，性能依次递减（producer吞吐量降低），数据健壮性则依次递增。我们可 以根据业务场景使用不同的参数。</p>\n<h3 id=\"4-2-Kafka消息存储原理\"><a href=\"#4-2-Kafka消息存储原理\" class=\"headerlink\" title=\"4.2 Kafka消息存储原理\"></a>4.2 Kafka消息存储原理</h3><h4 id=\"4-2-1-数据存储目录\"><a href=\"#4-2-1-数据存储目录\" class=\"headerlink\" title=\"4.2.1 数据存储目录\"></a>4.2.1 数据存储目录</h4><p>目录配置在配置文件config&#x2F;env.properties，由以下参数决定：</p>\n<pre><code>logs.dir=/tmp/kafka-logs\n</code></pre>\n<h4 id=\"4-2-2-partition分区\"><a href=\"#4-2-2-partition分区\" class=\"headerlink\" title=\"4.2.2 partition分区\"></a>4.2.2 partition分区</h4><p>为了实现横向扩展，把不同的数据存放在不同的Broker上,同时降低单台服务器的访问压力，我们把一个topic中的数据分隔成多个partition。—个partition中的消息是有序的，顺序写入，但是全局不一定有序。<br>  在服务器上，每个partition都有一个物理目录，topic名字后面的数字标号即代表分区。<br><img src=\"https://img-blog.csdnimg.cn/20210417170640277.png\" alt=\"在这里插入图片描述\"></p>\n<h4 id=\"4-2-3-replica副本\"><a href=\"#4-2-3-replica副本\" class=\"headerlink\" title=\"4.2.3 replica副本\"></a>4.2.3 replica副本</h4><p>为了提高分区的可靠性，kafka又设计了副本机制。创建topic的时候，通过指定replication-factor确定topic的副本数。<br>  注意：副本数必须小于等于节点数，而不能大于Broker的数量，否则会报错。<br>  这些所有的副本分为两种角色，leader对外提供读写服务。follower唯一的任务就是从leader异步拉取数据。</p>\n<h4 id=\"4-2-4-副本分布规则\"><a href=\"#4-2-4-副本分布规则\" class=\"headerlink\" title=\"4.2.4 副本分布规则\"></a>4.2.4 副本分布规则</h4><p>副本在Broker的分布有什么规则吗？例如有个topic：a4part2rep, 4个分区每个2个副本，一共8份副本，怎么分布到3台机器呢？<br><img src=\"https://img-blog.csdnimg.cn/20210417171144308.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  实际副本分布规则是由AdminUtils.scala——assignReplicasToBrokers决定的，具体规则如下：</p>\n<ol>\n<li>副本因子不能大于Broker的个数；</li>\n<li>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；</li>\n<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移 （nextReplicaShift）。</li>\n</ol>\n<p>这样设计可以提高容灾能力。在每个分区的第一个副本错开之后，一般第一个分区的第一个副本（按Broker编号排序）都是leader。leader是错开的，不至于一挂影响太大。</p>\n<h4 id=\"4-2-5-Segment\"><a href=\"#4-2-5-Segment\" class=\"headerlink\" title=\"4.2.5 Segment\"></a>4.2.5 Segment</h4><p>为了防止log不断追加导致文件过大，导致检索消息效率变低，一个partition又被划分成多个segment来组织数据。在磁盘上，每个segment由一个log文件和2个index文件组成。这三个文件是成套出现的。另外还有一个leader-epoch-checkpoint文件中保存了每一任leader开始写入消息时的offset。<br><img src=\"https://img-blog.csdnimg.cn/20210418150929793.png\" alt=\"在这里插入图片描述\"></p>\n<p>1 .log日志文件（日志就是数据）<br>  在一个segment文件里面，日志是追加写入的。如果满足一定条件，就会切分日志文件，产生一个新的segment什么时候会触发segment的切分呢？<br>  第一种是根据日志文件大小。当一个segment写满以后，会创建一个新的segment, 用最新的offset作为名称。文件大小由以下参数控制（默认1G）：</p>\n<pre><code>log.segment.bytes=1073741824\n</code></pre>\n<p>第二种是根据消息的最大时间戳，和当前系统时间戳的差值。还可以从更加精细的时间单位进行控制，如果配置了毫秒级别的日志切分间隔，会优先使用这个单位。否则就用小时的。间隔时间由以下参数决定：</p>\n<pre><code>log.roll.hours=168\nlog.roll.ms\n</code></pre>\n<p>还有第三种情况，offset索引文件或者timestamp索引文件达到了一定的大小。由参数<strong>log.index.size.max.bytes（默认10M）</strong> 控制。如果要减少日志文件的切分，可以把这个值调大一点。<br>2. .index偏移量(offset)索引文件<br>3. .timeindex 时间戳(timestamp)索引文件</p>\n<h4 id=\"4-2-6-索引\"><a href=\"#4-2-6-索引\" class=\"headerlink\" title=\"4.2.6 索引\"></a>4.2.6 索引</h4><p>由于一个segment的文件里面可能存放很多消息，如果要根据offset获取消息，必须要有一种快速检索消息的机制。这个就是索引。在Kafka中设计了两种索引：偏移量索引文件记录的是。offset和消息物理地址（在log文件中的位置）的映射关系。时间戳索引文件记录的是时间戳和offset的关系。<br>  内容是二进制的文件，不能以纯文本形式查看。bin目录下有dumplog工具。 查看最后10条offset索引：</p>\n<pre><code>./kafka-dump-log.sh —files /tmp/kafl&lt;a-logs/mytopic-0/00000000000000000000.index|head -n 10\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/20210418154758336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>注意，Kafka的索引并不是每一条消息都会建立索引，而是一种稀疏索引sparse index（DB2和Mongdb中都有稀疏索引）。至于这个索引有多稀疏，由以下参数决定：</p>\n<pre><code>log.index.interval.bytes=4096\n</code></pre>\n<p>只要写入的消息超过了 4KB,偏移量索引文件index和时间戳索引文件.timeindex就会増加一条索引记录(索引项)。这个值设置越小，索引越密集。值设置越大，索引越稀疏。相对来说，越稠密的索引检索数据更快，但是会消耗更多的存储空间。越的稀疏索引占用存储空间小，但是插入和删除时所需的维护开销也小。Kafka索引的时间复杂度为O(log2n)+O(m),n是索引文件里索引的个数，m为稀疏程度。<br>  第二种索引类型是时间戳索引。时间戳有两种，一种是消息创建的时间戳，一种是消费在Broker追加写入的时间。到底用哪个时间由以下参数控制：</p>\n<pre><code>log.message.timestamp.type=CreateTime\n</code></pre>\n<p>默认是创建时间。如果要改成日志追加时间，则修改为LogAppendTime。査看最早的10条时间戳索引：</p>\n<pre><code>./kafka-dump-log.sh —files /tmp/kafka-logs/mytopic-0/00000000000000000000.timeindex|head -n 10\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/20210418154859613.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  那么Kafka如何基于索引快速检索消息？比如我要检索偏移量是10002673的消息。</p>\n<ol>\n<li>消费的时候是能够确定分区的，所以第一步是找到在哪个segment中。Segment 文件是用base offset命名的，所以可以用二分法很快确定（找到名字不大于10002673 的 最大segment）。</li>\n<li>这个segment有对应的索引文件，它们是成套出现的。所以现在要在索引文件中根据offset找position。</li>\n<li>得到position之后，到对应的log文件开始査找offset,和消息的offset进行比较，直到找到消息。<br><img src=\"https://img-blog.csdnimg.cn/20210418155346397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n</ol>\n<h4 id=\"4-2-7-日志清理策略\"><a href=\"#4-2-7-日志清理策略\" class=\"headerlink\" title=\"4.2.7 日志清理策略\"></a>4.2.7 日志清理策略</h4><p>由于Kafka的日志并没有在消费后马上删除，随着时间的推移，日志越来越多，需要有相应的清理策略来保证系统的健康，日志清理的开关由以下参数控制：</p>\n<pre><code>log.cleaner.enable=true\n</code></pre>\n<p>Kafka提供了两种清理方式，分别是删除delete和压缩compact，由以下参数控制：</p>\n<pre><code>log.cleanup.policy=delete\n</code></pre>\n<p>日志删除的功能是由定时任务完成的，定时任务运行的时间间隔由以下参数控制：</p>\n<pre><code>log.retention.check.interval.ms=300000\n</code></pre>\n<p>删除多久以前的数据由以下参数控制（精度越小优先级越高）：</p>\n<pre><code>log.retention.hours=168\nlog.retention.minutes\nlog.retention.ms\n</code></pre>\n<p>还可以根据保留日志的大小来删除数据，超出该大小则删除最早的数据，由以下参数控制（默认-1代表不限制）：</p>\n<pre><code>log.retention.bytes=-1\n</code></pre>\n<p>若采取压缩的清理方式，则会根据相同的key进行压缩，当消息的key相同时，只保留最新的value。<br><img src=\"https://img-blog.csdnimg.cn/20210418164159281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h4 id=\"4-2-8-Controller选举\"><a href=\"#4-2-8-Controller选举\" class=\"headerlink\" title=\"4.2.8 Controller选举\"></a>4.2.8 Controller选举</h4><p>当创建添加一个的分区或者分区增加了副本的时候，都要从所有副本中选举一个新的Leader出来。<br>  投票怎么玩？是不是所有的partition副本直接发起投票，开始竞选呢？比如用ZK 实现。<br>  利用ZK怎么实现选举？ZK的什么功能可以感知到节点的变化（增加或者减少）? 或者说，ZK为什么能实现加锁和释放锁？<br>  3个特点：watch机制；节点不允许重复写入；临时节点。<br>  这样实现是比较简单，但是也会存在一定的弊端。如果分区和副本数量过多，所有的副本都直接进行选举的话，一旦某个出现节点的增减，就会造成大量的watch事件被触发，ZK的负载就会过重。<br>  Kafka早期的版本（0.82及以前）就是这样做的，后来换了一种实现方式。<br>  不是所有的repalica都参与leader选举，而是由其中的一个Broker统一来指挥， 这个Broker的角色就叫做Controller（控制器）。<br>  就像Redis Sentinel的架构，执行故障转移的时候，必须要先从所有哨兵中选一个负责做故障转移的节点一样。Kafka也要先从所有Broker中选出唯一的一个Controller，所有的Broker会尝试在zookeeper中创建临时节点&#x2F;controller,只有一个能创建成功（先到先得）。<br>  如果Controller挂掉了或者网络出现了问题，ZK上的临时节点会消失。其他的Broker通过watch监听到Controller下线的消息后，开始竞选新的Controller。方法跟之前还是一样的,谁先在ZK里面写入一个&#x2F;controller节点,谁就成为新的Controller。<br>  一个节点成为Controller之后，它肩上的责任也比别人重了几份，正所谓劳力越戴, 责任越大：</p>\n<ul>\n<li>监听Broker变化。</li>\n<li>监听Topic变化。</li>\n<li>监听Partition变化。</li>\n<li>获取和管理Broker、Topic、Partition的信息。</li>\n<li>管理Partiontion的主从信息。</li>\n</ul>\n<h4 id=\"4-2-9-分区副本Leader选举\"><a href=\"#4-2-9-分区副本Leader选举\" class=\"headerlink\" title=\"4.2.9 分区副本Leader选举\"></a>4.2.9 分区副本Leader选举</h4><p>Controller确定以后，开始进行leader选举。副本有3个概念：</p>\n<ul>\n<li>**Assigned-Replicas (AR)**：一个分区的所有副本</li>\n<li>**In-Sync Replicas (ISR)**：一个分区中跟leader数据保持一定程度的同步的副本</li>\n<li>**Out-Sync-Replicas (OSR)**：跟leader副本同步滞后过多的副本</li>\n</ul>\n<p>只有ISR有资格参加leader选举。而且这个ISR不是固定不变的，它是一个动态的列表。<br>如果同步延迟超过30秒，就踢出ISR，进入OSR。如果赶上来了， 就加入ISR。默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader。极端情况下，如果ISR为空，则可以允许ISR之外的副本参与选举，由以下参数控制：</p>\n<pre><code>unclean.leader.election.enable=true\n</code></pre>\n<p>注意，这种情况下可能造成数据丢失。<br>  那么leader的选举规则是什么呢？它使用一种类似微软的PacificA算法，在这种算法中，默认是让ISR中第一个replica变成leader。比如ISR是1、5、9, 优先让1成为leader。这个跟中国古代皇帝传位是一样的，优先传给皇长子。</p>\n<h4 id=\"4-2-10-主从同步\"><a href=\"#4-2-10-主从同步\" class=\"headerlink\" title=\"4.2.10 主从同步\"></a>4.2.10 主从同步</h4><p>Leader确定之后，客户端的读写只能操作leader节点。follower需要向leader同步数据。不同的raplica的offset是不一样的，同步到底怎么同步呢？<br>  首先需要认识几个概念：<br><strong>LEO (Log End Offset)：</strong> 下一条等待写入的消息的offset (最新的offset + 1),图中分别是9, 8, 6。<br><strong>HW (Hign Watermark):</strong> ISR中最小的LEO。Leader会管理所有ISR中最小的 LEO作为HW,目前是6。<br><img src=\"https://img-blog.csdnimg.cn/20210418214659821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  consumer最多只能消费到HW之前的位置(消费到offset 5的消息)。也就是说: 其他的副本没有同步过去的消息，是不能被消费的。<br>  有了这两个offset之后，再来看看消息怎么同步：</p>\n<p>followerl同步了1条消息，follower2同步了2条消息。此时HW推进了2,变成8。<img src=\"https://img-blog.csdnimg.cn/20210418214946178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  followerl同步了0条消息，follower2同步了1条消息。此时HW推进了1，变成9。LEO和HW重叠，所有的消息都可以消费了。<br><img src=\"https://img-blog.csdnimg.cn/20210418215103808.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  这里，我们关注一下，从节点怎么跟主节点保持同步？</p>\n<ol>\n<li>follower节点会向Leader发送一个fetch请求，leader向follower发送数据后，既需要更新follower的LEO。</li>\n<li>follower接收到数据响应后，依次写入消息并且更新LEO。</li>\n<li>leader 更新 HW （ISR 最小的 LEO）。</li>\n</ol>\n<p>kafka设计了独特的ISR复制，可以在保障数据一致性情况下又可提供高吞吐量。</p>\n<h4 id=\"4-2-11-replica故障处理\"><a href=\"#4-2-11-replica故障处理\" class=\"headerlink\" title=\"4.2.11 replica故障处理\"></a>4.2.11 replica故障处理</h4><h5 id=\"4-2-11-1-follower故障\"><a href=\"#4-2-11-1-follower故障\" class=\"headerlink\" title=\"4.2.11.1 follower故障\"></a>4.2.11.1 follower故障</h5><p>首先follower发生故障，会被先踢出ISR。follower恢复之后，从哪里开始同步数据呢？假设第1个replica宕机（中间这个）。<br><img src=\"https://img-blog.csdnimg.cn/20210418220330233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  恢复以后，首先根据之前记录的HW （6）,把高于HW的消息截掉（6、7）。然 后向leader同步消息。追上leader之后（30秒），重新加入ISR。</p>\n<h5 id=\"4-2-11-2-leader故障\"><a href=\"#4-2-11-2-leader故障\" class=\"headerlink\" title=\"4.2.11.2 leader故障\"></a>4.2.11.2 leader故障</h5><p>假设图中leader发生故障。首先选一个leader。因为replica 1 （中间这个）优先，它成为leader。为了保证数据一致，其他的follower需要把高于HW的消息截取掉（这里没有消息需要截取）。然后replica2同步数据。注意：这种机制只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>\n<h5 id=\"4-2-11-3-上面这两种方式没有问题吗？（全文重点！！！）\"><a href=\"#4-2-11-3-上面这两种方式没有问题吗？（全文重点！！！）\" class=\"headerlink\" title=\"4.2.11.3 上面这两种方式没有问题吗？（全文重点！！！）\"></a>4.2.11.3 上面这两种方式没有问题吗？（全文重点！！！）</h5><p>实际上，副本同步机制并没有上面说的那么简单。假设有A(leader)、B两个副本——<br>  作为leader，A还会维护每个副本的远程LEO值remoteLEO;<br>  作为follower，B会定时发送fetch请求给A拉取数据，在fetch时将自己当前的LEO和HW发送给A。<br>1）初始化状态时：<br>  LEO(A)&#x3D;0, HW(A)&#x3D;0，remoteLEO&#x3D;0;<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>2）当生产者发送一条数据m1时：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>3）B向A发起fetch请求，发送自己当前的LEO给A：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>4）A根据B发送的LEO,更新remoteLEO&#x3D;0，更新HW(A)&#x3D;min(LEO(A), remoteLEO(B))&#x3D;0，同时将HW(A)和未同步的数据m1发送给B：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;0，HW(B)&#x3D;0;</p>\n<p>5）B根据A返回的HW(A)，写入数据m1，同时更新LEO(B)&#x3D;1，HW(B)&#x3D;min(HW(A), LEO(B))&#x3D;0，<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;0;[m1]</p>\n<p>6）B向A发起第二次fetch请求，发送自己当前的LEO(B)&#x3D;1：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;0，remoteLEO&#x3D;0;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;0;[m1]</p>\n<p>7）此时A更新remoteLEO&#x3D;1，HW(A)&#x3D;min(LEO(A), remoteLEO(B))&#x3D;1，同时返回HW给B：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;1，remoteLEO&#x3D;1;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;0;[m1]</p>\n<p>8）B根据A返回的HW(A)，更新HW(B)&#x3D;min(HW(A), LEO(B))&#x3D;1，<br>  LEO(A)&#x3D;1, HW(A)&#x3D;1，remoteLEO&#x3D;1;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;1;[m1]</p>\n<p>这是一轮常规的数据同步，设想一下，当leader或者follower出现故障时，会导致什么问题？我们知道可以通过acks来控制消息的可靠性，那么当acks&#x3D;-1(all)的时候是否数据一定不会丢失？<br>  首先，我们要明白数据丢失的概念，一定是在leader返回ack但是数据不存在的情况下才叫数据丢失，如果leader没有返回ack，也就是说生产者知道消息没发送成功的话，不算数据丢失。那么假设acks&#x3D;-1的话，实际上leader是在步骤7）执行完毕后就返回ack给生产者。在这个前提下我们分析几个场景。<br>场景一：<br>  假设ISR中只有一个leader副本，且成功写入数据。此时leader挂掉，若参数设置允许OSR中的副本抢占leader的话，可能导致数据丢失。<br>  这种场景系统也无法处理，所以Kafka交给用户自行选择，若unclean.leader.election.enable&#x3D;true则无法保证消息的可靠性，若unclean.leader.election.enable&#x3D;false则无法保证系统的效率和可用性。<br>场景二：<br>  在执行完步骤7）之后B挂掉了，而当B重启之后（注意此时HW(B)&#x3D;0），根据4.2.11.1的做法，会先将超出HW(B)的消息m1抛弃，重新从A拉取数据。更极端的情况下，此时A恰好也挂掉，这时候B就会通过选举成为leader。而A重启之后成为follower，会通过截取m1的方式与leader保持同步。至此，消息m1丢失。更严重的是，若A重启之前，B又接收了生产者发送的新的数据m2，那么A重启后由于HW(A)&#x3D;1，将不会从B拉取到消息m2，结果如下：<br>  LEO(A)&#x3D;1, HW(A)&#x3D;1，remoteLEO&#x3D;1;[m1]<br>  LEO(B)&#x3D;1，HW(B)&#x3D;1;[m2]</p>\n<p>鉴于场景2，Kafka在0.11版本后增加了一个<strong>leader-epoch-checkpoint</strong>的概念，以文件的形式保存在日志目录下，当一个新的leader在写入第一条消息时，会在文件中记录一条信息，包括leader年代（即leader更换次数）epoch和当前leader写入的第一个offset。<br>  举个例子，当这个分区写入第一条消息时，leader-epoch-checkpoint文件中会记录一条信息（0 0），在写入50条消息之后leader挂掉并发生选举，leader-epoch-checkpoint会增加一条记录（1 50）。<br>  有了这种机制，当follower重启之后就不需要直接丢弃HW之后的数据，而是会发起一次请求对比leader中的epoch与自身的epoch：<br>  若epoch相等则只丢弃自身LEO大于leader的LEO的部分（即，若自身LEO不大于leader的LEO则不进行截取，与原来直接截取到HW有所差别）；<br>  若epoch不相等（自身小于leader的LEO）则将自身LEO与leader-epoch-checkpoint中epoch大于自身epoch的最小值的LEO相比较，丢弃自身LEO大于该LEO的数据。</p>\n<p>这部分有点绕，以刚才的例子说明，假设步骤7）执行完毕后B重启，此时：<br>  若B重启期间未发生leader选举，则A的leader-epoch-checkpoint文件与B一致，都是(0 0)，即epoch(A)&#x3D;epoch(B),此时LEO(B)&#x3D;LEO(A)&#x3D;1，无需截取。<br>  若B重启期间发生过leader选举（假设存在副本C、D），则leader-epoch-checkpoint文件存在多条记录(0 0)，(1 10)，(2 50)（又发生两次选举），此时B的epoch小于2，会将B的LEO与10比较（大于epoch(B)的最小epoch是1），同样不会丢弃数据。<br>  以上，就是0.11版本Kafka的数据同步方案。</p>\n<h3 id=\"4-3-Kafka消费者原理\"><a href=\"#4-3-Kafka消费者原理\" class=\"headerlink\" title=\"4.3 Kafka消费者原理\"></a>4.3 Kafka消费者原理</h3><h4 id=\"4-3-1-Offset的维护\"><a href=\"#4-3-1-Offset的维护\" class=\"headerlink\" title=\"4.3.1 Offset的维护\"></a>4.3.1 Offset的维护</h4><h5 id=\"4-3-1-1-Offset的存储\"><a href=\"#4-3-1-1-Offset的存储\" class=\"headerlink\" title=\"4.3.1.1 Offset的存储\"></a>4.3.1.1 Offset的存储</h5><p>我们知道在partition中，消息是不会删除的，所以才可以追加写入，写入的消息连续有序的。这种特性决定了 kafka可以消费历史消息，而且按照消息的顺序消费指定消息，而不是只能消费队头的消息。正常情况下，我们希望消费没有被消费过的数据，而且是从最先发送（序号小的） 的开始消费（这样才是有序和公平的）。<br>  那么对于一个partition,消费者组怎么才能做到接着上次消费的位置（offset）继续消费呢？肯定要把这个对应关系保存起来，下次消费的时候查找一下。<br>  首先这个对应关系确实是可以查看的。比如消费者组gp-assign-group-1和 ass5part （5个分区）的partition的偏移量关系，可使用如下命令査看：</p>\n<pre><code>./kafka-consumer-groups.sh “bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 —describe —group gp-assign-group-1\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/20210419010135861.png\" alt=\"在这里插入图片描述\"></p>\n<ul>\n<li>CURRENT-OFFSET指的是下一个未使用的offset。</li>\n<li>LEO , Log End Offset:下一条等待写入的消息的offset （最新的offset + 1）</li>\n<li>LAG是延迟量</li>\n</ul>\n<p>注意：这不是表示一个消费者和一个Topic的关系，而是一个consumer group和topic中的一个partition的关系（offset在partition中连续编号而不是全局连续编号）。</p>\n<p>那么这个对应关系到底是保存在哪里的呢？<br>  首先肯定是不可能放在消费者本地的。因为所有的消费者都可以使用这个consumer group id，放在本地是做不到统一维护的，肯定要放到服务端。<br>  Kafka早期的版本把消费者组和partition的offset直接维护在ZK中，但是读写的性能消耗太大了。后来就放在一个特殊的topic中，名字叫—consumer_offsets，默认有 50 个分区(offsets.topic.num.partitions 默认是 50)，每个分区默认一个replication。</p>\n<pre><code>./kafka・topics・sh —topic  \tconsumer_offsets —describe —zookeeper localhost:2181\n</code></pre>\n<p>那么这样一个特殊的Topic怎么存储消费者组gp-assign-group-1对于分区的偏移量的？Topic里面是可以存放对象类型的value的（经过序列化和反序列化）。这个Topic 里面主要存储两种对象：<br>  GroupMetadata:保存了消费者组中各个消费者的信息（每个消费者有编号）。<br>  OffsetAndMetadata:保存了消费者组和各个partition的offset位移信息元数据。</p>\n<pre><code>./kafka-console-consumer.sh —topic consumer_offsets --bootstrap-server 192.168.44.161:9093,192.168.44.161:9094,192.168.44.161:9095 -formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; —from-beginning\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/2021041901084354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  怎么知道一个consumer group的offset会放在这个特殊的Topic的哪个分区呢? 可以通过哈希取模计算得到：</p>\n<pre><code>Math.abs(&quot;gp-assign-group-1&quot;.hashCode()) % 50;\n</code></pre>\n<h5 id=\"4-3-1-2-如果找不到Offset\"><a href=\"#4-3-1-2-如果找不到Offset\" class=\"headerlink\" title=\"4.3.1.2 如果找不到Offset\"></a>4.3.1.2 如果找不到Offset</h5><p>如果增加了一个新的消费者组去消费—个topic的某个partion,没有offset的记录，这个时候应该从哪里开始消费呢？ 由以下参数控制：</p>\n<pre><code>auto.offset.reset=latest\n</code></pre>\n<p><strong>latest：</strong> 从最新的消息（最后发送的）开始消费。<br><strong>earliest：</strong> 从最早的（最先发送的）消息开始消费。可以消费到历史消息。<br><strong>none：</strong> 如果consumer group在服务端找不到offset会报错。</p>\n<h5 id=\"4-3-1-3-Offset的更新\"><a href=\"#4-3-1-3-Offset的更新\" class=\"headerlink\" title=\"4.3.1.3 Offset的更新\"></a>4.3.1.3 Offset的更新</h5><p>我们知道消费者组的offset是保存在Broker的，但是是由消费者上报给 Broker的。并不是消费者组消费了消息，Offset就会更新，消费者必须要有一个commit （提交）的动作。消费者可以自动提交或者手动提交。由以下参数控制：</p>\n<pre><code>enable.auto.commit=true\n</code></pre>\n<p>另外还可以使用一个参数来控制自动提交的频率：</p>\n<pre><code>auto.commit.interval.ms=5000\n</code></pre>\n<p>如果我们要在消费完消息做完业务逻辑处理之后才commit,就要把这个值改成 false。如果是false,消费者就必须要调用一个方法让Broker更新offset。有两种方式：<br>  consumer.commitSync()手动同步提交。<br>  consumer.commitAsync()手动异步提交。<br>  如果不提交或者提交失败,Broker的Offset不会更新，消费者下次消费的时候会受到重复消息。</p>\n<h4 id=\"4-3-2-消费者和消费策略\"><a href=\"#4-3-2-消费者和消费策略\" class=\"headerlink\" title=\"4.3.2 消费者和消费策略\"></a>4.3.2 消费者和消费策略</h4><h5 id=\"4-3-2-1-分区分配策略\"><a href=\"#4-3-2-1-分区分配策略\" class=\"headerlink\" title=\"4.3.2.1 分区分配策略\"></a>4.3.2.1 分区分配策略</h5><p>我们已经知道，在同一个消费者组中，一个分区只能被一个消费者消费。所以当消费者数量大于分区数量时，多余的消费者是无法消费消息的。那么如果分区数大于消费者数呢，Kafka又是如何分配的？<br>  为了保证系统最大的利用率，Kafka的分配策略一定会遵循一个最基本的原则——平均分配，简单理解，不会有任意两个消费者消费的分区数差大于1。在此基础上，Kafka有3种分区分配方式。以8个partition分配给3个consumer为例：<br><strong>1）Range（范围）</strong><br>  顾名思义，无需解释。<br>  C1：P0 P1 P2<br>  C2：P3 P4 P5<br>  C3：P6 P7<br><strong>2）RoundRobin（轮询）</strong><br>  顾名思义，无需解释。<br>  C1：P0 P3 P6<br>  C2：P1 P4 P7<br>  C3：P2 P5<br><strong>3）sticky（粘滞）</strong><br>  粘滞的分配策略较为复杂，它的核心思想是在分区重新分配时保证最小的移动（类似Redis的一致性hash思想，实现方式不同）。</p>\n<p>第一次分配类似轮询，结果如下：<br>  C1：P0 P3 P6<br>  C2：P1 P4 P7<br>  C3：P2 P5</p>\n<p>假设此时C2挂掉：<br>若按照RoundRobin，结果如下：<br>  C1：P0 P2 P4 P6<br>  C3：P1 P3 P5 P7</p>\n<p>sticky结果如下（尽量保证P0 P3 P6 P2 P5不动）：<br>  C1：P0 P3 P6 P1<br>  C3：P2 P5 P4 P7</p>\n<p>我们知道在分区分配时是会造成性能损耗的，若采用sticky分配策略可以尽可能减少性能损耗。该思想与Redis的一致性Hash是类似的，只是实现方式不同。</p>\n<h5 id=\"4-3-2-2-分区重分配Rebalance\"><a href=\"#4-3-2-2-分区重分配Rebalance\" class=\"headerlink\" title=\"4.3.2.2 分区重分配Rebalance\"></a>4.3.2.2 分区重分配Rebalance</h5><p>那么什么时候会触发分区重分配Rebalance呢？显然有两种情况，一种是消费者数量发生变化，一种是分区数量发生变化。Rebalance过程如下：</p>\n<ol>\n<li>确定协调者coordinator，通常由集群中负载最小的Broker承担。</li>\n<li>所有consumer向coordinator发送join group请求，确认自己是该组成员。</li>\n<li>coordinator在所有consumer中确定leader（通常是第一个）并由leader确定分区分配结果。</li>\n<li>coordinator向所有consumer发送分区分配结果。</li>\n</ol>\n<h4 id=\"4-3-3-Kafka为什么这么快？\"><a href=\"#4-3-3-Kafka为什么这么快？\" class=\"headerlink\" title=\"4.3.3 Kafka为什么这么快？\"></a>4.3.3 Kafka为什么这么快？</h4><h5 id=\"4-3-3-1-顺序读写\"><a href=\"#4-3-3-1-顺序读写\" class=\"headerlink\" title=\"4.3.3.1 顺序读写\"></a>4.3.3.1 顺序读写</h5><p>首先我们需要了解随机I&#x2F;O和顺序I&#x2F;O。<br>  磁盘的构造如图。磁盘的盘片不停地旋转，磁头会在磁盘表面画出一个圆形轨迹，这个就叫磁道。从内到位半径不同有很多磁道。然后又用半径线，把磁道分割成了扇区（两根射线之内的扇区组成扇面）。如果要读写数据, 必须找到数据对应的扇区，这个过程就叫寻址。<br>随机I&#x2F;O：读写的多条数据在磁盘上是分散的，寻址会很耗时。<br>顺序I&#x2F;O：读写的数据在磁盘上是集中的，不需要重复寻址的过程。<br><img src=\"https://img-blog.csdnimg.cn/20210419015453527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得 Kafka写入吞吐量得到了显著提升。<br>  顺序IO到底有多快呢？下图显示，在一定条件下测试，磁盘的顺序读写可以达到53.2M每秒，比内存的随机读写还要快。<br><img src=\"https://img-blog.csdnimg.cn/20210419015622131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h5 id=\"4-3-3-2-索引\"><a href=\"#4-3-3-2-索引\" class=\"headerlink\" title=\"4.3.3.2 索引\"></a>4.3.3.2 索引</h5><p>我们在写入日志的时候会建立关于Offset和时间的稀疏索引，提升了查找效率，这个上面已经提到过了。</p>\n<h5 id=\"4-3-3-3-批量读写\"><a href=\"#4-3-3-3-批量读写\" class=\"headerlink\" title=\"4.3.3.3 批量读写\"></a>4.3.3.3 批量读写</h5><p>Kafka无论是生产者发送消息还是消费者消费消息都是批量操作的，大大提高读写性能。</p>\n<h5 id=\"4-3-3-4-零拷贝\"><a href=\"#4-3-3-4-零拷贝\" class=\"headerlink\" title=\"4.3.3.4 零拷贝\"></a>4.3.3.4 零拷贝</h5><p>首先需要了解两个名词。<br>  第一个是操作系统虚拟内存的内核空间和用户空间。操作系统的虚拟内存分成了两块，一部分是内核空间，一部分是用户空间。这样就可以避免用户进程直接操作内核，保证内核安全。进程在内核空间可以执行任意命令，调用系统的一切资源；在用户空间必须要通过<br>—些系统接口才能向内核发出指令。如果用户要从磁盘读取数据(比如kafka消费消息)，必须先把数据从磁盘拷贝到内核缓冲区，然后在从内核缓冲区到用户缓冲区，最后才能返回给用户。<br><img src=\"https://img-blog.csdnimg.cn/20210419020156610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  第二个是DMA拷贝。没有DMA技术的时候，拷贝数据的事情需要CPU亲自去做, 这个时候它没法干其他的事情，如果传输的数据量大那就有问题了。DMA技术叫做直接内存访问(Direct Memory Access),其实可以理解为CPU给 自己找了一个小弟帮它做数据搬运的事情。在进行I&#x2F;O设备和内存的数据传输的时候， 数据搬运的工作全部交给DMA控制器，解放了 CPU的双手。<br>  理解了这两个东西之后，我们来看下传统的I&#x2F;O模型：<br><img src=\"https://img-blog.csdnimg.cn/20210419020246212.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>  比如kafka要消费消息，比如要先把数据从磁盘拷贝到内核缓冲区，然后拷贝到用户缓冲区，再拷贝到socket缓冲区，再拷贝到网卡设备。这里面发生了 4次用户态和内核态的切换和4次数据拷贝，2次系统函数的调用（read、write）,这个过程是非常耗费时间的。怎么优化呢?<br>  在Linux操作系统里面提供了一个sendfile函数（并不是所有操作系统都支持sendfile），可以实现”零拷贝”。这个时候就不需要经过用户缓冲区了，直接把数据拷贝到网卡（这里画的是支持SG-DMA拷贝的情况）。因为这个只有DMA拷贝，没有CPU拷贝，所以叫做”零拷贝”。零拷贝至少可以提高一倍的性能。<br><img src=\"https://img-blog.csdnimg.cn/20210419020413177.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"5、MQ选型：Kafka对比RabbitMQ-RocketMQ\"><a href=\"#5、MQ选型：Kafka对比RabbitMQ-RocketMQ\" class=\"headerlink\" title=\"5、MQ选型：Kafka对比RabbitMQ&#x2F;RocketMQ\"></a>5、MQ选型：Kafka对比RabbitMQ&#x2F;RocketMQ</h2><h3 id=\"5-1-Kafka特性\"><a href=\"#5-1-Kafka特性\" class=\"headerlink\" title=\"5.1 Kafka特性\"></a>5.1 Kafka特性</h3><ul>\n<li><strong>高吞吐、低延迟：</strong> kakfa最大的特点就是收发消息非常快，kafka每秒可以处理几十万条消息，它的最低延迟只有几毫秒；</li>\n<li><strong>高伸缩性：</strong> 如果可以通过增加分区partition来实现扩容。不同的分区可以在不同的Broker中。通过ZK来管理Broker实现扩展，ZK管理Consumer可以实现负载；</li>\n<li><strong>持久性、可靠性：</strong> Kafka能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失；</li>\n<li><strong>容错性：</strong> 允许集群中的节点失败，某个节点宕机，Kafka集群能够正常工作；</li>\n<li><strong>高并发：</strong> 支持数千个客户端同时读写。</li>\n</ul>\n<h3 id=\"5-2-Kafka对比RabbitMQ\"><a href=\"#5-2-Kafka对比RabbitMQ\" class=\"headerlink\" title=\"5.2 Kafka对比RabbitMQ\"></a>5.2 Kafka对比RabbitMQ</h3><ul>\n<li>产品侧重：kafka:流式消息处理、消息引擎；RabbitMQ:消息代理。</li>\n<li>性能：kafka有更高的吞吐量。RabbitMQ主要是push, kafka只有pull。</li>\n<li>消息顺序：分区里面的消息是有序的，同一个consumer group里面的一个消费者只能消费一个partition,能保证消息的顺序性。</li>\n<li>消息的路由和分发：RabbitMQ更加灵活。</li>\n<li>延迟消息、死信队列：RabbitMQ支持。</li>\n<li>消息的留存：kafka消费完之后消息会留存，RabbitMQ消费完就会删除。Kafka可以设置retention,清理消息。</li>\n</ul>\n<p><strong>优先选择RabbitMQ的情况：</strong></p>\n<ul>\n<li>高级灵活的路由规则；</li>\n<li>消息时序控制（控制消息过期或者消息延迟）；</li>\n<li>高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）;</li>\n<li>更简单的消费者实现。</li>\n</ul>\n<p><strong>优先选择Kafka的情况：</strong></p>\n<ul>\n<li>严格的消息顺序；</li>\n<li>延长消息留存时间，包括过去消息重放的可能；</li>\n<li>传统解决方案无法满足的高伸缩能力。</li>\n</ul>\n<h3 id=\"5-3-MQ选型分析\"><a href=\"#5-3-MQ选型分析\" class=\"headerlink\" title=\"5.3 MQ选型分析\"></a>5.3 MQ选型分析</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417132358379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"6、Kafka参数配置说明\"><a href=\"#6、Kafka参数配置说明\" class=\"headerlink\" title=\"6、Kafka参数配置说明\"></a>6、Kafka参数配置说明</h2><h3 id=\"6-1-Kafka生产者参数配置\"><a href=\"#6-1-Kafka生产者参数配置\" class=\"headerlink\" title=\"6.1 Kafka生产者参数配置\"></a>6.1 Kafka生产者参数配置</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417140452763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"6-2-Kafka服务端参数配置\"><a href=\"#6-2-Kafka服务端参数配置\" class=\"headerlink\" title=\"6.2 Kafka服务端参数配置\"></a>6.2 Kafka服务端参数配置</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417135422252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"6-3-Kafka消费者参数配置\"><a href=\"#6-3-Kafka消费者参数配置\" class=\"headerlink\" title=\"6.3 Kafka消费者参数配置\"></a>6.3 Kafka消费者参数配置</h3><p><img src=\"https://img-blog.csdnimg.cn/20210417135759333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FzbWlsZXkxMA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"6-4-Kafka增加数据可靠性的配置\"><a href=\"#6-4-Kafka增加数据可靠性的配置\" class=\"headerlink\" title=\"6.4 Kafka增加数据可靠性的配置\"></a>6.4 Kafka增加数据可靠性的配置</h3><ol>\n<li>设置acks &#x3D; all。acks是Producer的一个参数，代表已提交消息的定义。如果设置成all,则表明所有Broker都要接收到消息，该消息才算是”已提交”。</li>\n<li>设置retries为一个较大的值。同样是Producer的参数。当出现网络抖动时，消息发送可能会失败，此时配置了retries的Producer能够自动重试发送消息，尽量避免消息丢失。</li>\n<li>设置 unclean.leader.election.enable&#x3D;false。</li>\n<li>设置replication.factor &gt;&#x3D; 3。需要三个以上的副本。</li>\n<li>设置min.insync.replicas &gt; 1。Broker端参数，控制消息至少要被写入到多少个副本才算是”已提交”。设置成大于1可以提升消息持久性。在生产环境中不要使用默认值1。确保replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有 —个副本离线整个分区就无法正常工作了。推荐设置成replication.factor &#x3D; min.insync.replicas + 1。</li>\n<li>确保消息消费完成再提交。Consumer端有个参数enable.auto.commit,最好设置成false,并自己来处理offset的提交更新。</li>\n</ol>\n"},{"title":"请保持良好的睡眠","_content":"# 一、最佳睡眠方式\n\n- 睡眠三原则：\n    - 睡得好：晚上醒来的次数不超过一次，没有光或声音的干扰。\n    - 睡得长：从入睡到醒来能保证 7.5 小时的睡眠。\n    - 睡得稳：每天基本都能在同样的时间入睡和醒来。\n- 睡眠时长\n    - 对于成年人而言，**最普适的睡眠时长是 7.5 小时**，在这个基础上可以有正负 1.5 小时的偏差。\n    - 睡眠时间在 6-9 个小时的范围内，都是合适的，但最好还是 7.5 小时。\n\n# 二、失眠的分类\n\n## 1. 焦虑性失眠\n\n*Reason*\n\n晚上大脑对外界环境的信息接收通道被关闭，大脑就会倾向于从内部去获取信息。那些在白天容易被理智抑制的烦恼，到了晚上就更容易挣脱理性的束缚，对我们施加影响。\n\nSuggestion\n\n在睡前看一点轻松有趣的影视剧节目，**内容最好是跟外部世界相关的，不要跟自己联系上，不要让你想到自己。**\n\nCBTI 疗法\n\n1. 把脑海中的念头写下来，问自己：我担心的问题是什么？它会造成什么样的后果？\n2. 评估概率：按照你过往的经验和客观的看法，这些事情发生的概率有多高？\n3. 其他分支：除了这些你担心的后果，这些事情还有什么其他的可能性？\n4. 考虑反例：在你过往的经验中，有多少事情是你担心会发生、但最后完全没有发生的？有多少事情是你担心很严重、但到头来很简单就解决掉了？\n5. 列出帮助：万一你担心的事情真的发生了，你可以从哪些人、哪些途径获得帮助？\n\nAim\n\n使用 CBTI 疗法是为了让自己意识到，这些问题并没有我们想象的那么严重，我是完全有能力去克服和解决它们的，进而构建一个**安全感**的环境。\n\n## 2. 报复性熬夜\n\n```ad-definition\ntitle: 熬夜的定义\n只有当你入睡的时间晚于正常的睡眠时间，才算是熬夜，只要你的睡眠是规律的、足够的，那么你几点睡、几点醒，没有太大关系。\n```\n\n报复性熬夜\n\n明明知道该睡觉了，但就是不愿意上床，或者上床了，还是拿着手机不放手，不知不觉，就又拖了半个小时、一个小时、两个小时......\n\nTodo\n\n给自己设计一套日常仪式，通过这套仪式，潜移默化地告诉自己：这一天结束了，我完成了这一天的任务，现在让我们开启新的一天吧。\n\n```ad-case\n- 喝一杯牛奶，做一做简单的拉伸动作；\n- 试着做一下正念冥想；\n- 打扫房间，整理书桌、柜子，把东西摆回原位；\n- 整理和准备第二天要用的物品；\n- 列一下近期想做的事情，维护一份简单的计划表；\n```\n\n# 三、睡前注意事项\n\nPrinciple\n\n如果能很快睡着，那么最好的情况是固定时间入睡；如果不能，那么就等到困了再去睡。\n\nHint\n\n如果在床上很清醒，可以**立刻起来，去做一些别的事情，等自己困了再回去睡觉。**\n\nExample\n\n可以读读书，写写随笔，整理文件，做一些可以让自己放松，同时需要投入一定精力和脑力的事情，这样可以更快地让自己产生困意。\n\nDanger\n\n尽量避免玩游戏、读小说、做运动等会让自己越发兴奋的事情，这样很容易拖着拖着就通宵了。\n\n# 四、失眠的后果\n\nInfo\n\n**偶尔几天没睡好、睡得浅，或者时间紊乱，不会造成什么后果**。\n\nAttention\n\n**你越担心自己失眠，就越容易真的失眠。**\n\nDone\n\n在睡眠保持放松、愉快的心情。可以听一些舒缓的音乐，读一些舒缓的文字，减少对大脑的刺激，让大脑从工作岗位上撤下来，去休息。\n\n以下情况需要警惕\n\n- 连续好几个月以上睡眠时间低于 6 小时；\n- 连续一段时间（好几周），每天都感到疲惫、困倦、没有精神；\n- 连续一段时间里，每天晚上总是会醒来好几次，醒来之后要很久才能再次入睡；\n\n# 五、[无效的补觉](https://publish.obsidian.md/chinesehelp/%E8%A1%A5%E8%A7%89)\n\n1. 补觉什么都补不回来\n\n    1. 研究表明：让志愿者在10天内每天减少30%睡眠时间，再让他们之后7天想怎么睡怎么睡\n\n    2. 结果就是参与者在大多数功能指标上，仍未恢复到减少睡眠前的表现\n\n2. 补觉的好处\n\n    1. 《Scientifc Reports》论文研究过睡觉时间越短的学生，跟随节拍器规律行走的表现越差，\n\n    2. 如果在测试前补个觉，他们的表现会更好一些，基本能达到正常水平\n\n3. 补觉的坏处\n\n    1. 变得更胖\n\n        1. 《current biology》把志愿者分成3组，A组正常睡觉；B组连续9天只允许睡5个小时；C组持续5天只睡不到5小时，周末2天想睡多久睡多久\n\n        2. 结果发现熬夜组和补觉组在晚上都吃得更多\n\n        3. 熬夜造成胰岛素敏感性下降，身体对胰岛素利用能力减弱，更容易长胖\n\n    2. 造成慢性失眠\n\n        1. 无规律的睡眠没办法弥补熬夜的损害，反而打乱了\"生物钟\"，让你的睡眠习惯紊乱\n\n        2. 长期熬夜后再集中补觉还可能出现慢性失眠\n\n        3. 每周三天以上，并至少持续三个月入睡困难，就被称为慢性失眠。患者就算10点睡觉，到凌晨2一3点依然难以入睡，甚至一夜都睡不着\n\n    3. 越睡越困，并引发其他疾病\n\n        1. 当人在睡觉的时候，血液循环会变慢，这样血细胞对氧气和养分的输送也减少，大脑就得不到充足的营养，久而久之，你的大脑就会缺氧，整个人昏昏沉沉的，然后四肢也逐渐得不到足够的氧气，整个身体的活跃性就会下降\n\n        2. 如果睡得过多，身体排出大量水分，会导致血液变得黏稠，容易诱发心血管疾病\n\n4. 建议\n\n    1. 如果已经习惯晚睡晚起继续保持习惯，睡觉最好能保证每天都是同一个时间，这样对身体比较好\n\n    2. 自己觉得睡够了，实际上你的身体并没有得到恢复。\n\n    3. 睡得多了，睡眠质量反而更差。\n\n","source":"_posts/sleep.md","raw":"---\ntitle: 请保持良好的睡眠\n---\n# 一、最佳睡眠方式\n\n- 睡眠三原则：\n    - 睡得好：晚上醒来的次数不超过一次，没有光或声音的干扰。\n    - 睡得长：从入睡到醒来能保证 7.5 小时的睡眠。\n    - 睡得稳：每天基本都能在同样的时间入睡和醒来。\n- 睡眠时长\n    - 对于成年人而言，**最普适的睡眠时长是 7.5 小时**，在这个基础上可以有正负 1.5 小时的偏差。\n    - 睡眠时间在 6-9 个小时的范围内，都是合适的，但最好还是 7.5 小时。\n\n# 二、失眠的分类\n\n## 1. 焦虑性失眠\n\n*Reason*\n\n晚上大脑对外界环境的信息接收通道被关闭，大脑就会倾向于从内部去获取信息。那些在白天容易被理智抑制的烦恼，到了晚上就更容易挣脱理性的束缚，对我们施加影响。\n\nSuggestion\n\n在睡前看一点轻松有趣的影视剧节目，**内容最好是跟外部世界相关的，不要跟自己联系上，不要让你想到自己。**\n\nCBTI 疗法\n\n1. 把脑海中的念头写下来，问自己：我担心的问题是什么？它会造成什么样的后果？\n2. 评估概率：按照你过往的经验和客观的看法，这些事情发生的概率有多高？\n3. 其他分支：除了这些你担心的后果，这些事情还有什么其他的可能性？\n4. 考虑反例：在你过往的经验中，有多少事情是你担心会发生、但最后完全没有发生的？有多少事情是你担心很严重、但到头来很简单就解决掉了？\n5. 列出帮助：万一你担心的事情真的发生了，你可以从哪些人、哪些途径获得帮助？\n\nAim\n\n使用 CBTI 疗法是为了让自己意识到，这些问题并没有我们想象的那么严重，我是完全有能力去克服和解决它们的，进而构建一个**安全感**的环境。\n\n## 2. 报复性熬夜\n\n```ad-definition\ntitle: 熬夜的定义\n只有当你入睡的时间晚于正常的睡眠时间，才算是熬夜，只要你的睡眠是规律的、足够的，那么你几点睡、几点醒，没有太大关系。\n```\n\n报复性熬夜\n\n明明知道该睡觉了，但就是不愿意上床，或者上床了，还是拿着手机不放手，不知不觉，就又拖了半个小时、一个小时、两个小时......\n\nTodo\n\n给自己设计一套日常仪式，通过这套仪式，潜移默化地告诉自己：这一天结束了，我完成了这一天的任务，现在让我们开启新的一天吧。\n\n```ad-case\n- 喝一杯牛奶，做一做简单的拉伸动作；\n- 试着做一下正念冥想；\n- 打扫房间，整理书桌、柜子，把东西摆回原位；\n- 整理和准备第二天要用的物品；\n- 列一下近期想做的事情，维护一份简单的计划表；\n```\n\n# 三、睡前注意事项\n\nPrinciple\n\n如果能很快睡着，那么最好的情况是固定时间入睡；如果不能，那么就等到困了再去睡。\n\nHint\n\n如果在床上很清醒，可以**立刻起来，去做一些别的事情，等自己困了再回去睡觉。**\n\nExample\n\n可以读读书，写写随笔，整理文件，做一些可以让自己放松，同时需要投入一定精力和脑力的事情，这样可以更快地让自己产生困意。\n\nDanger\n\n尽量避免玩游戏、读小说、做运动等会让自己越发兴奋的事情，这样很容易拖着拖着就通宵了。\n\n# 四、失眠的后果\n\nInfo\n\n**偶尔几天没睡好、睡得浅，或者时间紊乱，不会造成什么后果**。\n\nAttention\n\n**你越担心自己失眠，就越容易真的失眠。**\n\nDone\n\n在睡眠保持放松、愉快的心情。可以听一些舒缓的音乐，读一些舒缓的文字，减少对大脑的刺激，让大脑从工作岗位上撤下来，去休息。\n\n以下情况需要警惕\n\n- 连续好几个月以上睡眠时间低于 6 小时；\n- 连续一段时间（好几周），每天都感到疲惫、困倦、没有精神；\n- 连续一段时间里，每天晚上总是会醒来好几次，醒来之后要很久才能再次入睡；\n\n# 五、[无效的补觉](https://publish.obsidian.md/chinesehelp/%E8%A1%A5%E8%A7%89)\n\n1. 补觉什么都补不回来\n\n    1. 研究表明：让志愿者在10天内每天减少30%睡眠时间，再让他们之后7天想怎么睡怎么睡\n\n    2. 结果就是参与者在大多数功能指标上，仍未恢复到减少睡眠前的表现\n\n2. 补觉的好处\n\n    1. 《Scientifc Reports》论文研究过睡觉时间越短的学生，跟随节拍器规律行走的表现越差，\n\n    2. 如果在测试前补个觉，他们的表现会更好一些，基本能达到正常水平\n\n3. 补觉的坏处\n\n    1. 变得更胖\n\n        1. 《current biology》把志愿者分成3组，A组正常睡觉；B组连续9天只允许睡5个小时；C组持续5天只睡不到5小时，周末2天想睡多久睡多久\n\n        2. 结果发现熬夜组和补觉组在晚上都吃得更多\n\n        3. 熬夜造成胰岛素敏感性下降，身体对胰岛素利用能力减弱，更容易长胖\n\n    2. 造成慢性失眠\n\n        1. 无规律的睡眠没办法弥补熬夜的损害，反而打乱了\"生物钟\"，让你的睡眠习惯紊乱\n\n        2. 长期熬夜后再集中补觉还可能出现慢性失眠\n\n        3. 每周三天以上，并至少持续三个月入睡困难，就被称为慢性失眠。患者就算10点睡觉，到凌晨2一3点依然难以入睡，甚至一夜都睡不着\n\n    3. 越睡越困，并引发其他疾病\n\n        1. 当人在睡觉的时候，血液循环会变慢，这样血细胞对氧气和养分的输送也减少，大脑就得不到充足的营养，久而久之，你的大脑就会缺氧，整个人昏昏沉沉的，然后四肢也逐渐得不到足够的氧气，整个身体的活跃性就会下降\n\n        2. 如果睡得过多，身体排出大量水分，会导致血液变得黏稠，容易诱发心血管疾病\n\n4. 建议\n\n    1. 如果已经习惯晚睡晚起继续保持习惯，睡觉最好能保证每天都是同一个时间，这样对身体比较好\n\n    2. 自己觉得睡够了，实际上你的身体并没有得到恢复。\n\n    3. 睡得多了，睡眠质量反而更差。\n\n","slug":"sleep","published":1,"date":"2024-08-25T09:13:15.503Z","updated":"2024-08-25T09:13:15.504Z","comments":1,"layout":"post","photos":[],"_id":"cm0admg71000454uiez6k0pyp","content":"<h1 id=\"一、最佳睡眠方式\"><a href=\"#一、最佳睡眠方式\" class=\"headerlink\" title=\"一、最佳睡眠方式\"></a>一、最佳睡眠方式</h1><ul>\n<li>睡眠三原则：<ul>\n<li>睡得好：晚上醒来的次数不超过一次，没有光或声音的干扰。</li>\n<li>睡得长：从入睡到醒来能保证 7.5 小时的睡眠。</li>\n<li>睡得稳：每天基本都能在同样的时间入睡和醒来。</li>\n</ul>\n</li>\n<li>睡眠时长<ul>\n<li>对于成年人而言，<strong>最普适的睡眠时长是 7.5 小时</strong>，在这个基础上可以有正负 1.5 小时的偏差。</li>\n<li>睡眠时间在 6-9 个小时的范围内，都是合适的，但最好还是 7.5 小时。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、失眠的分类\"><a href=\"#二、失眠的分类\" class=\"headerlink\" title=\"二、失眠的分类\"></a>二、失眠的分类</h1><h2 id=\"1-焦虑性失眠\"><a href=\"#1-焦虑性失眠\" class=\"headerlink\" title=\"1. 焦虑性失眠\"></a>1. 焦虑性失眠</h2><p><em>Reason</em></p>\n<p>晚上大脑对外界环境的信息接收通道被关闭，大脑就会倾向于从内部去获取信息。那些在白天容易被理智抑制的烦恼，到了晚上就更容易挣脱理性的束缚，对我们施加影响。</p>\n<p>Suggestion</p>\n<p>在睡前看一点轻松有趣的影视剧节目，<strong>内容最好是跟外部世界相关的，不要跟自己联系上，不要让你想到自己。</strong></p>\n<p>CBTI 疗法</p>\n<ol>\n<li>把脑海中的念头写下来，问自己：我担心的问题是什么？它会造成什么样的后果？</li>\n<li>评估概率：按照你过往的经验和客观的看法，这些事情发生的概率有多高？</li>\n<li>其他分支：除了这些你担心的后果，这些事情还有什么其他的可能性？</li>\n<li>考虑反例：在你过往的经验中，有多少事情是你担心会发生、但最后完全没有发生的？有多少事情是你担心很严重、但到头来很简单就解决掉了？</li>\n<li>列出帮助：万一你担心的事情真的发生了，你可以从哪些人、哪些途径获得帮助？</li>\n</ol>\n<p>Aim</p>\n<p>使用 CBTI 疗法是为了让自己意识到，这些问题并没有我们想象的那么严重，我是完全有能力去克服和解决它们的，进而构建一个<strong>安全感</strong>的环境。</p>\n<h2 id=\"2-报复性熬夜\"><a href=\"#2-报复性熬夜\" class=\"headerlink\" title=\"2. 报复性熬夜\"></a>2. 报复性熬夜</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ad-definition\">title: 熬夜的定义<br>只有当你入睡的时间晚于正常的睡眠时间，才算是熬夜，只要你的睡眠是规律的、足够的，那么你几点睡、几点醒，没有太大关系。<br></code></pre></td></tr></table></figure>\n\n<p>报复性熬夜</p>\n<p>明明知道该睡觉了，但就是不愿意上床，或者上床了，还是拿着手机不放手，不知不觉，就又拖了半个小时、一个小时、两个小时……</p>\n<p>Todo</p>\n<p>给自己设计一套日常仪式，通过这套仪式，潜移默化地告诉自己：这一天结束了，我完成了这一天的任务，现在让我们开启新的一天吧。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ad-case\">- 喝一杯牛奶，做一做简单的拉伸动作；<br>- 试着做一下正念冥想；<br>- 打扫房间，整理书桌、柜子，把东西摆回原位；<br>- 整理和准备第二天要用的物品；<br>- 列一下近期想做的事情，维护一份简单的计划表；<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、睡前注意事项\"><a href=\"#三、睡前注意事项\" class=\"headerlink\" title=\"三、睡前注意事项\"></a>三、睡前注意事项</h1><p>Principle</p>\n<p>如果能很快睡着，那么最好的情况是固定时间入睡；如果不能，那么就等到困了再去睡。</p>\n<p>Hint</p>\n<p>如果在床上很清醒，可以<strong>立刻起来，去做一些别的事情，等自己困了再回去睡觉。</strong></p>\n<p>Example</p>\n<p>可以读读书，写写随笔，整理文件，做一些可以让自己放松，同时需要投入一定精力和脑力的事情，这样可以更快地让自己产生困意。</p>\n<p>Danger</p>\n<p>尽量避免玩游戏、读小说、做运动等会让自己越发兴奋的事情，这样很容易拖着拖着就通宵了。</p>\n<h1 id=\"四、失眠的后果\"><a href=\"#四、失眠的后果\" class=\"headerlink\" title=\"四、失眠的后果\"></a>四、失眠的后果</h1><p>Info</p>\n<p><strong>偶尔几天没睡好、睡得浅，或者时间紊乱，不会造成什么后果</strong>。</p>\n<p>Attention</p>\n<p><strong>你越担心自己失眠，就越容易真的失眠。</strong></p>\n<p>Done</p>\n<p>在睡眠保持放松、愉快的心情。可以听一些舒缓的音乐，读一些舒缓的文字，减少对大脑的刺激，让大脑从工作岗位上撤下来，去休息。</p>\n<p>以下情况需要警惕</p>\n<ul>\n<li>连续好几个月以上睡眠时间低于 6 小时；</li>\n<li>连续一段时间（好几周），每天都感到疲惫、困倦、没有精神；</li>\n<li>连续一段时间里，每天晚上总是会醒来好几次，醒来之后要很久才能再次入睡；</li>\n</ul>\n<h1 id=\"五、无效的补觉\"><a href=\"#五、无效的补觉\" class=\"headerlink\" title=\"五、无效的补觉\"></a>五、<a href=\"https://publish.obsidian.md/chinesehelp/%E8%A1%A5%E8%A7%89\">无效的补觉</a></h1><ol>\n<li><p>补觉什么都补不回来</p>\n<ol>\n<li><p>研究表明：让志愿者在10天内每天减少30%睡眠时间，再让他们之后7天想怎么睡怎么睡</p>\n</li>\n<li><p>结果就是参与者在大多数功能指标上，仍未恢复到减少睡眠前的表现</p>\n</li>\n</ol>\n</li>\n<li><p>补觉的好处</p>\n<ol>\n<li><p>《Scientifc Reports》论文研究过睡觉时间越短的学生，跟随节拍器规律行走的表现越差，</p>\n</li>\n<li><p>如果在测试前补个觉，他们的表现会更好一些，基本能达到正常水平</p>\n</li>\n</ol>\n</li>\n<li><p>补觉的坏处</p>\n<ol>\n<li><p>变得更胖</p>\n<ol>\n<li><p>《current biology》把志愿者分成3组，A组正常睡觉；B组连续9天只允许睡5个小时；C组持续5天只睡不到5小时，周末2天想睡多久睡多久</p>\n</li>\n<li><p>结果发现熬夜组和补觉组在晚上都吃得更多</p>\n</li>\n<li><p>熬夜造成胰岛素敏感性下降，身体对胰岛素利用能力减弱，更容易长胖</p>\n</li>\n</ol>\n</li>\n<li><p>造成慢性失眠</p>\n<ol>\n<li><p>无规律的睡眠没办法弥补熬夜的损害，反而打乱了”生物钟”，让你的睡眠习惯紊乱</p>\n</li>\n<li><p>长期熬夜后再集中补觉还可能出现慢性失眠</p>\n</li>\n<li><p>每周三天以上，并至少持续三个月入睡困难，就被称为慢性失眠。患者就算10点睡觉，到凌晨2一3点依然难以入睡，甚至一夜都睡不着</p>\n</li>\n</ol>\n</li>\n<li><p>越睡越困，并引发其他疾病</p>\n<ol>\n<li><p>当人在睡觉的时候，血液循环会变慢，这样血细胞对氧气和养分的输送也减少，大脑就得不到充足的营养，久而久之，你的大脑就会缺氧，整个人昏昏沉沉的，然后四肢也逐渐得不到足够的氧气，整个身体的活跃性就会下降</p>\n</li>\n<li><p>如果睡得过多，身体排出大量水分，会导致血液变得黏稠，容易诱发心血管疾病</p>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>建议</p>\n<ol>\n<li><p>如果已经习惯晚睡晚起继续保持习惯，睡觉最好能保证每天都是同一个时间，这样对身体比较好</p>\n</li>\n<li><p>自己觉得睡够了，实际上你的身体并没有得到恢复。</p>\n</li>\n<li><p>睡得多了，睡眠质量反而更差。</p>\n</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"一、最佳睡眠方式\"><a href=\"#一、最佳睡眠方式\" class=\"headerlink\" title=\"一、最佳睡眠方式\"></a>一、最佳睡眠方式</h1><ul>\n<li>睡眠三原则：<ul>\n<li>睡得好：晚上醒来的次数不超过一次，没有光或声音的干扰。</li>\n<li>睡得长：从入睡到醒来能保证 7.5 小时的睡眠。</li>\n<li>睡得稳：每天基本都能在同样的时间入睡和醒来。</li>\n</ul>\n</li>\n<li>睡眠时长<ul>\n<li>对于成年人而言，<strong>最普适的睡眠时长是 7.5 小时</strong>，在这个基础上可以有正负 1.5 小时的偏差。</li>\n<li>睡眠时间在 6-9 个小时的范围内，都是合适的，但最好还是 7.5 小时。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、失眠的分类\"><a href=\"#二、失眠的分类\" class=\"headerlink\" title=\"二、失眠的分类\"></a>二、失眠的分类</h1><h2 id=\"1-焦虑性失眠\"><a href=\"#1-焦虑性失眠\" class=\"headerlink\" title=\"1. 焦虑性失眠\"></a>1. 焦虑性失眠</h2><p><em>Reason</em></p>\n<p>晚上大脑对外界环境的信息接收通道被关闭，大脑就会倾向于从内部去获取信息。那些在白天容易被理智抑制的烦恼，到了晚上就更容易挣脱理性的束缚，对我们施加影响。</p>\n<p>Suggestion</p>\n<p>在睡前看一点轻松有趣的影视剧节目，<strong>内容最好是跟外部世界相关的，不要跟自己联系上，不要让你想到自己。</strong></p>\n<p>CBTI 疗法</p>\n<ol>\n<li>把脑海中的念头写下来，问自己：我担心的问题是什么？它会造成什么样的后果？</li>\n<li>评估概率：按照你过往的经验和客观的看法，这些事情发生的概率有多高？</li>\n<li>其他分支：除了这些你担心的后果，这些事情还有什么其他的可能性？</li>\n<li>考虑反例：在你过往的经验中，有多少事情是你担心会发生、但最后完全没有发生的？有多少事情是你担心很严重、但到头来很简单就解决掉了？</li>\n<li>列出帮助：万一你担心的事情真的发生了，你可以从哪些人、哪些途径获得帮助？</li>\n</ol>\n<p>Aim</p>\n<p>使用 CBTI 疗法是为了让自己意识到，这些问题并没有我们想象的那么严重，我是完全有能力去克服和解决它们的，进而构建一个<strong>安全感</strong>的环境。</p>\n<h2 id=\"2-报复性熬夜\"><a href=\"#2-报复性熬夜\" class=\"headerlink\" title=\"2. 报复性熬夜\"></a>2. 报复性熬夜</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ad-definition\">title: 熬夜的定义<br>只有当你入睡的时间晚于正常的睡眠时间，才算是熬夜，只要你的睡眠是规律的、足够的，那么你几点睡、几点醒，没有太大关系。<br></code></pre></td></tr></table></figure>\n\n<p>报复性熬夜</p>\n<p>明明知道该睡觉了，但就是不愿意上床，或者上床了，还是拿着手机不放手，不知不觉，就又拖了半个小时、一个小时、两个小时……</p>\n<p>Todo</p>\n<p>给自己设计一套日常仪式，通过这套仪式，潜移默化地告诉自己：这一天结束了，我完成了这一天的任务，现在让我们开启新的一天吧。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ad-case\">- 喝一杯牛奶，做一做简单的拉伸动作；<br>- 试着做一下正念冥想；<br>- 打扫房间，整理书桌、柜子，把东西摆回原位；<br>- 整理和准备第二天要用的物品；<br>- 列一下近期想做的事情，维护一份简单的计划表；<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"三、睡前注意事项\"><a href=\"#三、睡前注意事项\" class=\"headerlink\" title=\"三、睡前注意事项\"></a>三、睡前注意事项</h1><p>Principle</p>\n<p>如果能很快睡着，那么最好的情况是固定时间入睡；如果不能，那么就等到困了再去睡。</p>\n<p>Hint</p>\n<p>如果在床上很清醒，可以<strong>立刻起来，去做一些别的事情，等自己困了再回去睡觉。</strong></p>\n<p>Example</p>\n<p>可以读读书，写写随笔，整理文件，做一些可以让自己放松，同时需要投入一定精力和脑力的事情，这样可以更快地让自己产生困意。</p>\n<p>Danger</p>\n<p>尽量避免玩游戏、读小说、做运动等会让自己越发兴奋的事情，这样很容易拖着拖着就通宵了。</p>\n<h1 id=\"四、失眠的后果\"><a href=\"#四、失眠的后果\" class=\"headerlink\" title=\"四、失眠的后果\"></a>四、失眠的后果</h1><p>Info</p>\n<p><strong>偶尔几天没睡好、睡得浅，或者时间紊乱，不会造成什么后果</strong>。</p>\n<p>Attention</p>\n<p><strong>你越担心自己失眠，就越容易真的失眠。</strong></p>\n<p>Done</p>\n<p>在睡眠保持放松、愉快的心情。可以听一些舒缓的音乐，读一些舒缓的文字，减少对大脑的刺激，让大脑从工作岗位上撤下来，去休息。</p>\n<p>以下情况需要警惕</p>\n<ul>\n<li>连续好几个月以上睡眠时间低于 6 小时；</li>\n<li>连续一段时间（好几周），每天都感到疲惫、困倦、没有精神；</li>\n<li>连续一段时间里，每天晚上总是会醒来好几次，醒来之后要很久才能再次入睡；</li>\n</ul>\n<h1 id=\"五、无效的补觉\"><a href=\"#五、无效的补觉\" class=\"headerlink\" title=\"五、无效的补觉\"></a>五、<a href=\"https://publish.obsidian.md/chinesehelp/%E8%A1%A5%E8%A7%89\">无效的补觉</a></h1><ol>\n<li><p>补觉什么都补不回来</p>\n<ol>\n<li><p>研究表明：让志愿者在10天内每天减少30%睡眠时间，再让他们之后7天想怎么睡怎么睡</p>\n</li>\n<li><p>结果就是参与者在大多数功能指标上，仍未恢复到减少睡眠前的表现</p>\n</li>\n</ol>\n</li>\n<li><p>补觉的好处</p>\n<ol>\n<li><p>《Scientifc Reports》论文研究过睡觉时间越短的学生，跟随节拍器规律行走的表现越差，</p>\n</li>\n<li><p>如果在测试前补个觉，他们的表现会更好一些，基本能达到正常水平</p>\n</li>\n</ol>\n</li>\n<li><p>补觉的坏处</p>\n<ol>\n<li><p>变得更胖</p>\n<ol>\n<li><p>《current biology》把志愿者分成3组，A组正常睡觉；B组连续9天只允许睡5个小时；C组持续5天只睡不到5小时，周末2天想睡多久睡多久</p>\n</li>\n<li><p>结果发现熬夜组和补觉组在晚上都吃得更多</p>\n</li>\n<li><p>熬夜造成胰岛素敏感性下降，身体对胰岛素利用能力减弱，更容易长胖</p>\n</li>\n</ol>\n</li>\n<li><p>造成慢性失眠</p>\n<ol>\n<li><p>无规律的睡眠没办法弥补熬夜的损害，反而打乱了”生物钟”，让你的睡眠习惯紊乱</p>\n</li>\n<li><p>长期熬夜后再集中补觉还可能出现慢性失眠</p>\n</li>\n<li><p>每周三天以上，并至少持续三个月入睡困难，就被称为慢性失眠。患者就算10点睡觉，到凌晨2一3点依然难以入睡，甚至一夜都睡不着</p>\n</li>\n</ol>\n</li>\n<li><p>越睡越困，并引发其他疾病</p>\n<ol>\n<li><p>当人在睡觉的时候，血液循环会变慢，这样血细胞对氧气和养分的输送也减少，大脑就得不到充足的营养，久而久之，你的大脑就会缺氧，整个人昏昏沉沉的，然后四肢也逐渐得不到足够的氧气，整个身体的活跃性就会下降</p>\n</li>\n<li><p>如果睡得过多，身体排出大量水分，会导致血液变得黏稠，容易诱发心血管疾病</p>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>建议</p>\n<ol>\n<li><p>如果已经习惯晚睡晚起继续保持习惯，睡觉最好能保证每天都是同一个时间，这样对身体比较好</p>\n</li>\n<li><p>自己觉得睡够了，实际上你的身体并没有得到恢复。</p>\n</li>\n<li><p>睡得多了，睡眠质量反而更差。</p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":"黑曜石左拉","_content":"# 黑曜石左拉\n\n[![](https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61)](https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61) [![](https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61)](https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61) [![](https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441)](https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441)\n\nObsidian Publish 的免费（但更好？）替代品。\n\n> 该存储库包含一个易于使用（阅读：简单）的解决方案，用于将 Obsidian 个人知识管理系统（阅读：一堆随机 Markdown）转换为 Zola 站点。\n\n致谢：这个仓库是从[Adidoks](https://github.com/aaranxu/adidoks)分叉的。\n\n特别感谢：Wikilink 解析由[obsidian-export](https://github.com/zoni/obsidian-export)提供支持。\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#announcements)公告\n\n**v1.3.0 满足功能要求！✨**\n\nBug修复：\n\n- 修复了一些与非常规文件名相关的错误（例如包含“.”和其他特殊字符）\n\n改进：\n\n- 更好的本地测试设置（见`Local Testing`下文）\n- 可配置的根部分名称\n- 可配置的页脚内容\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#setup)设置\n\n**第 1 步：设置 Netlify**\n\n- 将您的 Obsidian 保管库文件夹转变为 Git 存储库\n- 创建一个指向该 Git 存储库的 Netlify 站点\n\n**第 2 步：编辑`netlify.toml`**\n\n- `netlify.toml`在您的黑曜石保管库文件夹中创建\n- 复制此存储库中的内容`netlify.example.toml`并替换适当的设置（`SITE_URL`，`REPO_URL`并且`LANDING_PAGE`不能留空）。\n\n**第三步：你就完成了🎉！**\n\n- 推动你的改变，准备好成名！\n- 花哨一点：（`netlify.toml`例如`LANDING_TITLE`）中的所有文本字段设置都支持 HTML 语法。我还为那些想要添加个人风格的人添加了`Animate.css`++ ~`Hover.css``CSShake`\n\n**第 4 步：问题和功能请求**\n\n- 如果您遇到任何问题，请先参考[Config+FAQ](https://github.com/ppeetteerrs/obsidian-zola/blob/main/CONFIG.md)。如果仍未解决，只需在`Issues`选项卡中发布即可。如果问题与部署相关，最好包含在 Netlify 面板中找到的错误日志的副本。\n- 如果您有任何功能请求，也请发布问题。但是，请注意，此存储库旨在作为一个文件设置。除非大多数用户需要，否则不会支持高级功能/详细的可配置性。不过，我可以帮助您实现适合您需求的分叉🥂。\n\n**第 5 步：（可选增强功能）自动提交站点地图**\n\n为了使您的网站对搜索引擎更加友好，您可以添加一个 netlify 插件，以便在每次重新部署网站时自动提交新的站点地图。只需将以下内容添加到您的`netlify.toml`. 请记住替换`baseUrl`为您的`SITE_URL`.\n\n```toml\n[[plugins]]\npackage = \"netlify-plugin-submit-sitemap\"\n\n[plugins.inputs]\n\n# The base url of your site (optional, default = main URL set in Netlify)\nbaseUrl = \"https://peteryuen.netlify.app/\"\n\n# Path to the sitemap URL (optional, default = /sitemap.xml)\nsitemapPath = \"/sitemap.xml\"\n\n# Time in seconds to not submit the sitemap after successful submission\nignorePeriod = 0\n\n# Enabled providers to submit sitemap to (optional, default = 'google', 'bing', 'yandex'). Possible providers are currently only 'google', 'bing', 'yandex'.\nproviders = [\n  \"google\",\n  \"bing\",\n  \"yandex\",\n]\n```\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#example-site)示例站点\n\n> 不要`netlify.toml`从示例站点复制，它不稳定。请参考来自`netlify.example.toml`.\n\n该[示例站点](https://peteryuen.netlify.app/)展示了 的功能`obsidian-zola`。请注意，示例站点使用 的`dev`分支`obsidian-zola`。如果您看到示例站点中可用但主分支中尚不可用的功能，请考虑尝试`dev`（不稳定）分支。具体方法可以参考[示例仓库](https://github.com/ppeetteerrs/obsidian-pkm) `netlify.toml`的.\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#local-testing-ubuntu-thanks-trwbox)本地测试（Ubuntu）[感谢@trwbox]\n\n- 根据网站上的说明安装 zola`https://www.getzola.org/documentation/getting-started/installation/`\n- 运行以下命令来安装其他所需的依赖项`sudo apt install python-is-python3 python3-pip`和`pip3 install python-slugify rtoml`（或使用`conda`/ `mamba`）\n- 用于`git clone https://github.com/ppeetteerrs/obsidian-zola`将存储库克隆到黑曜石保管库文件夹内以外的其他位置\n- `.vault_path`使用文件或`$VAULT`环境变量设置 ObsisianVault 的路径\n- 用于`./local-run.sh`运行网站\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#features)特征\n\n**免责声明**\n\n> 该工具专为使用 Obsidian 作为简单高效的笔记应用程序（或 PKM）的用户而设计。如果您为 Obsidian 配置了大​​量奇特的短代码、插件和特定于 Obsidian 的语法，则该工具不会（也无意）支持这些功能。\n\n**支持的**\n\n- 知识图谱（也可以将其视为反向链接）\n- LaTEX（由 提供支持`KaTEX`，再见 MathJAX 粉丝👋）\n- 部分字符串搜索（由 提供支持`elasticlunr`）\n- 语法高亮 + Fira 代码！\n- 可定制的动画\n- 导航\n- 表中的内容\n- 典型的 Markdown 语法\n- 删除线\n- 表格\n- 单行脚注（即`[^1]`在段落中及`[^1]: xxx`后面）\n- 复选框\n- 链接转义模式：`[Slides Demo](<Slides Demo>)`\n\n**不支持**\n\n- 非图像/注释嵌入（例如视频、音频、PDF）。它们将变成链接。\n- 调整图像大小\n- 突出显示文本\n- 评论\n- 内联/多行脚注\n- 美人鱼图\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#gotchas)陷阱\n\n1. 没有带有名称`index.md`或名称的文件`_index.md`\n2. ~~不存在与其子文件夹同名的文件（例如同时存在`.../category1.md`且`.../category1/xxx.md`不允许）~~（固定的）\n3. `LANDING_PAGE``SLUGIFY`如果打开，则需要设置为 slugified 文件名（例如，要使用`I am Home.md`，`LANDING_PAGE`需要`i-am-home`）\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#wips--ideas)WIP/想法\n\n- （可能会做）反向链接/提及\n- （也许）洛蒂动画？\n- （不知道）可配置的折叠图标","source":"_posts/obsidian-zola.md","raw":"---\ntitle: 黑曜石左拉\n---\n# 黑曜石左拉\n\n[![](https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61)](https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61) [![](https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61)](https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61) [![](https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441)](https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441)\n\nObsidian Publish 的免费（但更好？）替代品。\n\n> 该存储库包含一个易于使用（阅读：简单）的解决方案，用于将 Obsidian 个人知识管理系统（阅读：一堆随机 Markdown）转换为 Zola 站点。\n\n致谢：这个仓库是从[Adidoks](https://github.com/aaranxu/adidoks)分叉的。\n\n特别感谢：Wikilink 解析由[obsidian-export](https://github.com/zoni/obsidian-export)提供支持。\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#announcements)公告\n\n**v1.3.0 满足功能要求！✨**\n\nBug修复：\n\n- 修复了一些与非常规文件名相关的错误（例如包含“.”和其他特殊字符）\n\n改进：\n\n- 更好的本地测试设置（见`Local Testing`下文）\n- 可配置的根部分名称\n- 可配置的页脚内容\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#setup)设置\n\n**第 1 步：设置 Netlify**\n\n- 将您的 Obsidian 保管库文件夹转变为 Git 存储库\n- 创建一个指向该 Git 存储库的 Netlify 站点\n\n**第 2 步：编辑`netlify.toml`**\n\n- `netlify.toml`在您的黑曜石保管库文件夹中创建\n- 复制此存储库中的内容`netlify.example.toml`并替换适当的设置（`SITE_URL`，`REPO_URL`并且`LANDING_PAGE`不能留空）。\n\n**第三步：你就完成了🎉！**\n\n- 推动你的改变，准备好成名！\n- 花哨一点：（`netlify.toml`例如`LANDING_TITLE`）中的所有文本字段设置都支持 HTML 语法。我还为那些想要添加个人风格的人添加了`Animate.css`++ ~`Hover.css``CSShake`\n\n**第 4 步：问题和功能请求**\n\n- 如果您遇到任何问题，请先参考[Config+FAQ](https://github.com/ppeetteerrs/obsidian-zola/blob/main/CONFIG.md)。如果仍未解决，只需在`Issues`选项卡中发布即可。如果问题与部署相关，最好包含在 Netlify 面板中找到的错误日志的副本。\n- 如果您有任何功能请求，也请发布问题。但是，请注意，此存储库旨在作为一个文件设置。除非大多数用户需要，否则不会支持高级功能/详细的可配置性。不过，我可以帮助您实现适合您需求的分叉🥂。\n\n**第 5 步：（可选增强功能）自动提交站点地图**\n\n为了使您的网站对搜索引擎更加友好，您可以添加一个 netlify 插件，以便在每次重新部署网站时自动提交新的站点地图。只需将以下内容添加到您的`netlify.toml`. 请记住替换`baseUrl`为您的`SITE_URL`.\n\n```toml\n[[plugins]]\npackage = \"netlify-plugin-submit-sitemap\"\n\n[plugins.inputs]\n\n# The base url of your site (optional, default = main URL set in Netlify)\nbaseUrl = \"https://peteryuen.netlify.app/\"\n\n# Path to the sitemap URL (optional, default = /sitemap.xml)\nsitemapPath = \"/sitemap.xml\"\n\n# Time in seconds to not submit the sitemap after successful submission\nignorePeriod = 0\n\n# Enabled providers to submit sitemap to (optional, default = 'google', 'bing', 'yandex'). Possible providers are currently only 'google', 'bing', 'yandex'.\nproviders = [\n  \"google\",\n  \"bing\",\n  \"yandex\",\n]\n```\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#example-site)示例站点\n\n> 不要`netlify.toml`从示例站点复制，它不稳定。请参考来自`netlify.example.toml`.\n\n该[示例站点](https://peteryuen.netlify.app/)展示了 的功能`obsidian-zola`。请注意，示例站点使用 的`dev`分支`obsidian-zola`。如果您看到示例站点中可用但主分支中尚不可用的功能，请考虑尝试`dev`（不稳定）分支。具体方法可以参考[示例仓库](https://github.com/ppeetteerrs/obsidian-pkm) `netlify.toml`的.\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#local-testing-ubuntu-thanks-trwbox)本地测试（Ubuntu）[感谢@trwbox]\n\n- 根据网站上的说明安装 zola`https://www.getzola.org/documentation/getting-started/installation/`\n- 运行以下命令来安装其他所需的依赖项`sudo apt install python-is-python3 python3-pip`和`pip3 install python-slugify rtoml`（或使用`conda`/ `mamba`）\n- 用于`git clone https://github.com/ppeetteerrs/obsidian-zola`将存储库克隆到黑曜石保管库文件夹内以外的其他位置\n- `.vault_path`使用文件或`$VAULT`环境变量设置 ObsisianVault 的路径\n- 用于`./local-run.sh`运行网站\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#features)特征\n\n**免责声明**\n\n> 该工具专为使用 Obsidian 作为简单高效的笔记应用程序（或 PKM）的用户而设计。如果您为 Obsidian 配置了大​​量奇特的短代码、插件和特定于 Obsidian 的语法，则该工具不会（也无意）支持这些功能。\n\n**支持的**\n\n- 知识图谱（也可以将其视为反向链接）\n- LaTEX（由 提供支持`KaTEX`，再见 MathJAX 粉丝👋）\n- 部分字符串搜索（由 提供支持`elasticlunr`）\n- 语法高亮 + Fira 代码！\n- 可定制的动画\n- 导航\n- 表中的内容\n- 典型的 Markdown 语法\n- 删除线\n- 表格\n- 单行脚注（即`[^1]`在段落中及`[^1]: xxx`后面）\n- 复选框\n- 链接转义模式：`[Slides Demo](<Slides Demo>)`\n\n**不支持**\n\n- 非图像/注释嵌入（例如视频、音频、PDF）。它们将变成链接。\n- 调整图像大小\n- 突出显示文本\n- 评论\n- 内联/多行脚注\n- 美人鱼图\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#gotchas)陷阱\n\n1. 没有带有名称`index.md`或名称的文件`_index.md`\n2. ~~不存在与其子文件夹同名的文件（例如同时存在`.../category1.md`且`.../category1/xxx.md`不允许）~~（固定的）\n3. `LANDING_PAGE``SLUGIFY`如果打开，则需要设置为 slugified 文件名（例如，要使用`I am Home.md`，`LANDING_PAGE`需要`i-am-home`）\n\n# [](https://github.com/ppeetteerrs/obsidian-zola#wips--ideas)WIP/想法\n\n- （可能会做）反向链接/提及\n- （也许）洛蒂动画？\n- （不知道）可配置的折叠图标","slug":"obsidian-zola","published":1,"date":"2024-08-25T09:13:16.279Z","updated":"2024-08-25T09:13:16.279Z","comments":1,"layout":"post","photos":[],"_id":"cm0admg72000554uib2jgbnb1","content":"<h1 id=\"黑曜石左拉\"><a href=\"#黑曜石左拉\" class=\"headerlink\" title=\"黑曜石左拉\"></a>黑曜石左拉</h1><p><a href=\"https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61\"><img src=\"https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61\"></a> <a href=\"https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61\"><img src=\"https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61\"></a> <a href=\"https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441\"><img src=\"https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441\"></a></p>\n<p>Obsidian Publish 的免费（但更好？）替代品。</p>\n<blockquote>\n<p>该存储库包含一个易于使用（阅读：简单）的解决方案，用于将 Obsidian 个人知识管理系统（阅读：一堆随机 Markdown）转换为 Zola 站点。</p>\n</blockquote>\n<p>致谢：这个仓库是从<a href=\"https://github.com/aaranxu/adidoks\">Adidoks</a>分叉的。</p>\n<p>特别感谢：Wikilink 解析由<a href=\"https://github.com/zoni/obsidian-export\">obsidian-export</a>提供支持。</p>\n<h1 id=\"公告\"><a href=\"#公告\" class=\"headerlink\" title=\"公告\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#announcements\"></a>公告</h1><p><strong>v1.3.0 满足功能要求！✨</strong></p>\n<p>Bug修复：</p>\n<ul>\n<li>修复了一些与非常规文件名相关的错误（例如包含“.”和其他特殊字符）</li>\n</ul>\n<p>改进：</p>\n<ul>\n<li>更好的本地测试设置（见<code>Local Testing</code>下文）</li>\n<li>可配置的根部分名称</li>\n<li>可配置的页脚内容</li>\n</ul>\n<h1 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#setup\"></a>设置</h1><p><strong>第 1 步：设置 Netlify</strong></p>\n<ul>\n<li>将您的 Obsidian 保管库文件夹转变为 Git 存储库</li>\n<li>创建一个指向该 Git 存储库的 Netlify 站点</li>\n</ul>\n<p><strong>第 2 步：编辑<code>netlify.toml</code></strong></p>\n<ul>\n<li><code>netlify.toml</code>在您的黑曜石保管库文件夹中创建</li>\n<li>复制此存储库中的内容<code>netlify.example.toml</code>并替换适当的设置（<code>SITE_URL</code>，<code>REPO_URL</code>并且<code>LANDING_PAGE</code>不能留空）。</li>\n</ul>\n<p><strong>第三步：你就完成了🎉！</strong></p>\n<ul>\n<li>推动你的改变，准备好成名！</li>\n<li>花哨一点：（<code>netlify.toml</code>例如<code>LANDING_TITLE</code>）中的所有文本字段设置都支持 HTML 语法。我还为那些想要添加个人风格的人添加了<code>Animate.css</code>++ ~&#96;Hover.css&#96;&#96;CSShake&#96;</li>\n</ul>\n<p><strong>第 4 步：问题和功能请求</strong></p>\n<ul>\n<li>如果您遇到任何问题，请先参考<a href=\"https://github.com/ppeetteerrs/obsidian-zola/blob/main/CONFIG.md\">Config+FAQ</a>。如果仍未解决，只需在<code>Issues</code>选项卡中发布即可。如果问题与部署相关，最好包含在 Netlify 面板中找到的错误日志的副本。</li>\n<li>如果您有任何功能请求，也请发布问题。但是，请注意，此存储库旨在作为一个文件设置。除非大多数用户需要，否则不会支持高级功能&#x2F;详细的可配置性。不过，我可以帮助您实现适合您需求的分叉🥂。</li>\n</ul>\n<p><strong>第 5 步：（可选增强功能）自动提交站点地图</strong></p>\n<p>为了使您的网站对搜索引擎更加友好，您可以添加一个 netlify 插件，以便在每次重新部署网站时自动提交新的站点地图。只需将以下内容添加到您的<code>netlify.toml</code>. 请记住替换<code>baseUrl</code>为您的<code>SITE_URL</code>.</p>\n<figure class=\"highlight toml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs toml\"><span class=\"hljs-section\">[[plugins]]</span><br><span class=\"hljs-attr\">package</span> = <span class=\"hljs-string\">&quot;netlify-plugin-submit-sitemap&quot;</span><br><br><span class=\"hljs-section\">[plugins.inputs]</span><br><br><span class=\"hljs-comment\"># The base url of your site (optional, default = main URL set in Netlify)</span><br><span class=\"hljs-attr\">baseUrl</span> = <span class=\"hljs-string\">&quot;https://peteryuen.netlify.app/&quot;</span><br><br><span class=\"hljs-comment\"># Path to the sitemap URL (optional, default = /sitemap.xml)</span><br><span class=\"hljs-attr\">sitemapPath</span> = <span class=\"hljs-string\">&quot;/sitemap.xml&quot;</span><br><br><span class=\"hljs-comment\"># Time in seconds to not submit the sitemap after successful submission</span><br><span class=\"hljs-attr\">ignorePeriod</span> = <span class=\"hljs-number\">0</span><br><br><span class=\"hljs-comment\"># Enabled providers to submit sitemap to (optional, default = &#x27;google&#x27;, &#x27;bing&#x27;, &#x27;yandex&#x27;). Possible providers are currently only &#x27;google&#x27;, &#x27;bing&#x27;, &#x27;yandex&#x27;.</span><br><span class=\"hljs-attr\">providers</span> = [<br>  <span class=\"hljs-string\">&quot;google&quot;</span>,<br>  <span class=\"hljs-string\">&quot;bing&quot;</span>,<br>  <span class=\"hljs-string\">&quot;yandex&quot;</span>,<br>]<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"示例站点\"><a href=\"#示例站点\" class=\"headerlink\" title=\"示例站点\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#example-site\"></a>示例站点</h1><blockquote>\n<p>不要<code>netlify.toml</code>从示例站点复制，它不稳定。请参考来自<code>netlify.example.toml</code>.</p>\n</blockquote>\n<p>该<a href=\"https://peteryuen.netlify.app/\">示例站点</a>展示了 的功能<code>obsidian-zola</code>。请注意，示例站点使用 的<code>dev</code>分支<code>obsidian-zola</code>。如果您看到示例站点中可用但主分支中尚不可用的功能，请考虑尝试<code>dev</code>（不稳定）分支。具体方法可以参考<a href=\"https://github.com/ppeetteerrs/obsidian-pkm\">示例仓库</a> <code>netlify.toml</code>的.</p>\n<h1 id=\"本地测试（Ubuntu）-感谢-trwbox\"><a href=\"#本地测试（Ubuntu）-感谢-trwbox\" class=\"headerlink\" title=\"本地测试（Ubuntu）[感谢@trwbox]\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#local-testing-ubuntu-thanks-trwbox\"></a>本地测试（Ubuntu）[感谢@trwbox]</h1><ul>\n<li>根据网站上的说明安装 zola<code>https://www.getzola.org/documentation/getting-started/installation/</code></li>\n<li>运行以下命令来安装其他所需的依赖项<code>sudo apt install python-is-python3 python3-pip</code>和<code>pip3 install python-slugify rtoml</code>（或使用<code>conda</code>&#x2F; <code>mamba</code>）</li>\n<li>用于<code>git clone https://github.com/ppeetteerrs/obsidian-zola</code>将存储库克隆到黑曜石保管库文件夹内以外的其他位置</li>\n<li><code>.vault_path</code>使用文件或<code>$VAULT</code>环境变量设置 ObsisianVault 的路径</li>\n<li>用于<code>./local-run.sh</code>运行网站</li>\n</ul>\n<h1 id=\"特征\"><a href=\"#特征\" class=\"headerlink\" title=\"特征\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#features\"></a>特征</h1><p><strong>免责声明</strong></p>\n<blockquote>\n<p>该工具专为使用 Obsidian 作为简单高效的笔记应用程序（或 PKM）的用户而设计。如果您为 Obsidian 配置了大​​量奇特的短代码、插件和特定于 Obsidian 的语法，则该工具不会（也无意）支持这些功能。</p>\n</blockquote>\n<p><strong>支持的</strong></p>\n<ul>\n<li>知识图谱（也可以将其视为反向链接）</li>\n<li>LaTEX（由 提供支持<code>KaTEX</code>，再见 MathJAX 粉丝👋）</li>\n<li>部分字符串搜索（由 提供支持<code>elasticlunr</code>）</li>\n<li>语法高亮 + Fira 代码！</li>\n<li>可定制的动画</li>\n<li>导航</li>\n<li>表中的内容</li>\n<li>典型的 Markdown 语法</li>\n<li>删除线</li>\n<li>表格</li>\n<li>单行脚注（即<code>&lt;sup id=&quot;fnref:1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;&lt;span class=&quot;hint--top hint--rounded&quot; aria-label=&quot;xxx</code>后面）</li>\n<li>复选框</li>\n<li>链接转义模式：<code>[Slides Demo]()</code>“&gt;[1]</span></a></sup><code>在段落中及</code></li>\n</ul>\n<p><strong>不支持</strong></p>\n<ul>\n<li>非图像&#x2F;注释嵌入（例如视频、音频、PDF）。它们将变成链接。</li>\n<li>调整图像大小</li>\n<li>突出显示文本</li>\n<li>评论</li>\n<li>内联&#x2F;多行脚注</li>\n<li>美人鱼图</li>\n</ul>\n<h1 id=\"陷阱\"><a href=\"#陷阱\" class=\"headerlink\" title=\"陷阱\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#gotchas\"></a>陷阱</h1><ol>\n<li>没有带有名称<code>index.md</code>或名称的文件<code>_index.md</code></li>\n<li><del>不存在与其子文件夹同名的文件（例如同时存在<code>.../category1.md</code>且<code>.../category1/xxx.md</code>不允许）</del>（固定的）</li>\n<li><code>LANDING_PAGE``SLUGIFY</code>如果打开，则需要设置为 slugified 文件名（例如，要使用<code>I am Home.md</code>，<code>LANDING_PAGE</code>需要<code>i-am-home</code>）</li>\n</ol>\n<h1 id=\"WIP-想法\"><a href=\"#WIP-想法\" class=\"headerlink\" title=\"WIP&#x2F;想法\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#wips--ideas\"></a>WIP&#x2F;想法</h1><ul>\n<li>（可能会做）反向链接&#x2F;提及</li>\n<li>（也许）洛蒂动画？</li>\n<li>（不知道）可配置的折叠图标<section class=\"footnotes\"><div class=\"footnote-list\"><ol><li><span id=\"fn:1\" class=\"footnote-text\"><span>xxx&#96;后面）<ul>\n<li>复选框</li>\n<li>链接转义模式：<code>[Slides Demo](&lt;Slides Demo&gt;)</code></li>\n</ul>\n<a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li></ol></div></section></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"黑曜石左拉\"><a href=\"#黑曜石左拉\" class=\"headerlink\" title=\"黑曜石左拉\"></a>黑曜石左拉</h1><p><a href=\"https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61\"><img src=\"https://camo.githubusercontent.com/1d5ec435f65ca9b3a5d5ab1c25c27349318ca18dc423430b57fd566b7e2555cd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f70706565747465657272732f6f6273696469616e2d7a6f6c61\"></a> <a href=\"https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61\"><img src=\"https://camo.githubusercontent.com/de840d9d223cf010cfaea38d4dbdf0355ceef30bce62e0b42ea59e2119d17523/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642d7261772f70706565747465657272732f6f6273696469616e2d7a6f6c61\"></a> <a href=\"https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441\"><img src=\"https://camo.githubusercontent.com/2ebf393f6cc610f2ae2883a8b3ca39f13d559bcf9e951a67bd21705246e4e8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64796e616d69632f6a736f6e3f636f6c6f723d626c756576696f6c6574266c6162656c3d746f6461792532377325323076696577732671756572793d2532342e6461746173657473253542312535442e76616c7565732535422532382534302e6c656e6774682d312532392535442675726c3d687474707325334125324625324679687970652e6d6525324661706925324663686172742532467265706f7369746f72795f76696577735f636f756e745f63686172745f636f6e74726f6c6c65722533467265706f7369746f72794e6f64654964253344525f6b67444f477048703441\"></a></p>\n<p>Obsidian Publish 的免费（但更好？）替代品。</p>\n<blockquote>\n<p>该存储库包含一个易于使用（阅读：简单）的解决方案，用于将 Obsidian 个人知识管理系统（阅读：一堆随机 Markdown）转换为 Zola 站点。</p>\n</blockquote>\n<p>致谢：这个仓库是从<a href=\"https://github.com/aaranxu/adidoks\">Adidoks</a>分叉的。</p>\n<p>特别感谢：Wikilink 解析由<a href=\"https://github.com/zoni/obsidian-export\">obsidian-export</a>提供支持。</p>\n<h1 id=\"公告\"><a href=\"#公告\" class=\"headerlink\" title=\"公告\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#announcements\"></a>公告</h1><p><strong>v1.3.0 满足功能要求！✨</strong></p>\n<p>Bug修复：</p>\n<ul>\n<li>修复了一些与非常规文件名相关的错误（例如包含“.”和其他特殊字符）</li>\n</ul>\n<p>改进：</p>\n<ul>\n<li>更好的本地测试设置（见<code>Local Testing</code>下文）</li>\n<li>可配置的根部分名称</li>\n<li>可配置的页脚内容</li>\n</ul>\n<h1 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#setup\"></a>设置</h1><p><strong>第 1 步：设置 Netlify</strong></p>\n<ul>\n<li>将您的 Obsidian 保管库文件夹转变为 Git 存储库</li>\n<li>创建一个指向该 Git 存储库的 Netlify 站点</li>\n</ul>\n<p><strong>第 2 步：编辑<code>netlify.toml</code></strong></p>\n<ul>\n<li><code>netlify.toml</code>在您的黑曜石保管库文件夹中创建</li>\n<li>复制此存储库中的内容<code>netlify.example.toml</code>并替换适当的设置（<code>SITE_URL</code>，<code>REPO_URL</code>并且<code>LANDING_PAGE</code>不能留空）。</li>\n</ul>\n<p><strong>第三步：你就完成了🎉！</strong></p>\n<ul>\n<li>推动你的改变，准备好成名！</li>\n<li>花哨一点：（<code>netlify.toml</code>例如<code>LANDING_TITLE</code>）中的所有文本字段设置都支持 HTML 语法。我还为那些想要添加个人风格的人添加了<code>Animate.css</code>++ ~&#96;Hover.css&#96;&#96;CSShake&#96;</li>\n</ul>\n<p><strong>第 4 步：问题和功能请求</strong></p>\n<ul>\n<li>如果您遇到任何问题，请先参考<a href=\"https://github.com/ppeetteerrs/obsidian-zola/blob/main/CONFIG.md\">Config+FAQ</a>。如果仍未解决，只需在<code>Issues</code>选项卡中发布即可。如果问题与部署相关，最好包含在 Netlify 面板中找到的错误日志的副本。</li>\n<li>如果您有任何功能请求，也请发布问题。但是，请注意，此存储库旨在作为一个文件设置。除非大多数用户需要，否则不会支持高级功能&#x2F;详细的可配置性。不过，我可以帮助您实现适合您需求的分叉🥂。</li>\n</ul>\n<p><strong>第 5 步：（可选增强功能）自动提交站点地图</strong></p>\n<p>为了使您的网站对搜索引擎更加友好，您可以添加一个 netlify 插件，以便在每次重新部署网站时自动提交新的站点地图。只需将以下内容添加到您的<code>netlify.toml</code>. 请记住替换<code>baseUrl</code>为您的<code>SITE_URL</code>.</p>\n<figure class=\"highlight toml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs toml\"><span class=\"hljs-section\">[[plugins]]</span><br><span class=\"hljs-attr\">package</span> = <span class=\"hljs-string\">&quot;netlify-plugin-submit-sitemap&quot;</span><br><br><span class=\"hljs-section\">[plugins.inputs]</span><br><br><span class=\"hljs-comment\"># The base url of your site (optional, default = main URL set in Netlify)</span><br><span class=\"hljs-attr\">baseUrl</span> = <span class=\"hljs-string\">&quot;https://peteryuen.netlify.app/&quot;</span><br><br><span class=\"hljs-comment\"># Path to the sitemap URL (optional, default = /sitemap.xml)</span><br><span class=\"hljs-attr\">sitemapPath</span> = <span class=\"hljs-string\">&quot;/sitemap.xml&quot;</span><br><br><span class=\"hljs-comment\"># Time in seconds to not submit the sitemap after successful submission</span><br><span class=\"hljs-attr\">ignorePeriod</span> = <span class=\"hljs-number\">0</span><br><br><span class=\"hljs-comment\"># Enabled providers to submit sitemap to (optional, default = &#x27;google&#x27;, &#x27;bing&#x27;, &#x27;yandex&#x27;). Possible providers are currently only &#x27;google&#x27;, &#x27;bing&#x27;, &#x27;yandex&#x27;.</span><br><span class=\"hljs-attr\">providers</span> = [<br>  <span class=\"hljs-string\">&quot;google&quot;</span>,<br>  <span class=\"hljs-string\">&quot;bing&quot;</span>,<br>  <span class=\"hljs-string\">&quot;yandex&quot;</span>,<br>]<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"示例站点\"><a href=\"#示例站点\" class=\"headerlink\" title=\"示例站点\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#example-site\"></a>示例站点</h1><blockquote>\n<p>不要<code>netlify.toml</code>从示例站点复制，它不稳定。请参考来自<code>netlify.example.toml</code>.</p>\n</blockquote>\n<p>该<a href=\"https://peteryuen.netlify.app/\">示例站点</a>展示了 的功能<code>obsidian-zola</code>。请注意，示例站点使用 的<code>dev</code>分支<code>obsidian-zola</code>。如果您看到示例站点中可用但主分支中尚不可用的功能，请考虑尝试<code>dev</code>（不稳定）分支。具体方法可以参考<a href=\"https://github.com/ppeetteerrs/obsidian-pkm\">示例仓库</a> <code>netlify.toml</code>的.</p>\n<h1 id=\"本地测试（Ubuntu）-感谢-trwbox\"><a href=\"#本地测试（Ubuntu）-感谢-trwbox\" class=\"headerlink\" title=\"本地测试（Ubuntu）[感谢@trwbox]\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#local-testing-ubuntu-thanks-trwbox\"></a>本地测试（Ubuntu）[感谢@trwbox]</h1><ul>\n<li>根据网站上的说明安装 zola<code>https://www.getzola.org/documentation/getting-started/installation/</code></li>\n<li>运行以下命令来安装其他所需的依赖项<code>sudo apt install python-is-python3 python3-pip</code>和<code>pip3 install python-slugify rtoml</code>（或使用<code>conda</code>&#x2F; <code>mamba</code>）</li>\n<li>用于<code>git clone https://github.com/ppeetteerrs/obsidian-zola</code>将存储库克隆到黑曜石保管库文件夹内以外的其他位置</li>\n<li><code>.vault_path</code>使用文件或<code>$VAULT</code>环境变量设置 ObsisianVault 的路径</li>\n<li>用于<code>./local-run.sh</code>运行网站</li>\n</ul>\n<h1 id=\"特征\"><a href=\"#特征\" class=\"headerlink\" title=\"特征\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#features\"></a>特征</h1><p><strong>免责声明</strong></p>\n<blockquote>\n<p>该工具专为使用 Obsidian 作为简单高效的笔记应用程序（或 PKM）的用户而设计。如果您为 Obsidian 配置了大​​量奇特的短代码、插件和特定于 Obsidian 的语法，则该工具不会（也无意）支持这些功能。</p>\n</blockquote>\n<p><strong>支持的</strong></p>\n<ul>\n<li>知识图谱（也可以将其视为反向链接）</li>\n<li>LaTEX（由 提供支持<code>KaTEX</code>，再见 MathJAX 粉丝👋）</li>\n<li>部分字符串搜索（由 提供支持<code>elasticlunr</code>）</li>\n<li>语法高亮 + Fira 代码！</li>\n<li>可定制的动画</li>\n<li>导航</li>\n<li>表中的内容</li>\n<li>典型的 Markdown 语法</li>\n<li>删除线</li>\n<li>表格</li>\n<li>单行脚注（即<code>&lt;sup id=&quot;fnref:1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;&lt;span class=&quot;hint--top hint--rounded&quot; aria-label=&quot;xxx</code>后面）</li>\n<li>复选框</li>\n<li>链接转义模式：<code>[Slides Demo]()</code>“&gt;[1]</span></a></sup><code>在段落中及</code></li>\n</ul>\n<p><strong>不支持</strong></p>\n<ul>\n<li>非图像&#x2F;注释嵌入（例如视频、音频、PDF）。它们将变成链接。</li>\n<li>调整图像大小</li>\n<li>突出显示文本</li>\n<li>评论</li>\n<li>内联&#x2F;多行脚注</li>\n<li>美人鱼图</li>\n</ul>\n<h1 id=\"陷阱\"><a href=\"#陷阱\" class=\"headerlink\" title=\"陷阱\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#gotchas\"></a>陷阱</h1><ol>\n<li>没有带有名称<code>index.md</code>或名称的文件<code>_index.md</code></li>\n<li><del>不存在与其子文件夹同名的文件（例如同时存在<code>.../category1.md</code>且<code>.../category1/xxx.md</code>不允许）</del>（固定的）</li>\n<li><code>LANDING_PAGE``SLUGIFY</code>如果打开，则需要设置为 slugified 文件名（例如，要使用<code>I am Home.md</code>，<code>LANDING_PAGE</code>需要<code>i-am-home</code>）</li>\n</ol>\n<h1 id=\"WIP-想法\"><a href=\"#WIP-想法\" class=\"headerlink\" title=\"WIP&#x2F;想法\"></a><a href=\"https://github.com/ppeetteerrs/obsidian-zola#wips--ideas\"></a>WIP&#x2F;想法</h1><ul>\n<li>（可能会做）反向链接&#x2F;提及</li>\n<li>（也许）洛蒂动画？</li>\n<li>（不知道）可配置的折叠图标<section class=\"footnotes\"><div class=\"footnote-list\"><ol><li><span id=\"fn:1\" class=\"footnote-text\"><span>xxx&#96;后面）<ul>\n<li>复选框</li>\n<li>链接转义模式：<code>[Slides Demo](&lt;Slides Demo&gt;)</code></li>\n</ul>\n<a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li></ol></div></section></li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}